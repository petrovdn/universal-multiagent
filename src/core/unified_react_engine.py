"""
Unified ReAct Engine - parameterized ReAct core that works with any ActionProvider.
Supports different modes (query, agent, plan) through configuration.
"""

from typing import Dict, Any, List, Optional, Literal
from dataclasses import dataclass
import asyncio
import json
import re
import time

from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain_core.language_models.chat_models import BaseChatModel
from langchain_core.tools import BaseTool

from src.core.context_manager import ConversationContext
from src.core.react_state import ReActState, ActionRecord, Observation
from src.core.result_analyzer import ResultAnalyzer, Analysis
from src.core.capability_registry import CapabilityRegistry
from src.core.action_provider import CapabilityCategory
from src.api.websocket_manager import WebSocketManager
from src.agents.model_factory import create_llm
from src.utils.logging_config import get_logger

logger = get_logger(__name__)


@dataclass
class ReActConfig:
    """Configuration for UnifiedReActEngine execution mode."""
    mode: Literal["query", "agent", "plan"]
    allowed_categories: List[CapabilityCategory]
    max_iterations: int = 10
    show_plan_to_user: bool = False
    require_plan_approval: bool = False
    enable_alternatives: bool = True


class UnifiedReActEngine:
    """
    Unified ReAct engine that works with CapabilityRegistry.
    Supports different modes through configuration.
    
    This engine is provider-agnostic - it doesn't know about MCP vs A2A,
    it just works with capabilities from the registry.
    """
    
    def __init__(
        self,
        config: ReActConfig,
        capability_registry: CapabilityRegistry,
        ws_manager: WebSocketManager,
        session_id: str,
        model_name: Optional[str] = None
    ):
        """
        Initialize UnifiedReActEngine.
        
        Args:
            config: ReAct configuration
            capability_registry: Capability registry with all providers
            ws_manager: WebSocket manager for events
            session_id: Session identifier
            model_name: Model name for LLM (optional)
        """
        self.config = config
        self.registry = capability_registry
        self.ws_manager = ws_manager
        self.session_id = session_id
        self.model_name = model_name
        
        # Get allowed capabilities based on config
        self.capabilities = self.registry.get_capabilities(
            categories=config.allowed_categories
        )
        
        # Build LLM tools from capabilities for planning
        self.tools = self._build_tools_from_capabilities()
        
        # Create LLM with thinking support
        self.llm = self._create_llm_with_thinking()
        
        # Bind tools to LLM
        self.llm_with_tools = self.llm.bind_tools(self.tools)
        
        # Result analyzer
        self.result_analyzer = ResultAnalyzer(model_name=model_name)
        
        # Stop flag
        self._stop_requested: bool = False
        self._current_thinking_id: Optional[str] = None  # Current thinking block ID
        self._thinking_start_time: Optional[float] = None  # Start time for elapsed calculation
        self._current_intent_id: Optional[str] = None  # Current intent block ID (Cursor-style)
        
        logger.info(
            f"[UnifiedReActEngine] Initialized for session {session_id} "
            f"with mode={config.mode}, {len(self.capabilities)} capabilities"
        )
    
    def stop(self):
        """Request stop of execution."""
        self._stop_requested = True
        logger.info(f"[UnifiedReActEngine] Stop requested for session {self.session_id}")
    
    def _build_tools_from_capabilities(self) -> List[BaseTool]:
        """
        Build LangChain tools from capabilities for LLM planning.
        
        Returns:
            List of BaseTool objects for LLM
        """
        # For now, we need to get actual BaseTool instances from MCP provider
        # This is a temporary bridge - in future, we might not need this
        tools = []
        
        # Get MCP provider if available
        for provider in self.registry.providers:
            if provider.provider_type.value == "mcp_tool":
                # MCP provider has direct access to BaseTool instances
                if hasattr(provider, 'tools'):
                    tools.extend(provider.tools.values())
                break
        
        logger.info(f"[UnifiedReActEngine] Built {len(tools)} tools for LLM planning")
        return tools
    
    def _create_llm_with_thinking(self, budget_tokens: int = 5000) -> BaseChatModel:
        """Create LLM instance with extended thinking support."""
        from src.utils.config_loader import get_config
        from langchain_anthropic import ChatAnthropic
        
        config_model_name = self.model_name or "claude-sonnet-4-5"
        config = get_config()
        
        try:
            from src.agents.model_factory import get_available_models
            available_models = get_available_models()
            
            if config_model_name in available_models:
                model_config = available_models[config_model_name]
                provider = model_config.get("provider")
                
                if provider == "anthropic" and model_config.get("supports_reasoning"):
                    reasoning_type = model_config.get("reasoning_type")
                    if reasoning_type == "extended_thinking":
                        return ChatAnthropic(
                            model=model_config["model_id"],
                            api_key=config.anthropic_api_key,
                            streaming=True,
                            temperature=1,
                            thinking={
                                "type": "enabled",
                                "budget_tokens": budget_tokens
                            }
                        )
            
            # Fallback
            return create_llm(config_model_name)
        except Exception as e:
            logger.error(f"[UnifiedReActEngine] Failed to create LLM: {e}")
            return create_llm(config.default_model)
    
    async def execute(
        self,
        goal: str,
        context: ConversationContext,
        file_ids: Optional[List[str]] = None,
        phase: Optional[str] = None  # For Plan Mode: "research", "plan", "execute"
    ) -> Dict[str, Any]:
        """
        Execute ReAct cycle for goal.
        
        Args:
            goal: User's goal
            context: Conversation context
            file_ids: Optional list of file IDs
            phase: Optional phase identifier (for Plan Mode)
            
        Returns:
            Execution result
        """
        file_ids = file_ids or []
        
        # Initialize state
        state = ReActState(goal=goal)
        state.context = {
            "file_ids": file_ids,
            "session_id": self.session_id,
            "phase": phase
        }
        self._stop_requested = False
        
        # Check if query needs tools or can be answered directly (like Cursor does)
        needs_tools = await self._needs_tools(goal, context)
        
        if not needs_tools:
            # Simple query - answer directly without tools
            logger.info(f"[UnifiedReActEngine] Simple query detected, answering directly without tools")
            try:
                return await self._answer_directly(goal, context, state)
            except Exception as e:
                logger.warning(f"[UnifiedReActEngine] Direct answer failed, falling back to ReAct: {e}")
                # Continue with normal ReAct loop if direct answer fails
        
        # Send start event (legacy)
        await self.ws_manager.send_event(
            self.session_id,
            "react_start",
            {"goal": goal, "mode": self.config.mode}
        )
        
        # Send thinking_started event (new Cursor-style)
        self._current_thinking_id = f"thinking-{int(time.time() * 1000)}"
        self._thinking_start_time = time.time()  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Ä–µ–º—è —Å—Ç–∞—Ä—Ç–∞
        await self.ws_manager.send_event(
            self.session_id,
            "thinking_started",
            {"thinking_id": self._current_thinking_id, "started_at": int(time.time() * 1000)}
        )
        
        try:
            # Main ReAct loop
            while state.iteration < state.max_iterations:
                if self._stop_requested:
                    logger.info(f"[UnifiedReActEngine] Stop requested at iteration {state.iteration}")
                    break
                
                state.iteration += 1
                logger.info(f"[UnifiedReActEngine] Starting iteration {state.iteration}")
                
                # 1. THINK - Analyze current situation
                state.status = "thinking"
                thought = await self._think(state, context, file_ids)
                state.current_thought = thought
                state.add_reasoning_step("think", thought)
                await self._stream_reasoning("react_thinking", {
                    "thought": thought,
                    "iteration": state.iteration
                })
                
                if self._stop_requested:
                    break
                
                # 2. PLAN - Choose next action
                state.status = "acting"
                action_plan = await self._plan_action(state, thought, context, file_ids)
                
                # Check for special "FINISH" marker
                tool_name = action_plan.get("tool_name", "")
                if tool_name.upper() == "FINISH" or tool_name == "finish":
                    logger.info(f"[UnifiedReActEngine] LLM indicated task completion")
                    state.add_reasoning_step("plan", action_plan.get("reasoning", "–ó–∞–¥–∞—á–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞"), {
                        "tool": "FINISH",
                        "marker": True
                    })
                    await self._stream_reasoning("react_action", {
                        "action": action_plan.get("description", "–ó–∞–¥–∞—á–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞"),
                        "tool": "FINISH",
                        "params": {},
                        "iteration": state.iteration
                    })
                    return await self._finalize_success(
                        state,
                        action_plan.get("description", "–ó–∞–¥–∞—á–∞ —É—Å–ø–µ—à–Ω–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞"),
                        context
                    )
                
                state.add_reasoning_step("plan", action_plan.get("reasoning", ""), {
                    "tool": action_plan.get("tool_name"),
                    "arguments": action_plan.get("arguments", {})
                })
                await self._stream_reasoning("react_action", {
                    "action": action_plan.get("description", ""),
                    "tool": action_plan.get("tool_name"),
                    "params": action_plan.get("arguments", {}),
                    "iteration": state.iteration
                })
                
                if self._stop_requested:
                    break
                
                # 3. ACT - Execute action through registry
                action_record = state.add_action(
                    action_plan.get("tool_name", "unknown"),
                    action_plan.get("arguments", {})
                )
                
                try:
                    result = await self._execute_action(action_plan, context)
                except Exception as e:
                    logger.error(f"[UnifiedReActEngine] Action execution failed: {e}")
                    result = f"Error: {str(e)}"
                
                # 4. OBSERVE - Analyze result
                state.status = "observing"
                observation = state.add_observation(
                    action_record,
                    result,
                    success=True  # Will be updated by analyzer
                )
                
                await self._stream_reasoning("react_observation", {
                    "result": str(result)[:500],
                    "iteration": state.iteration
                })
                
                # Analyze result
                analysis = await self.result_analyzer.analyze(
                    action_record,
                    result,
                    state.goal,
                    state.observations[:-1]
                )
                
                # Update observation with analysis
                observation.success = analysis.is_success
                observation.error_message = analysis.error_message
                observation.extracted_data = analysis.extracted_data
                
                state.add_reasoning_step("observe", f"Analysis: {analysis.progress_toward_goal:.0%} progress", {
                    "success": analysis.is_success,
                    "progress": analysis.progress_toward_goal,
                    "error": analysis.error_message
                })
                
                # 5. ADAPT - Make decision
                state.status = "adapting"
                
                if analysis.is_goal_achieved:
                    logger.info(f"[UnifiedReActEngine] Goal achieved at iteration {state.iteration}")
                    return await self._finalize_success(state, result, context)
                
                elif analysis.is_error:
                    if self.config.enable_alternatives:
                        alternative = await self._find_alternative(state, analysis, context, file_ids)
                        if alternative:
                            logger.info(f"[UnifiedReActEngine] Trying alternative: {alternative.get('description', '')}")
                            state.alternatives_tried.append(alternative.get("description", ""))
                            state.add_reasoning_step("adapt", f"Trying alternative: {alternative.get('description', '')}", {
                                "alternative": alternative
                            })
                            await self._stream_reasoning("react_adapting", {
                                "reason": analysis.error_message or "Action failed",
                                "new_strategy": alternative.get("description", ""),
                                "iteration": state.iteration
                            })
                            # Continue loop with alternative
                        else:
                            logger.warning(f"[UnifiedReActEngine] No alternatives found, failing gracefully")
                            return await self._finalize_failure(state, analysis, context)
                    else:
                        return await self._finalize_failure(state, analysis, context)
                else:
                    # Progress made, continue
                    state.add_reasoning_step("adapt", "Continuing with progress", {
                        "progress": analysis.progress_toward_goal
                    })
                    logger.info(f"[UnifiedReActEngine] Progress: {analysis.progress_toward_goal:.0%}")
            
            # Max iterations reached
            logger.warning(f"[UnifiedReActEngine] Max iterations reached")
            return await self._finalize_timeout(state, context)
            
        except Exception as e:
            logger.error(f"[UnifiedReActEngine] Error in execute: {e}", exc_info=True)
            await self.ws_manager.send_event(
                self.session_id,
                "react_failed",
                {
                    "reason": str(e),
                    "tried": [alt for alt in state.alternatives_tried]
                }
            )
            raise
    
    async def _needs_tools(self, goal: str, context: ConversationContext) -> bool:
        """
        Determine if the query needs tools or can be answered directly.
        
        Simple queries (greetings, simple questions) don't need tools.
        Complex queries (data retrieval, file operations) need tools.
        """
        goal_lower = goal.lower().strip()
        
        # Simple greetings and basic questions - no tools needed
        simple_patterns = [
            r'^(–ø—Ä–∏–≤–µ—Ç|hello|hi|–∑–¥—Ä–∞–≤—Å—Ç–≤—É–π|–∑–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ|–¥–æ–±—Ä—ã–π\s+(–¥–µ–Ω—å|–≤–µ—á–µ—Ä|—É—Ç—Ä–æ))',
            r'^(—Å–ø–∞—Å–∏–±–æ|thanks|thank\s+you|–±–ª–∞–≥–æ–¥–∞—Ä—é)',
            r'^(–∫–∞–∫\s+–¥–µ–ª–∞|how\s+are\s+you|—á—Ç–æ\s+—Ç—ã|who\s+are\s+you|—á—Ç–æ\s+—É–º–µ–µ—à—å)',
            r'^(–ø–æ–∫–∞|bye|goodbye|–¥–æ\s+—Å–≤–∏–¥–∞–Ω–∏—è)',
        ]
        
        for pattern in simple_patterns:
            if re.match(pattern, goal_lower):
                return False
        
        # Check if query mentions specific actions that require tools
        tool_keywords = [
            '–Ω–∞–π–¥–∏', 'find', '–ø–æ–ª—É—á–∏', 'get', '–≤—ã–≤–µ–¥–∏', 'show', '–æ—Ç–∫—Ä–æ–π', 'open',
            '—Å–æ–∑–¥–∞–π', 'create', '–æ—Ç–ø—Ä–∞–≤—å', 'send', '—Å–æ—Ö—Ä–∞–Ω–∏', 'save',
            '–∫–∞–ª–µ–Ω–¥–∞—Ä—å', 'calendar', '–≤—Å—Ç—Ä–µ—á–∏', 'events', 'meetings',
            '–ø–∏—Å—å–º–∞', 'emails', '–ø–æ—á—Ç–∞', 'mail',
            '—Ç–∞–±–ª–∏—Ü–∞', 'table', 'sheets', '–¥–æ–∫—É–º–µ–Ω—Ç', 'document',
            '—Ñ–∞–π–ª', 'file', '–¥–∞–Ω–Ω—ã–µ', 'data'
        ]
        
        for keyword in tool_keywords:
            if keyword in goal_lower:
                return True
        
        # Use LLM to determine if tools are needed (for edge cases)
        try:
            prompt = f"""–û–ø—Ä–µ–¥–µ–ª–∏, –Ω—É–∂–Ω—ã –ª–∏ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã (–∫–∞–ª–µ–Ω–¥–∞—Ä—å, –ø–æ—á—Ç–∞, —Ñ–∞–π–ª—ã) –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ —ç—Ç–æ—Ç –∑–∞–ø—Ä–æ—Å:

–ó–∞–ø—Ä–æ—Å: "{goal}"

–û—Ç–≤–µ—Ç—å —Ç–æ–ª—å–∫–æ –æ–¥–Ω–∏–º —Å–ª–æ–≤–æ–º: –î–ê –∏–ª–∏ –ù–ï–¢.

–î–ê - –µ—Å–ª–∏ –Ω—É–∂–Ω—ã –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä, "–Ω–∞–π–¥–∏ –≤—Å—Ç—Ä–µ—á–∏", "–ø–æ–∫–∞–∂–∏ –ø–∏—Å—å–º–∞", "–æ—Ç–∫—Ä–æ–π —Ñ–∞–π–ª")
–ù–ï–¢ - –µ—Å–ª–∏ —ç—Ç–æ –ø—Ä–æ—Å—Ç–æ–π –≤–æ–ø—Ä–æ—Å –∏–ª–∏ –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ, –Ω–µ —Ç—Ä–µ–±—É—é—â–µ–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤"""
            
            messages = [
                SystemMessage(content="–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—é –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤. –û—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ –î–ê –∏–ª–∏ –ù–ï–¢."),
                HumanMessage(content=prompt)
            ]
            
            response = await self.llm.ainvoke(messages)
            response_text = str(response.content).strip().upper()
            
            return "–î–ê" in response_text or "YES" in response_text
        except Exception as e:
            logger.error(f"[UnifiedReActEngine] Error checking if tools needed: {e}")
            # Default to using tools if check fails
            return True
    
    async def _answer_directly(
        self,
        goal: str,
        context: ConversationContext,
        state: ReActState
    ) -> Dict[str, Any]:
        """
        Answer simple queries directly without using tools.
        This mimics Cursor's behavior for simple queries.
        """
        try:
            # Build context from conversation history
            context_str = ""
            if hasattr(context, 'messages') and context.messages:
                recent_messages = context.messages[-6:]  # Last 6 messages
                context_str = "\n".join([
                    f"{msg.get('role', 'user')}: {msg.get('content', '')}"
                    for msg in recent_messages
                    if isinstance(msg, dict)
                ])
            
            prompt = f"""–¢—ã –ø–æ–ª–µ–∑–Ω—ã–π AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –û—Ç–≤–µ—Ç—å –Ω–∞ –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ –∏ –¥—Ä—É–∂–µ–ª—é–±–Ω–æ.

{context_str if context_str else ''}

–ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {goal}

–û—Ç–≤–µ—Ç—å –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ."""
            
            messages = [
                SystemMessage(content="–¢—ã –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π –∏ –ø–æ–ª–µ–∑–Ω—ã–π AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –û—Ç–≤–µ—á–∞–π –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ –∏ –∫—Ä–∞—Ç–∫–æ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ."),
                HumanMessage(content=prompt)
            ]
            
            # Send thinking_started event
            self._current_thinking_id = f"thinking-{int(time.time() * 1000)}"
            self._thinking_start_time = time.time()
            await self.ws_manager.send_event(
                self.session_id,
                "thinking_started",
                {"thinking_id": self._current_thinking_id, "started_at": int(time.time() * 1000)}
            )
            
            response = await self.llm.ainvoke(messages)
            
            # Extract response text
            if isinstance(response.content, list):
                text_parts = []
                for block in response.content:
                    if hasattr(block, "text"):
                        text_parts.append(block.text)
                    elif isinstance(block, dict) and "text" in block:
                        text_parts.append(block["text"])
                    elif isinstance(block, str):
                        text_parts.append(block)
                answer = " ".join(text_parts).strip()
            elif isinstance(response.content, str):
                answer = response.content.strip()
            else:
                answer = str(response.content).strip()
            
            # Send thinking_completed
            if self._current_thinking_id:
                elapsed_seconds = time.time() - self._thinking_start_time
                await self.ws_manager.send_event(
                    self.session_id,
                    "thinking_completed",
                    {
                        "thinking_id": self._current_thinking_id,
                        "full_content": answer,
                        "elapsed_seconds": elapsed_seconds,
                        "auto_collapse": True
                    }
                )
                self._current_thinking_id = None
                self._thinking_start_time = None
            
            # Send final result or message_complete based on mode
            if self.config.mode == "query":
                await self.ws_manager.send_event(
                    self.session_id,
                    "final_result",
                    {"content": answer}
                )
            else:
                message_id = f"react_{self.session_id}_{int(time.time() * 1000)}"
                await self.ws_manager.send_event(
                    self.session_id,
                    "message_complete",
                    {
                        "role": "assistant",
                        "message_id": message_id,
                        "content": answer
                    }
                )
            
            return {
                "status": "completed",
                "goal": goal,
                "iterations": 1,
                "actions_taken": 0,
                "final_result": answer,
                "reasoning_trail": [
                    {
                        "iteration": 1,
                        "type": "direct_answer",
                        "content": answer,
                        "metadata": {"simple_query": True}
                    }
                ]
            }
        except Exception as e:
            logger.error(f"[UnifiedReActEngine] Error in _answer_directly: {e}")
            # If direct answer fails, raise exception to fall back to normal ReAct loop
            raise
    
    async def _think(
        self,
        state: ReActState,
        context: ConversationContext,
        file_ids: List[str]
    ) -> str:
        """Generate thought about current situation."""
        context_str = f"–¶–µ–ª—å: {state.goal}\n\n"
        
        # Add file context (uploaded files have PRIORITY #1)
        if file_ids:
            uploaded_files_found = []
            for file_id in file_ids:
                file_data = context.get_file(file_id)
                if file_data:
                    uploaded_files_found.append(file_data)
            if uploaded_files_found:
                context_str += "üìé –ü—Ä–∏–∫—Ä–µ–ø–ª–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã (—Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —É–∂–µ –≤ —Å–æ–æ–±—â–µ–Ω–∏–∏):\n"
                for file_data in uploaded_files_found:
                    context_str += f"- {file_data.get('filename', 'unknown')}\n"
        
        # Add open files context (PRIORITY #2)
        open_files = context.get_open_files() if hasattr(context, 'get_open_files') else []
        if open_files:
            context_str += "üìÇ –û—Ç–∫—Ä—ã—Ç—ã–µ —Ñ–∞–π–ª—ã –≤ —Ä–∞–±–æ—á–µ–π –æ–±–ª–∞—Å—Ç–∏:\n"
            for file in open_files:
                title = file.get('title', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')
                context_str += f"- {title}\n"
        
        if state.action_history:
            context_str += "\n–í—ã–ø–æ–ª–Ω–µ–Ω–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è:\n"
            for i, action in enumerate(state.action_history[-5:], 1):
                obs = next((o for o in state.observations if o.action == action), None)
                status = "‚úì" if obs and obs.success else "‚úó"
                context_str += f"{i}. {status} {action.tool_name}\n"
        
        if state.observations:
            context_str += "\n–ü–æ—Å–ª–µ–¥–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã:\n"
            for obs in state.observations[-3:]:
                result_preview = str(obs.raw_result)[:200]
                context_str += f"- {obs.action.tool_name}: {result_preview}...\n"
        
        prompt = f"""–¢—ã –≤—ã–ø–æ–ª–Ω—è–µ—à—å –∑–∞–¥–∞—á—É –ø–æ—à–∞–≥–æ–≤–æ, –∏—Å–ø–æ–ª—å–∑—É—è –¥–æ—Å—Ç—É–ø–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã.

{context_str}

–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ç–µ–∫—É—â—É—é —Å–∏—Ç—É–∞—Ü–∏—é:
1. –ß—Ç–æ —É–∂–µ —Å–¥–µ–ª–∞–Ω–æ?
2. –ß—Ç–æ –æ—Å—Ç–∞–ª–æ—Å—å —Å–¥–µ–ª–∞—Ç—å –¥–ª—è –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è —Ü–µ–ª–∏?
3. –ö–∞–∫–æ–µ —Å–ª–µ–¥—É—é—â–µ–µ –¥–µ–π—Å—Ç–≤–∏–µ –±—É–¥–µ—Ç –Ω–∞–∏–±–æ–ª–µ–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–º?

–î–∞–π –∫—Ä–∞—Ç–∫–∏–π –∞–Ω–∞–ª–∏–∑ (2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è) –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ."""

        try:
            messages = [
                SystemMessage(content="–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É –∑–∞–¥–∞—á –∏ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—é –¥–µ–π—Å—Ç–≤–∏–π. –û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ."),
                HumanMessage(content=prompt)
            ]
            
            response = await self.llm.ainvoke(messages)
            
            # Handle different response formats
            if isinstance(response.content, list):
                text_parts = []
                for block in response.content:
                    if hasattr(block, "text"):
                        text_parts.append(block.text)
                    elif isinstance(block, dict) and "text" in block:
                        text_parts.append(block["text"])
                    elif isinstance(block, str):
                        text_parts.append(block)
                thought = " ".join(text_parts).strip()
            elif isinstance(response.content, str):
                thought = response.content.strip()
            else:
                thought = str(response.content).strip()
            
            return thought
        except Exception as e:
            logger.error(f"[UnifiedReActEngine] Error in _think: {e}")
            return f"–ê–Ω–∞–ª–∏–∑–∏—Ä—É—é —Å–∏—Ç—É–∞—Ü–∏—é... (–∏—Ç–µ—Ä–∞—Ü–∏—è {state.iteration})"
    
    async def _plan_action(
        self,
        state: ReActState,
        thought: str,
        context: ConversationContext,
        file_ids: List[str]
    ) -> Dict[str, Any]:
        """Plan next action based on thought."""
        # #region agent log
        try:
            with open('/Users/Dima/universal-multiagent/.cursor/debug.log', 'a') as f:
                import json as _json
                f.write(_json.dumps({"location": "unified_react_engine.py:_plan_action:entry", "message": "file_ids received", "data": {"file_ids": file_ids, "file_ids_count": len(file_ids)}, "timestamp": __import__('time').time() * 1000, "sessionId": "debug-session", "runId": "run1", "hypothesisId": "H1"}) + "\n")
        except: pass
        # #endregion
        
        # Get capability descriptions (filtered by allowed categories)
        capability_descriptions = []
        for cap in self.capabilities[:50]:  # Limit to first 50
            capability_descriptions.append(f"- {cap.name}: {cap.description}")
        
        tools_str = "\n".join(capability_descriptions)
        
        # Build context
        context_str = f"–¶–µ–ª—å: {state.goal}\n\n"
        context_str += f"–¢–µ–∫—É—â–∏–π –∞–Ω–∞–ª–∏–∑: {thought}\n\n"
        
        if state.action_history:
            context_str += "–£–∂–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ:\n"
            for action in state.action_history[-3:]:
                context_str += f"- {action.tool_name}\n"
        
        # Add uploaded files context (PRIORITY #1) - must come FIRST
        if file_ids:
            uploaded_files_found = []
            for file_id in file_ids:
                file_data = context.get_file(file_id)
                # #region agent log
                try:
                    with open('/Users/Dima/universal-multiagent/.cursor/debug.log', 'a') as f:
                        import json as _json
                        f.write(_json.dumps({"location": "unified_react_engine.py:_plan_action:get_file", "message": "get_file result", "data": {"file_id": file_id, "file_data_exists": file_data is not None, "file_data_keys": list(file_data.keys()) if file_data else None, "has_text": "text" in file_data if file_data else False}, "timestamp": __import__('time').time() * 1000, "sessionId": "debug-session", "runId": "run1", "hypothesisId": "H2,H3"}) + "\n")
                except: pass
                # #endregion
                if file_data:
                    uploaded_files_found.append(file_data)
            
            # #region agent log
            try:
                with open('/Users/Dima/universal-multiagent/.cursor/debug.log', 'a') as f:
                    import json as _json
                    f.write(_json.dumps({"location": "unified_react_engine.py:_plan_action:files_found", "message": "uploaded_files_found count", "data": {"count": len(uploaded_files_found), "filenames": [f.get('filename') for f in uploaded_files_found]}, "timestamp": __import__('time').time() * 1000, "sessionId": "debug-session", "runId": "run1", "hypothesisId": "H2"}) + "\n")
            except: pass
            # #endregion
            
            if uploaded_files_found:
                context_str += "\nüìé –ü–†–ò–ö–†–ï–ü–õ–ï–ù–ù–´–ï –§–ê–ô–õ–´ (–ü–†–ò–û–†–ò–¢–ï–¢ #1 - –∏—Å–ø–æ–ª—å–∑—É–π –∏—Ö –ü–ï–†–í–´–ú!):\n"
                for file_data in uploaded_files_found:
                    filename = file_data.get('filename', 'unknown')
                    file_type = file_data.get('type', '')
                    if file_type.startswith('image/'):
                        context_str += f"- –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {filename} (—Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —É–∂–µ –≤ —Å–æ–æ–±—â–µ–Ω–∏–∏)\n"
                    elif file_type == 'application/pdf' and 'text' in file_data:
                        context_str += f"- PDF: {filename} (—Ç–µ–∫—Å—Ç —É–∂–µ –≤–∫–ª—é—á–µ–Ω –≤ —Å–æ–æ–±—â–µ–Ω–∏–µ)\n"
                    else:
                        context_str += f"- {filename} ({file_type})\n"
                context_str += "‚ö†Ô∏è –ù–ï –∏—â–∏ —ç—Ç–∏ —Ñ–∞–π–ª—ã –≤ Google Drive - –∏—Ö —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –£–ñ–ï –≤ —Å–æ–æ–±—â–µ–Ω–∏–∏!\n"
        
        # Add open files context (PRIORITY #2)
        open_files = context.get_open_files() if hasattr(context, 'get_open_files') else []
        if open_files:
            context_str += "\nüìÇ –û—Ç–∫—Ä—ã—Ç—ã–µ —Ñ–∞–π–ª—ã –≤ —Ä–∞–±–æ—á–µ–π –æ–±–ª–∞—Å—Ç–∏ (–ü–†–ò–û–†–ò–¢–ï–¢ #2):\n"
            for file in open_files:
                if file.get('type') == 'sheets':
                    context_str += f"- –¢–∞–±–ª–∏—Ü–∞: {file.get('title')} (ID: {file.get('spreadsheet_id')})\n"
                elif file.get('type') == 'docs':
                    context_str += f"- –î–æ–∫—É–º–µ–Ω—Ç: {file.get('title')} (ID: {file.get('document_id')})\n"
            context_str += "‚ö†Ô∏è –ò—Å–ø–æ–ª—å–∑—É–π document_id/spreadsheet_id –Ω–∞–ø—Ä—è–º—É—é, –ù–ï –∏—â–∏ —á–µ—Ä–µ–∑ search!\n"
        
        # #region agent log
        try:
            with open('/Users/Dima/universal-multiagent/.cursor/debug.log', 'a') as f:
                import json as _json
                f.write(_json.dumps({"location": "unified_react_engine.py:_plan_action:context_str", "message": "context_str before prompt", "data": {"context_str_preview": context_str[:500], "has_uploaded_files_mention": "–ü–†–ò–ö–†–ï–ü–õ–ï–ù–ù–´–ï" in context_str, "has_open_files_mention": "–û—Ç–∫—Ä—ã—Ç—ã–µ —Ñ–∞–π–ª—ã" in context_str}, "timestamp": __import__('time').time() * 1000, "sessionId": "debug-session", "runId": "run1", "hypothesisId": "H5"}) + "\n")
        except: pass
        # #endregion
        
        prompt = f"""–¢—ã –ø–ª–∞–Ω–∏—Ä—É–µ—à—å —Å–ª–µ–¥—É—é—â–µ–µ –¥–µ–π—Å—Ç–≤–∏–µ –¥–ª—è –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è —Ü–µ–ª–∏.

{context_str}

–î–æ—Å—Ç—É–ø–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã:
{tools_str}

–í–ê–ñ–ù–û:
- –ï—Å–ª–∏ –ø–æ–ª—É—á–µ–Ω —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º —Å–æ–±—ã—Ç–∏–π/–¥–∞–Ω–Ω—ã—Ö, –Ω–æ –ë–ï–ó –¥–µ—Ç–∞–ª–µ–π (–Ω–∞–ø—Ä–∏–º–µ—Ä, "Found 10 events" –±–µ–∑ —Å–ø–∏—Å–∫–∞), 
  —ç—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ –Ω—É–∂–Ω–æ –ø–æ–ª—É—á–∏—Ç—å –î–ï–¢–ê–õ–ò —ç—Ç–∏—Ö –¥–∞–Ω–Ω—ã—Ö
- –ù–ï –∑–∞–≤–µ—Ä—à–∞–π –∑–∞–¥–∞—á—É, –ø–æ–∫–∞ –Ω–µ –ø–æ–ª—É—á–µ–Ω—ã –≤—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–µ—Ç–∞–ª–∏ –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
- –î–ª—è –∫–∞–ª–µ–Ω–¥–∞—Ä—è: –µ—Å–ª–∏ –ø–æ–ª—É—á–µ–Ω–æ —Ç–æ–ª—å–∫–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–±—ã—Ç–∏–π, –Ω—É–∂–Ω–æ –ø–æ–ª—É—á–∏—Ç—å –¥–µ—Ç–∞–ª–∏ –∫–∞–∂–¥–æ–≥–æ —Å–æ–±—ã—Ç–∏—è
- –î–ª—è —Ñ–∞–π–ª–æ–≤: –µ—Å–ª–∏ –ø–æ–ª—É—á–µ–Ω —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤, –Ω–æ –Ω—É–∂–Ω–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ - –ø–æ–ª—É—á–∏ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ
- –î–ª—è –ø–∏—Å–µ–º: –µ—Å–ª–∏ –ø–æ–ª—É—á–µ–Ω —Å–ø–∏—Å–æ–∫ –ø–∏—Å–µ–º, –Ω–æ –Ω—É–∂–Ω–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ - –ø–æ–ª—É—á–∏ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ

–í—ã–±–µ—Ä–∏ –û–î–ò–ù –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –∏ —É–∫–∞–∂–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –µ–≥–æ –≤—ã–∑–æ–≤–∞. –û—Ç–≤–µ—Ç—å –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON:
{{
    "tool_name": "–∏–º—è_–∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞",
    "arguments": {{"param1": "value1", "param2": "value2"}},
    "description": "–∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –¥–µ–π—Å—Ç–≤–∏—è",
    "reasoning": "–ø–æ—á–µ–º—É –≤—ã–±—Ä–∞–Ω–æ —ç—Ç–æ –¥–µ–π—Å—Ç–≤–∏–µ"
}}

–ï—Å–ª–∏ —Ü–µ–ª—å –ø–æ–ª–Ω–æ—Å—Ç—å—é –¥–æ—Å—Ç–∏–≥–Ω—É—Ç–∞ –∏ –ø–æ–ª—É—á–µ–Ω—ã –í–°–ï –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–µ—Ç–∞–ª–∏ –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é, –∏—Å–ø–æ–ª—å–∑—É–π —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π –º–∞—Ä–∫–µ—Ä:
{{
    "tool_name": "FINISH",
    "arguments": {{}},
    "description": "–∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–Ω–æ–π –∑–∞–¥–∞—á–∏",
    "reasoning": "–ø–æ—á–µ–º—É –∑–∞–¥–∞—á–∞ —Å—á–∏—Ç–∞–µ—Ç—Å—è –≤—ã–ø–æ–ª–Ω–µ–Ω–Ω–æ–π (—É–∫–∞–∂–∏, –∫–∞–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –ø–æ–ª—É—á–µ–Ω—ã)"
}}

–û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –≤–∞–ª–∏–¥–Ω—ã–º JSON, –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞."""

        try:
            messages = [
                SystemMessage(content="–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—é –¥–µ–π—Å—Ç–≤–∏–π. –û—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ –≤–∞–ª–∏–¥–Ω—ã–º JSON."),
                HumanMessage(content=prompt)
            ]
            
            response = await self.llm.ainvoke(messages)
            
            # Handle different response formats
            if isinstance(response.content, list):
                text_parts = []
                for block in response.content:
                    if hasattr(block, "text"):
                        text_parts.append(block.text)
                    elif isinstance(block, dict) and "text" in block:
                        text_parts.append(block["text"])
                    elif isinstance(block, str):
                        text_parts.append(block)
                response_text = " ".join(text_parts).strip()
            elif isinstance(response.content, str):
                response_text = response.content.strip()
            else:
                response_text = str(response.content).strip()
            
            # Extract JSON
            json_match = re.search(r'\{[\s\S]*\}', response_text)
            if json_match:
                json_str = json_match.group(0)
                action_plan = json.loads(json_str)
            else:
                action_plan = json.loads(response_text)
            
            # Validate
            if "tool_name" not in action_plan:
                raise ValueError("tool_name missing in action plan")
            
            return action_plan
            
        except Exception as e:
            logger.error(f"[UnifiedReActEngine] Error in _plan_action: {e}")
            # Fallback
            if self.capabilities:
                fallback_cap = self.capabilities[0]
                return {
                    "tool_name": fallback_cap.name,
                    "arguments": {},
                    "description": f"Fallback: –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ {fallback_cap.name}",
                    "reasoning": f"–û—à–∏–±–∫–∞ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è: {str(e)}. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è fallback –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç."
                }
            else:
                return {
                    "tool_name": "error",
                    "arguments": {},
                    "description": "–û—à–∏–±–∫–∞ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è: –Ω–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤",
                    "reasoning": str(e)
                }
    
    async def _execute_action(
        self,
        action_plan: Dict[str, Any],
        context: ConversationContext
    ) -> Any:
        """Execute action through CapabilityRegistry (provider-agnostic)."""
        capability_name = action_plan.get("tool_name")
        arguments = action_plan.get("arguments", {})
        
        # Registry routes to appropriate provider (MCP or A2A)
        return await self.registry.execute(capability_name, arguments)
    
    async def _find_alternative(
        self,
        state: ReActState,
        analysis: Analysis,
        context: ConversationContext,
        file_ids: List[str]
    ) -> Optional[Dict[str, Any]]:
        """Find alternative action when current one failed."""
        context_str = f"–¶–µ–ª—å: {state.goal}\n\n"
        context_str += f"–û—à–∏–±–∫–∞: {analysis.error_message}\n\n"
        context_str += "–ù–µ—É–¥–∞—á–Ω—ã–µ –ø–æ–ø—ã—Ç–∫–∏:\n"
        for action in state.action_history[-3:]:
            context_str += f"- {action.tool_name}\n"
        
        context_str += f"\n–ò—Å–ø—Ä–æ–±–æ–≤–∞–Ω–Ω—ã–µ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã: {', '.join(state.alternatives_tried) if state.alternatives_tried else '–Ω–µ—Ç'}\n"
        
        # Get capability descriptions
        capability_descriptions = []
        for cap in self.capabilities[:50]:
            capability_descriptions.append(f"- {cap.name}: {cap.description}")
        
        tools_str = "\n".join(capability_descriptions)
        
        prompt = f"""–ü—Ä–µ–¥—ã–¥—É—â–µ–µ –¥–µ–π—Å—Ç–≤–∏–µ –Ω–µ —É–¥–∞–ª–æ—Å—å. –ù–∞–π–¥–∏ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π —Å–ø–æ—Å–æ–± –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è —Ü–µ–ª–∏.

{context_str}

–î–æ—Å—Ç—É–ø–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã:
{tools_str}

–ü—Ä–µ–¥–ª–æ–∂–∏ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON:
{{
    "tool_name": "–∏–º—è_–∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞",
    "arguments": {{"param1": "value1"}},
    "description": "–æ–ø–∏—Å–∞–Ω–∏–µ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–æ–≥–æ –¥–µ–π—Å—Ç–≤–∏—è",
    "reasoning": "–ø–æ—á–µ–º—É —ç—Ç–æ –¥–æ–ª–∂–Ω–æ —Å—Ä–∞–±–æ—Ç–∞—Ç—å"
}}

–ï—Å–ª–∏ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã –Ω–µ—Ç, –≤–µ—Ä–Ω–∏ {{"alternative": false}}.

–û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –≤–∞–ª–∏–¥–Ω—ã–º JSON."""

        try:
            messages = [
                SystemMessage(content="–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –ø–æ–∏—Å–∫—É –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã—Ö —Ä–µ—à–µ–Ω–∏–π. –û—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ –≤–∞–ª–∏–¥–Ω—ã–º JSON."),
                HumanMessage(content=prompt)
            ]
            
            response = await self.llm.ainvoke(messages)
            
            # Handle different response formats
            if isinstance(response.content, list):
                text_parts = []
                for block in response.content:
                    if hasattr(block, "text"):
                        text_parts.append(block.text)
                    elif isinstance(block, dict) and "text" in block:
                        text_parts.append(block["text"])
                    elif isinstance(block, str):
                        text_parts.append(block)
                response_text = " ".join(text_parts).strip()
            elif isinstance(response.content, str):
                response_text = response.content.strip()
            else:
                response_text = str(response.content).strip()
            
            # Extract JSON
            json_match = re.search(r'\{[\s\S]*\}', response_text)
            if json_match:
                json_str = json_match.group(0)
                alternative = json.loads(json_str)
            else:
                alternative = json.loads(response_text)
            
            # Check if alternative exists
            if alternative.get("alternative") is False:
                return None
            
            if "tool_name" not in alternative:
                return None
            
            return alternative
            
        except Exception as e:
            logger.error(f"[UnifiedReActEngine] Error in _find_alternative: {e}")
            return None
    
    async def _generate_final_answer(self, state: ReActState) -> str:
        """Generate a human-friendly final answer based on all collected results."""
        try:
            # Collect all observations/results
            observations_text = ""
            for obs in state.observations:
                if obs.raw_result:
                    observations_text += f"- {obs.action.tool_name}: {str(obs.raw_result)[:500]}\n"
            
            if not observations_text:
                observations_text = "–ù–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ—Ç –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤."
            
            prompt = f"""–í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: "{state.goal}"

–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞:
{observations_text}

–í–ê–ñ–ù–û: –í–Ω–∏–º–∞—Ç–µ–ª—å–Ω–æ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤—ã—à–µ. –ï—Å–ª–∏ —Ç–∞–º –µ—Å—Ç—å –¥–∞–Ω–Ω—ã–µ (events, messages, files –∏ —Ç.–¥.) - –∑–Ω–∞—á–∏—Ç –æ–Ω–∏ –ù–ê–ô–î–ï–ù–´.

–°—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π –æ—Ç–≤–µ—Ç –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ:
- –ï—Å–ª–∏ –Ω–∞–π–¥–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ - –ø–µ—Ä–µ—á–∏—Å–ª–∏ –∏—Ö –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ–Ω—è—Ç–Ω–æ
- –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ –ø—É—Å—Ç—ã–µ (–ø—É—Å—Ç–æ–π –º–∞—Å—Å–∏–≤ [], "Found 0") - —Å–∫–∞–∂–∏ —á—Ç–æ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ
- –ù–ï –≥–æ–≤–æ—Ä–∏ —á—Ç–æ –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç, –µ—Å–ª–∏ –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö –µ—Å—Ç—å –∑–∞–ø–∏—Å–∏!

–û—Ç–≤–µ—Ç:"""

            response = await self.llm.ainvoke([HumanMessage(content=prompt)])
            answer = response.content.strip() if hasattr(response, 'content') else str(response).strip()
            return answer
        except Exception as e:
            logger.error(f"[UnifiedReActEngine] Error generating final answer: {e}")
            # Fallback to last result
            if state.observations:
                last_result = str(state.observations[-1].raw_result)
                return self._format_result_summary(last_result, state.observations[-1].action.tool_name)
            return "–ó–∞–¥–∞—á–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞."

    async def _finalize_success(
        self,
        state: ReActState,
        final_result: Any,
        context: ConversationContext
    ) -> Dict[str, Any]:
        """Finalize successful execution."""
        state.status = "done"
        
        # Generate human-friendly final answer instead of raw result
        human_answer = await self._generate_final_answer(state)
        
        result_summary = {
            "status": "completed",
            "goal": state.goal,
            "iterations": state.iteration,
            "actions_taken": len(state.action_history),
            "final_result": human_answer,
            "reasoning_trail": [
                {
                    "iteration": step.iteration,
                    "type": step.step_type,
                    "content": step.content,
                    "metadata": step.metadata
                }
                for step in state.reasoning_trail
            ]
        }
        
        # Send react_complete event
        await self.ws_manager.send_event(
            self.session_id,
            "react_complete",
            {
                "result": human_answer[:1000],
                "trail": result_summary["reasoning_trail"][-10:]
            }
        )
        
        # Send final_result or message_complete event based on mode
        if self.config.mode == "query":
            # Send final_result event for Query mode
            await self.ws_manager.send_event(
                self.session_id,
                "final_result",
                {
                    "content": human_answer
                }
            )
        else:
            # For agent and plan modes, send message_complete to ensure response is displayed
            message_id = f"react_{self.session_id}_{int(time.time() * 1000)}"
            await self.ws_manager.send_event(
                self.session_id,
                "message_complete",
                {
                    "role": "assistant",
                    "message_id": message_id,
                    "content": human_answer
                }
            )
        
        # Send thinking_completed event
        if self._current_thinking_id and self._thinking_start_time:
            elapsed_seconds = time.time() - self._thinking_start_time
            # –°–æ–±–∏—Ä–∞–µ–º –≤–µ—Å—å –∫–æ–Ω—Ç–µ–Ω—Ç –∏–∑ reasoning trail
            full_content = "\n".join([step.content for step in state.reasoning_trail])
            await self.ws_manager.send_event(
                self.session_id,
                "thinking_completed",
                {
                    "thinking_id": self._current_thinking_id,
                    "full_content": full_content,
                    "elapsed_seconds": elapsed_seconds,
                    "auto_collapse": True
                }
            )
            self._current_thinking_id = None
            self._thinking_start_time = None
        
        if hasattr(context, 'add_message'):
            context.add_message("assistant", f"–ó–∞–¥–∞—á–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞: {state.goal}")
        
        logger.info(f"[UnifiedReActEngine] Successfully completed in {state.iteration} iterations")
        return result_summary
    
    async def _finalize_failure(
        self,
        state: ReActState,
        analysis: Analysis,
        context: ConversationContext
    ) -> Dict[str, Any]:
        """Finalize failed execution with report."""
        state.status = "failed"
        
        failure_report = {
            "status": "failed",
            "goal": state.goal,
            "iterations": state.iteration,
            "actions_taken": len(state.action_history),
            "error": analysis.error_message or "–ù–µ —É–¥–∞–ª–æ—Å—å –¥–æ—Å—Ç–∏—á—å —Ü–µ–ª–∏",
            "alternatives_tried": state.alternatives_tried,
            "reasoning_trail": [
                {
                    "iteration": step.iteration,
                    "type": step.step_type,
                    "content": step.content,
                    "metadata": step.metadata
                }
                for step in state.reasoning_trail
            ]
        }
        
        await self.ws_manager.send_event(
            self.session_id,
            "react_failed",
            {
                "reason": failure_report["error"],
                "tried": state.alternatives_tried
            }
        )
        
        # Send message_complete with error message for agent/plan modes
        if self.config.mode != "query":
            error_message = f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å –∑–∞–¥–∞—á—É: {failure_report['error']}"
            message_id = f"react_{self.session_id}_{int(time.time() * 1000)}"
            await self.ws_manager.send_event(
                self.session_id,
                "message_complete",
                {
                    "role": "assistant",
                    "message_id": message_id,
                    "content": error_message
                }
            )
        
        # Send thinking_completed event (with error, –Ω–µ —Å–≤–æ—Ä–∞—á–∏–≤–∞–µ–º)
        if self._current_thinking_id and self._thinking_start_time:
            elapsed_seconds = time.time() - self._thinking_start_time
            full_content = "\n".join([step.content for step in state.reasoning_trail])
            await self.ws_manager.send_event(
                self.session_id,
                "thinking_completed",
                {
                    "thinking_id": self._current_thinking_id,
                    "full_content": full_content,
                    "elapsed_seconds": elapsed_seconds,
                    "auto_collapse": False  # –ù–µ —Å–≤–æ—Ä–∞—á–∏–≤–∞–µ–º –ø—Ä–∏ –æ—à–∏–±–∫–µ
                }
            )
            self._current_thinking_id = None
            self._thinking_start_time = None
        
        logger.warning(f"[UnifiedReActEngine] Failed after {state.iteration} iterations: {failure_report['error']}")
        return failure_report
    
    async def _finalize_timeout(
        self,
        state: ReActState,
        context: ConversationContext
    ) -> Dict[str, Any]:
        """Finalize execution that reached max iterations."""
        state.status = "failed"
        
        timeout_report = {
            "status": "timeout",
            "goal": state.goal,
            "iterations": state.iteration,
            "actions_taken": len(state.action_history),
            "message": f"–î–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç –∏—Ç–µ—Ä–∞—Ü–∏–π ({state.max_iterations})",
            "reasoning_trail": [
                {
                    "iteration": step.iteration,
                    "type": step.step_type,
                    "content": step.content,
                    "metadata": step.metadata
                }
                for step in state.reasoning_trail
            ]
        }
        
        await self.ws_manager.send_event(
            self.session_id,
            "react_failed",
            {
                "reason": timeout_report["message"],
                "tried": state.alternatives_tried
            }
        )
        
        # Send timeout message based on mode
        timeout_message = f"‚è±Ô∏è {timeout_report['message']}. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —É—Ç–æ—á–Ω–∏—Ç—å –∑–∞–ø—Ä–æ—Å –∏–ª–∏ —Ä–∞–∑–±–∏—Ç—å –∑–∞–¥–∞—á—É –Ω–∞ –±–æ–ª–µ–µ –º–µ–ª–∫–∏–µ —à–∞–≥–∏."
        
        if self.config.mode == "query":
            # For Query mode, send final_result event
            await self.ws_manager.send_event(
                self.session_id,
                "final_result",
                {
                    "content": timeout_message
                }
            )
        else:
            # For agent and plan modes, send message_complete
            message_id = f"react_{self.session_id}_{int(time.time() * 1000)}"
            await self.ws_manager.send_event(
                self.session_id,
                "message_complete",
                {
                    "role": "assistant",
                    "message_id": message_id,
                    "content": timeout_message
                }
            )
        
        # Send thinking_completed event (timeout)
        if self._current_thinking_id and self._thinking_start_time:
            elapsed_seconds = time.time() - self._thinking_start_time
            full_content = "\n".join([step.content for step in state.reasoning_trail])
            await self.ws_manager.send_event(
                self.session_id,
                "thinking_completed",
                {
                    "thinking_id": self._current_thinking_id,
                    "full_content": full_content,
                    "elapsed_seconds": elapsed_seconds,
                    "auto_collapse": False
                }
            )
            self._current_thinking_id = None
            self._thinking_start_time = None
        
        logger.warning(f"[UnifiedReActEngine] Timeout after {state.iteration} iterations")
        return timeout_report
    
    def _transform_to_human_readable(self, action: str, tool_name: str) -> str:
        """Transform technical messages to human-readable format."""
        action_lower = action.lower()
        tool_lower = tool_name.lower()
        
        # –ï—Å–ª–∏ —É–∂–µ human-readable, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å
        if not action_lower.startswith(('fallback:', 'error:', '–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ')):
            return action
        
        # –ú–∞–ø–ø–∏–Ω–≥ tool names –Ω–∞ human-readable –æ–ø–∏—Å–∞–Ω–∏—è
        if 'calendar' in tool_lower or 'event' in tool_lower:
            return "üìÖ –ü–æ–ª—É—á–∞—é —Å–æ–±—ã—Ç–∏—è –∫–∞–ª–µ–Ω–¥–∞—Ä—è..."
        elif 'email' in tool_lower or 'gmail' in tool_lower or 'mail' in tool_lower:
            return "üìß –ò—â—É –≤ –ø–æ—á—Ç–µ..."
        elif 'file' in tool_lower or 'workspace' in tool_lower or 'drive' in tool_lower:
            return "üìÅ –ò—â—É —Ñ–∞–π–ª—ã..."
        elif 'search' in tool_lower:
            return "üîç –ò—â—É –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é..."
        elif 'create' in tool_lower or 'write' in tool_lower:
            return "‚úèÔ∏è –°–æ–∑–¥–∞—é –¥–æ–∫—É–º–µ–Ω—Ç..."
        elif 'read' in tool_lower or 'get' in tool_lower:
            return "üìñ –ß–∏—Ç–∞—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é..."
        else:
            return "üîß –í—ã–ø–æ–ª–Ω—è—é –¥–µ–π—Å—Ç–≤–∏–µ..."
    
    def _get_detail_type(self, tool_name: str) -> str:
        """Map tool name to intent detail type."""
        tool_lower = tool_name.lower()
        if 'search' in tool_lower or 'find' in tool_lower:
            return 'search'
        elif 'read' in tool_lower or 'get' in tool_lower or 'list' in tool_lower or 'fetch' in tool_lower:
            return 'read'
        elif 'create' in tool_lower or 'write' in tool_lower or 'send' in tool_lower or 'update' in tool_lower:
            return 'write'
        else:
            return 'execute'
    
    def _extract_result_details(self, result: str) -> List[str]:
        """Extract meaningful details from result for display in intent block."""
        details = []
        try:
            import json
            logger.debug(f"[_extract_result_details] Parsing result: {result[:200]}...")
            
            # Try to parse as JSON
            data = None
            if result.strip().startswith('{') or result.strip().startswith('['):
                try:
                    data = json.loads(result)
                except json.JSONDecodeError:
                    pass
            
            if isinstance(data, list):
                # List of items (events, messages, files)
                logger.debug(f"[_extract_result_details] Found list with {len(data)} items")
                for item in data[:5]:  # Max 5 items
                    if isinstance(item, dict):
                        # Try common fields
                        name = item.get('summary') or item.get('title') or item.get('subject') or item.get('name') or item.get('filename')
                        if name:
                            details.append(f"‚Ä¢ {name}")
                            logger.debug(f"[_extract_result_details] Extracted: {name}")
            elif isinstance(data, dict):
                logger.debug(f"[_extract_result_details] Found dict with keys: {list(data.keys())[:10]}")
                # Single item or structured response
                if 'events' in data:
                    for event in data['events'][:5]:
                        name = event.get('summary') or event.get('title')
                        if name:
                            details.append(f"üìÖ {name}")
                elif 'messages' in data:
                    for msg in data['messages'][:5]:
                        subject = msg.get('subject') or msg.get('snippet', '')[:50]
                        if subject:
                            details.append(f"üìß {subject}")
                elif 'files' in data:
                    for f in data['files'][:5]:
                        name = f.get('name') or f.get('title')
                        if name:
                            details.append(f"üìÑ {name}")
                else:
                    # Try direct fields for single event/item
                    name = data.get('summary') or data.get('title') or data.get('subject')
                    if name:
                        details.append(f"‚Ä¢ {name}")
            
            # If no structured data found, check for "Found N" pattern and extract lines
            if not details and 'Found' in result:
                lines = result.split('\n')
                for line in lines[1:6]:  # Skip first "Found N" line
                    line = line.strip()
                    if line and len(line) > 3 and not line.startswith('{') and not line.startswith('Found'):
                        details.append(f"‚Ä¢ {line[:100]}")
                        
        except Exception as e:
            logger.error(f"[_extract_result_details] Error: {e}")
            # If parsing fails, try to extract from text
            lines = result.split('\n')
            for line in lines[:5]:
                line = line.strip()
                if line and len(line) > 3 and not line.startswith('{'):
                    details.append(f"‚Ä¢ {line[:100]}")
        
        logger.debug(f"[_extract_result_details] Extracted {len(details)} details")
        return details

    def _format_result_summary(self, result: str, tool: str) -> str:
        """Format raw tool result into human-readable Russian summary."""
        import re
        result_lower = result.lower()
        tool_lower = tool.lower() if tool else ""
        
        # Extract count from common patterns like "Found 5 events", "Found 0 messages"
        count_match = re.search(r'found\s+(\d+)\s+(\w+)', result_lower)
        if count_match:
            count = int(count_match.group(1))
            item_type = count_match.group(2)
            
            # Map item types to Russian with proper pluralization
            def pluralize_ru(n: int, one: str, few: str, many: str) -> str:
                mod10 = n % 10
                mod100 = n % 100
                if mod100 >= 11 and mod100 <= 14:
                    return many
                if mod10 == 1:
                    return one
                if mod10 >= 2 and mod10 <= 4:
                    return few
                return many
            
            if 'event' in item_type or 'calendar' in item_type or '–≤—Å—Ç—Ä–µ—á' in tool_lower:
                word = pluralize_ru(count, '–≤—Å—Ç—Ä–µ—á–∞', '–≤—Å—Ç—Ä–µ—á–∏', '–≤—Å—Ç—Ä–µ—á')
                return f"–ù–∞–π–¥–µ–Ω–æ {count} {word}" if count > 0 else "–í—Å—Ç—Ä–µ—á –Ω–µ –Ω–∞–π–¥–µ–Ω–æ"
            elif 'message' in item_type or 'mail' in item_type or 'email' in item_type or '–ø–∏—Å—å–º' in tool_lower:
                word = pluralize_ru(count, '–ø–∏—Å—å–º–æ', '–ø–∏—Å—å–º–∞', '–ø–∏—Å–µ–º')
                return f"–ù–∞–π–¥–µ–Ω–æ {count} {word}" if count > 0 else "–ü–∏—Å–µ–º –Ω–µ –Ω–∞–π–¥–µ–Ω–æ"
            elif 'file' in item_type or 'document' in item_type or 'doc' in item_type or '—Ñ–∞–π–ª' in tool_lower:
                word = pluralize_ru(count, '—Ñ–∞–π–ª', '—Ñ–∞–π–ª–∞', '—Ñ–∞–π–ª–æ–≤')
                return f"–ù–∞–π–¥–µ–Ω–æ {count} {word}" if count > 0 else "–§–∞–π–ª–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ"
            elif 'contact' in item_type or '–∫–æ–Ω—Ç–∞–∫—Ç' in tool_lower:
                word = pluralize_ru(count, '–∫–æ–Ω—Ç–∞–∫—Ç', '–∫–æ–Ω—Ç–∞–∫—Ç–∞', '–∫–æ–Ω—Ç–∞–∫—Ç–æ–≤')
                return f"–ù–∞–π–¥–µ–Ω–æ {count} {word}" if count > 0 else "–ö–æ–Ω—Ç–∞–∫—Ç–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ"
            elif 'task' in item_type or '–∑–∞–¥–∞—á' in tool_lower:
                word = pluralize_ru(count, '–∑–∞–¥–∞—á–∞', '–∑–∞–¥–∞—á–∏', '–∑–∞–¥–∞—á')
                return f"–ù–∞–π–¥–µ–Ω–æ {count} {word}" if count > 0 else "–ó–∞–¥–∞—á –Ω–µ –Ω–∞–π–¥–µ–Ω–æ"
            else:
                word = pluralize_ru(count, '—Ä–µ–∑—É–ª—å—Ç–∞—Ç', '—Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞', '—Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤')
                return f"–ù–∞–π–¥–µ–Ω–æ {count} {word}" if count > 0 else "–ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ"
        
        # Handle success/error patterns
        if 'success' in result_lower or 'successfully' in result_lower:
            return "‚úì –í—ã–ø–æ–ª–Ω–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ"
        if 'error' in result_lower or 'failed' in result_lower:
            return "‚úó –û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è"
        if 'created' in result_lower:
            return "‚úì –°–æ–∑–¥–∞–Ω–æ"
        if 'sent' in result_lower:
            return "‚úì –û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ"
        if 'updated' in result_lower:
            return "‚úì –û–±–Ω–æ–≤–ª–µ–Ω–æ"
        if 'deleted' in result_lower:
            return "‚úì –£–¥–∞–ª–µ–Ω–æ"
        
        # Default: truncate result
        if len(result) > 50:
            return result[:47] + "..."
        return result if result else "–í—ã–ø–æ–ª–Ω–µ–Ω–æ"

    async def _stream_reasoning(self, event_type: str, data: Dict[str, Any]):
        """Stream reasoning event to WebSocket - Cursor-style intent blocks only."""
        try:
            connection_count = self.ws_manager.get_connection_count(self.session_id)
            if connection_count > 0:
                # Only send intent events (Cursor-style) - no legacy events
                if event_type == "react_thinking":
                    # Don't start intent on thinking - wait for action
                    pass
                
                elif event_type == "react_action":
                    # Start NEW intent with action description
                    tool = data.get("tool", "unknown")
                    action = data.get("action", "")
                    
                    # Save tool for later use in observation
                    self._last_tool = tool
                    
                    # Create human-readable description for the intent
                    description = self._transform_to_human_readable(action, tool)
                    
                    # Start new intent for this action
                    self._current_intent_id = f"intent-{int(time.time() * 1000)}"
                    await self.ws_manager.send_event(
                        self.session_id,
                        "intent_start",
                        {
                            "intent_id": self._current_intent_id,
                            "text": description
                        }
                    )
                
                elif event_type == "react_observation":
                    # Add result details and complete the intent
                    if hasattr(self, '_current_intent_id') and self._current_intent_id:
                        result = str(data.get("result", ""))
                        tool = getattr(self, '_last_tool', 'unknown')
                        
                        # Format result into human-readable Russian summary
                        summary = self._format_result_summary(result, tool)
                        
                        # Extract and send result details (e.g., meeting names, file names)
                        details = self._extract_result_details(result)
                        for detail in details:
                            await self.ws_manager.send_event(
                                self.session_id,
                                "intent_detail",
                                {
                                    "intent_id": self._current_intent_id,
                                    "type": "analyze",
                                    "description": detail
                                }
                            )
                        
                        # Complete intent with summary (for collapsed header)
                        await self.ws_manager.send_event(
                            self.session_id,
                            "intent_complete",
                            {
                                "intent_id": self._current_intent_id,
                                "summary": summary,
                                "auto_collapse": True
                            }
                        )
                        self._current_intent_id = None
                
            else:
                logger.debug(f"[UnifiedReActEngine] Skipping event {event_type} - no WebSocket connection")
        except Exception as e:
            logger.debug(f"[UnifiedReActEngine] Failed to send event {event_type}: {e}")

