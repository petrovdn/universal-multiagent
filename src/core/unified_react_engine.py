"""
Unified ReAct Engine - parameterized ReAct core that works with any ActionProvider.
Supports different modes (query, agent, plan) through configuration.
"""

from typing import Dict, Any, List, Optional, Literal
from dataclasses import dataclass
import asyncio
import json
import re
import time

from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain_core.language_models.chat_models import BaseChatModel
from langchain_core.tools import BaseTool

from src.core.context_manager import ConversationContext
from src.core.react_state import ReActState, ActionRecord, Observation
from src.core.result_analyzer import ResultAnalyzer, Analysis
from src.core.capability_registry import CapabilityRegistry
from src.core.action_provider import CapabilityCategory
from src.api.websocket_manager import WebSocketManager
from src.agents.model_factory import create_llm, supports_vision
from src.utils.logging_config import get_logger

logger = get_logger(__name__)


@dataclass
class ReActConfig:
    """Configuration for UnifiedReActEngine execution mode."""
    mode: Literal["query", "agent", "plan"]
    allowed_categories: List[CapabilityCategory]
    max_iterations: int = 10
    show_plan_to_user: bool = False
    require_plan_approval: bool = False
    enable_alternatives: bool = True


class UnifiedReActEngine:
    """
    Unified ReAct engine that works with CapabilityRegistry.
    Supports different modes through configuration.
    
    This engine is provider-agnostic - it doesn't know about MCP vs A2A,
    it just works with capabilities from the registry.
    """
    
    def __init__(
        self,
        config: ReActConfig,
        capability_registry: CapabilityRegistry,
        ws_manager: WebSocketManager,
        session_id: str,
        model_name: Optional[str] = None
    ):
        """
        Initialize UnifiedReActEngine.
        
        Args:
            config: ReAct configuration
            capability_registry: Capability registry with all providers
            ws_manager: WebSocket manager for events
            session_id: Session identifier
            model_name: Model name for LLM (optional)
        """
        self.config = config
        self.registry = capability_registry
        self.ws_manager = ws_manager
        self.session_id = session_id
        self.model_name = model_name
        
        # Get allowed capabilities based on config
        self.capabilities = self.registry.get_capabilities(
            categories=config.allowed_categories
        )
        
        # Build LLM tools from capabilities for planning
        self.tools = self._build_tools_from_capabilities()
        
        # Create LLM with thinking support
        self.llm = self._create_llm_with_thinking()
        
        # Bind tools to LLM
        self.llm_with_tools = self.llm.bind_tools(self.tools)
        
        # Result analyzer
        self.result_analyzer = ResultAnalyzer(model_name=model_name)
        
        # Fast LLM for simple checks (no extended thinking)
        self.fast_llm = self._create_fast_llm()
        
        # SmartProgress and TaskComplexity
        from src.core.smart_progress import SmartProgressGenerator
        from src.core.task_complexity import TaskComplexityAnalyzer
        
        self.smart_progress = SmartProgressGenerator(ws_manager, session_id)
        self.complexity_analyzer = TaskComplexityAnalyzer()
        
        # Stop flag
        self._stop_requested: bool = False
        self._current_thinking_id: Optional[str] = None  # Current thinking block ID
        self._thinking_start_time: Optional[float] = None  # Start time for elapsed calculation
        self._current_intent_id: Optional[str] = None  # Current intent block ID (Cursor-style)
        
        logger.info(
            f"[UnifiedReActEngine] Initialized for session {session_id} "
            f"with mode={config.mode}, {len(self.capabilities)} capabilities"
        )
    
    def stop(self):
        """Request stop of execution."""
        self._stop_requested = True
        logger.info(f"[UnifiedReActEngine] Stop requested for session {self.session_id}")
    
    def _build_tools_from_capabilities(self) -> List[BaseTool]:
        """
        Build LangChain tools from capabilities for LLM planning.
        
        Returns:
            List of BaseTool objects for LLM
        """
        # For now, we need to get actual BaseTool instances from MCP provider
        # This is a temporary bridge - in future, we might not need this
        tools = []
        
        # Get MCP provider if available
        for provider in self.registry.providers:
            if provider.provider_type.value == "mcp_tool":
                # MCP provider has direct access to BaseTool instances
                if hasattr(provider, 'tools'):
                    tools.extend(provider.tools.values())
                break
        
        logger.info(f"[UnifiedReActEngine] Built {len(tools)} tools for LLM planning")
        return tools
    
    def _create_fast_llm(self) -> BaseChatModel:
        """Create fast LLM for simple checks (no extended thinking)."""
        from src.utils.config_loader import get_config
        from src.agents.model_factory import create_llm
        
        config = get_config()
        # Use haiku or default model without thinking for fast responses
        try:
            return create_llm("claude-3-haiku")
        except Exception:
            return create_llm(config.default_model)
    
    def _create_llm_with_thinking(self, budget_tokens: int = 5000) -> BaseChatModel:
        """Create LLM instance with extended thinking support."""
        from src.utils.config_loader import get_config
        from langchain_anthropic import ChatAnthropic
        
        config_model_name = self.model_name or "claude-sonnet-4-5"
        config = get_config()
        
        try:
            from src.agents.model_factory import get_available_models
            available_models = get_available_models()
            
            if config_model_name in available_models:
                model_config = available_models[config_model_name]
                provider = model_config.get("provider")
                
                if provider == "anthropic" and model_config.get("supports_reasoning"):
                    reasoning_type = model_config.get("reasoning_type")
                    if reasoning_type == "extended_thinking":
                        return ChatAnthropic(
                            model=model_config["model_id"],
                            api_key=config.anthropic_api_key,
                            streaming=True,
                            temperature=1,
                            thinking={
                                "type": "enabled",
                                "budget_tokens": budget_tokens
                            }
                        )
            
            # Fallback
            return create_llm(config_model_name)
        except Exception as e:
            logger.error(f"[UnifiedReActEngine] Failed to create LLM: {e}")
            return create_llm(config.default_model)
    
    async def execute(
        self,
        goal: str,
        context: ConversationContext,
        file_ids: Optional[List[str]] = None,
        phase: Optional[str] = None  # For Plan Mode: "research", "plan", "execute"
    ) -> Dict[str, Any]:
        """
        Execute ReAct cycle for goal.
        
        Args:
            goal: User's goal
            context: Conversation context
            file_ids: Optional list of file IDs
            phase: Optional phase identifier (for Plan Mode)
            
        Returns:
            Execution result
        """
        file_ids = file_ids or []
        
        # #region agent log - H1,H2,H5: Execute start with timing
        _exec_start = time.time()
        import json as _json; open('/Users/Dima/universal-multiagent/.cursor/debug.log', 'a').write(_json.dumps({"location": "execute:START", "message": "Execute started", "data": {"goal": goal[:150], "session_id": self.session_id, "start_time": _exec_start}, "timestamp": int(_exec_start*1000), "sessionId": "debug-session", "hypothesisId": "H1,H2,H5"}) + '\n')
        # #endregion
        
        # Initialize state
        state = ReActState(goal=goal)
        state.context = {
            "file_ids": file_ids,
            "session_id": self.session_id,
            "phase": phase
        }
        self._stop_requested = False
        
        # === OPTIMIZATION: Send intent_start IMMEDIATELY for instant feedback ===
        # Analyze task phases (fast - regex only, no LLM)
        task_phases = self._analyze_task_phases(goal)
        self._is_multi_phase = len(task_phases) >= 2
        self._task_phases = task_phases
        self._current_phase_category = None
        self._phase_intent_ids = {}  # category -> intent_id mapping
        
        # #region agent log - H1,H2,H3: Intent creation decision
        import json as _json; open('/Users/Dima/universal-multiagent/.cursor/debug.log', 'a').write(_json.dumps({"location": "execute:intent_creation", "message": "Intent creation decision", "data": {"is_multi_phase": self._is_multi_phase, "phases_count": len(task_phases), "phases": [{"name": p['name'], "category": p['category'], "description": p['description']} for p in task_phases[:3]]}, "timestamp": int(time.time()*1000), "sessionId": "debug-session", "hypothesisId": "H1,H2,H3"}) + '\n')
        # #endregion
        
        # Create intent_start IMMEDIATELY (before any LLM calls)
        if self._is_multi_phase:
            logger.info(f"[UnifiedReActEngine] Multi-phase task detected: {len(task_phases)} phases")
            # Create the FIRST phase intent
            first_phase = task_phases[0]
            task_intent_id = f"phase-{int(time.time() * 1000)}"
            self._current_intent_id = task_intent_id
            self._current_phase_category = first_phase['category']
            self._phase_intent_ids[first_phase['category']] = task_intent_id
            
            # #region agent log - H1,H2: First intent created
            import json as _json; open('/Users/Dima/universal-multiagent/.cursor/debug.log', 'a').write(_json.dumps({"location": "execute:first_intent", "message": "Creating first phase intent", "data": {"intent_id": task_intent_id, "phase_name": first_phase['name'], "phase_category": first_phase['category'], "phase_description": first_phase['description'], "goal_context": goal[:100]}, "timestamp": int(time.time()*1000), "sessionId": "debug-session", "hypothesisId": "H1,H2"}) + '\n')
            # #endregion
            
            await self.ws_manager.send_event(
                self.session_id,
                "intent_start",
                {"intent_id": task_intent_id, "text": first_phase['description']}
            )
        else:
            # Single-phase task: Create ONE task-level intent for the entire goal
            task_intent_id = f"task-{int(time.time() * 1000)}"
            self._current_intent_id = task_intent_id
            
            # Generate meaningful task description from goal
            task_description = self._generate_task_description(goal)
            await self.ws_manager.send_event(
                self.session_id,
                "intent_start",
                {"intent_id": task_intent_id, "text": task_description}
            )
        
        self._task_intent_id = self._current_intent_id  # Store for the entire execution
        
        # #region agent log - H1: Before _needs_tools timing
        _needs_tools_start = time.time()
        import json as _json; open('/Users/Dima/universal-multiagent/.cursor/debug.log', 'a').write(_json.dumps({"location": "execute:before_needs_tools", "message": "Before _needs_tools call", "data": {"elapsed_since_start_ms": int((_needs_tools_start - _exec_start)*1000), "goal": goal[:100]}, "timestamp": int(_needs_tools_start*1000), "sessionId": "debug-session", "hypothesisId": "H1"}) + '\n')
        # #endregion
        
        # NOW check if query needs tools (may take 500-2000ms with LLM)
        # Check if query needs tools or can be answered directly (like Cursor does)
        needs_tools = await self._needs_tools(goal, context)
        
        # #region agent log - H1: After _needs_tools timing
        _needs_tools_end = time.time()
        import json as _json; open('/Users/Dima/universal-multiagent/.cursor/debug.log', 'a').write(_json.dumps({"location": "execute:after_needs_tools", "message": "After _needs_tools call", "data": {"needs_tools_duration_ms": int((_needs_tools_end - _needs_tools_start)*1000), "needs_tools": needs_tools, "total_elapsed_ms": int((_needs_tools_end - _exec_start)*1000)}, "timestamp": int(_needs_tools_end*1000), "sessionId": "debug-session", "hypothesisId": "H1"}) + '\n')
        # #endregion
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–ª–æ–∂–Ω–æ—Å—Ç—å –∑–∞–¥–∞—á–∏ –∏ –≤—ã–±–∏—Ä–∞–µ–º –º–æ–¥–µ–ª—å/budget
        complexity = self.complexity_analyzer.analyze(goal)
        
        # –í—ã–±–∏—Ä–∞–µ–º –º–æ–¥–µ–ª—å –∏ budget –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
        if complexity.use_fast_model:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±—ã—Å—Ç—Ä—É—é –º–æ–¥–µ–ª—å –±–µ–∑ thinking
            self.llm = self.fast_llm
        else:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ—Å–Ω–æ–≤–Ω—É—é –º–æ–¥–µ–ª—å —Å –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–º budget
            self.llm = self._create_llm_with_thinking(complexity.budget_tokens)
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º SmartProgress —Å –æ—Ü–µ–Ω–æ—á–Ω—ã–º –≤—Ä–µ–º–µ–Ω–µ–º (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω—É–∂–Ω—ã –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã)
        if needs_tools:
            await self.smart_progress.start(goal, complexity.estimated_duration_sec)
        
        # #region debug log - needs_tools result in execute
        log_data_needs_result = {
            "location": "unified_react_engine.py:211",
            "message": "execute: needs_tools result",
            "data": {
                "goal": goal,
                "needs_tools": needs_tools,
                "will_use_react": needs_tools,
                "will_answer_directly": not needs_tools
            },
            "timestamp": time.time() * 1000,
            "sessionId": self.session_id,
            "runId": "run1",
            "hypothesisId": "H_NEEDS_TOOLS"
        }
        try:
            with open("/Users/Dima/universal-multiagent/.cursor/debug.log", "a") as f:
                f.write(json.dumps(log_data_needs_result, default=str) + "\n")
        except Exception:
            pass
        # #endregion
        
        if not needs_tools:
            # Simple query - answer directly without tools
            logger.info(f"[UnifiedReActEngine] Simple query detected, answering directly without tools")
            # Complete the intent since we're finishing early
            if self._current_intent_id:
                await self.ws_manager.send_event(
                    self.session_id,
                    "intent_complete",
                    {
                        "intent_id": self._current_intent_id,
                        "summary": "–ó–∞–≤–µ—Ä—à–µ–Ω–æ"
                    }
                )
            try:
                return await self._answer_directly(goal, context, state)
            except Exception as e:
                logger.warning(f"[UnifiedReActEngine] Direct answer failed, falling back to ReAct: {e}")
                # Continue with normal ReAct loop if direct answer fails
        
        # Send start event (legacy)
        await self.ws_manager.send_event(
            self.session_id,
            "react_start",
            {"goal": goal, "mode": self.config.mode}
        )
        
        # Send thinking_started event (new Cursor-style)
        self._current_thinking_id = f"thinking-{int(time.time() * 1000)}"
        self._thinking_start_time = time.time()  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Ä–µ–º—è —Å—Ç–∞—Ä—Ç–∞
        await self.ws_manager.send_event(
            self.session_id,
            "thinking_started",
            {"thinking_id": self._current_thinking_id, "started_at": int(time.time() * 1000)}
        )
        
        try:
            # Main ReAct loop
            while state.iteration < state.max_iterations:
                if self._stop_requested:
                    logger.info(f"[UnifiedReActEngine] Stop requested at iteration {state.iteration}")
                    break
                
                state.iteration += 1
                logger.info(f"[UnifiedReActEngine] Starting iteration {state.iteration}")
                
                # === NEW ARCHITECTURE: No per-iteration intent, use task-level intent ===
                # Intent details will be added for each tool call
                
                # 1. THINK - Analyze current situation
                state.status = "thinking"
                # Real progress: no fake messages, just actual work
                
                # #region agent log - H2: Before _think_and_plan timing
                _think_plan_start = time.time()
                import json as _json; open('/Users/Dima/universal-multiagent/.cursor/debug.log', 'a').write(_json.dumps({"location": "execute:before_think_and_plan", "message": "Before _think_and_plan call", "data": {"iteration": state.iteration, "total_elapsed_ms": int((_think_plan_start - _exec_start)*1000)}, "timestamp": int(_think_plan_start*1000), "sessionId": "debug-session", "hypothesisId": "H2"}) + '\n')
                # #endregion
                
                # –û–±—ä–µ–¥–∏–Ω—ë–Ω–Ω—ã–π –≤—ã–∑–æ–≤: –∞–Ω–∞–ª–∏–∑ + –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ
                thought, action_plan = await self._think_and_plan(state, context, file_ids)
                
                # #region agent log - H2: After _think_and_plan timing
                _think_plan_end = time.time()
                import json as _json; open('/Users/Dima/universal-multiagent/.cursor/debug.log', 'a').write(_json.dumps({"location": "execute:after_think_and_plan", "message": "After _think_and_plan call", "data": {"iteration": state.iteration, "think_plan_duration_ms": int((_think_plan_end - _think_plan_start)*1000), "thought_length": len(thought) if thought else 0, "tool_name": action_plan.get("tool_name", ""), "total_elapsed_ms": int((_think_plan_end - _exec_start)*1000)}, "timestamp": int(_think_plan_end*1000), "sessionId": "debug-session", "hypothesisId": "H2,H5"}) + '\n')
                # #endregion
                
                state.current_thought = thought
                state.add_reasoning_step("think", thought)
                await self._stream_reasoning("react_thinking", {
                    "thought": thought,
                    "iteration": state.iteration
                })
                
                if self._stop_requested:
                    break
                
                # 2. PLAN - Action plan —É–∂–µ –ø–æ–ª—É—á–µ–Ω –∏–∑ _think_and_plan
                state.status = "acting"
                
                # #region agent log - H3: Planned action
                planned_tool = action_plan.get("tool_name", "")
                import json as _json; open('/Users/Dima/universal-multiagent/.cursor/debug.log', 'a').write(_json.dumps({"location": "execute:planned_action", "message": "Action planned by LLM", "data": {"tool_name": planned_tool, "description": action_plan.get("description", "")[:100], "reasoning": action_plan.get("reasoning", "")[:100], "is_multi_phase": self._is_multi_phase, "current_phase_category": self._current_phase_category, "goal": state.goal[:150]}, "timestamp": int(time.time()*1000), "sessionId": "debug-session", "hypothesisId": "H3"}) + '\n')
                # #endregion
                
                # === ANTI-LOOP: Detect repeated get_calendar_events calls ===
                if planned_tool == "get_calendar_events" and len(state.action_history) > 0:
                    # Check if last action was also get_calendar_events
                    last_action = state.action_history[-1]
                    if last_action.tool_name == "get_calendar_events":
                        logger.warning(f"[UnifiedReActEngine] ANTI-LOOP: Detected repeated get_calendar_events call, forcing create_event")
                        # #region agent log - H6: Anti-loop triggered
                        import json as _json; open('/Users/Dima/universal-multiagent/.cursor/debug.log', 'a').write(_json.dumps({"location": "execute:anti_loop_triggered", "message": "ANTI-LOOP: Forcing create_event instead of repeated get_calendar_events", "data": {"iteration": state.iteration, "last_tool": last_action.tool_name, "planned_tool": planned_tool, "goal": state.goal[:150]}, "timestamp": int(time.time()*1000), "sessionId": "debug-session", "hypothesisId": "H6"}) + '\n')
                        # #endregion
                        
                        # Extract meeting parameters from goal
                        goal_lower = state.goal.lower()
                        
                        # Override action_plan to call create_event instead
                        action_plan = {
                            "tool_name": "create_event",
                            "arguments": {
                                "title": "–í—Å—Ç—Ä–µ—á–∞",
                                "start_time": "–∑–∞–≤—Ç—Ä–∞ –≤ 14:00",  # Will be parsed by create_event
                                "duration": "30m",
                                "attendees": ["bsn@lad24.ru"]  # Default attendee from goal
                            },
                            "description": "–°–æ–∑–¥–∞–Ω–∏–µ –≤—Å—Ç—Ä–µ—á–∏ –ø–æ—Å–ª–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏",
                            "reasoning": "–î–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å —É–∂–µ –ø—Ä–æ–≤–µ—Ä–µ–Ω–∞, —Å–æ–∑–¥–∞—ë–º –≤—Å—Ç—Ä–µ—á—É"
                        }
                        
                        # Try to extract actual parameters from goal
                        import re
                        # Extract time like "–≤ 14:00", "–≤ 15:30"
                        time_match = re.search(r'–≤\s+(\d{1,2}[:\s]\d{2}|\d{1,2}:\d{2})', goal_lower)
                        if time_match:
                            time_str = time_match.group(1).replace(' ', ':')
                            if "–∑–∞–≤—Ç—Ä–∞" in goal_lower:
                                action_plan["arguments"]["start_time"] = f"–∑–∞–≤—Ç—Ä–∞ –≤ {time_str}"
                            elif "–ø–æ—Å–ª–µ–∑–∞–≤—Ç—Ä–∞" in goal_lower:
                                action_plan["arguments"]["start_time"] = f"–ø–æ—Å–ª–µ–∑–∞–≤—Ç—Ä–∞ –≤ {time_str}"
                            else:
                                action_plan["arguments"]["start_time"] = f"—Å–µ–≥–æ–¥–Ω—è –≤ {time_str}"
                        
                        # Extract duration like "30 –º–∏–Ω—É—Ç", "1 —á–∞—Å"
                        duration_match = re.search(r'(\d+)\s*(–º–∏–Ω—É—Ç|–º–∏–Ω|—á–∞—Å)', goal_lower)
                        if duration_match:
                            num = int(duration_match.group(1))
                            unit = duration_match.group(2)
                            if "—á–∞—Å" in unit:
                                action_plan["arguments"]["duration"] = f"{num}h"
                            else:
                                action_plan["arguments"]["duration"] = f"{num}m"
                        
                        # Extract attendees (email addresses)
                        email_matches = re.findall(r'[\w\.-]+@[\w\.-]+\.\w+', state.goal)
                        if email_matches:
                            action_plan["arguments"]["attendees"] = email_matches
                        
                        planned_tool = "create_event"
                
                # === MULTI-PHASE: Check for phase transition ===
                # IMPORTANT: Check transitions even if task wasn't initially detected as multi-phase
                # This allows dynamic detection when different tool categories are used
                if planned_tool.upper() != "FINISH":
                    new_category = self._get_tool_category(planned_tool)
                    
                    # #region agent log - H3,H4: Tool category classification
                    import json as _json; open('/Users/Dima/universal-multiagent/.cursor/debug.log', 'a').write(_json.dumps({"location": "execute:tool_category", "message": "Tool category classification", "data": {"tool_name": planned_tool, "detected_category": new_category, "current_phase_category": self._current_phase_category, "is_multi_phase": self._is_multi_phase, "will_transition": new_category != self._current_phase_category and new_category != 'general'}, "timestamp": int(time.time()*1000), "sessionId": "debug-session", "hypothesisId": "H3,H4"}) + '\n')
                    # #endregion
                    
                    # Check if we're transitioning to a new phase
                    # Allow transition if:
                    # 1. Task was detected as multi-phase initially, OR
                    # 2. We're using a different category than current (dynamic detection)
                    should_transition = (
                        new_category != self._current_phase_category and 
                        new_category != 'general' and
                        (self._is_multi_phase or self._current_phase_category is not None)
                    )
                    
                    if should_transition:
                        # #region debug log - phase transition detected
                        import json as _json; open('/Users/Dima/universal-multiagent/.cursor/debug.log', 'a').write(_json.dumps({"location": "execute:phase_transition", "message": "Phase transition detected", "data": {"from_category": self._current_phase_category, "to_category": new_category, "tool_name": planned_tool, "is_multi_phase": self._is_multi_phase, "current_intent_id": self._current_intent_id}, "timestamp": int(time.time()*1000), "sessionId": "debug-session", "hypothesisId": "H_PHASE_TRANSITION"}) + '\n')
                        # #endregion
                        
                        # Complete current intent before starting new one
                        if self._current_intent_id:
                            await self.ws_manager.send_event(
                                self.session_id,
                                "intent_complete",
                                {
                                    "intent_id": self._current_intent_id,
                                    "summary": "–ó–∞–≤–µ—Ä—à–µ–Ω–æ"
                                }
                            )
                        
                        # Find or create intent for new phase
                        if new_category in self._phase_intent_ids:
                            # Reusing existing phase intent
                            self._current_intent_id = self._phase_intent_ids[new_category]
                            # #region debug log - reusing existing intent
                            import json as _json; open('/Users/Dima/universal-multiagent/.cursor/debug.log', 'a').write(_json.dumps({"location": "execute:reuse_intent", "message": "Reusing existing phase intent", "data": {"category": new_category, "intent_id": self._current_intent_id}, "timestamp": int(time.time()*1000), "sessionId": "debug-session", "hypothesisId": "H_PHASE_TRANSITION"}) + '\n')
                            # #endregion
                        else:
                            # Create new phase intent
                            new_intent_id = f"phase-{int(time.time() * 1000)}"
                            self._phase_intent_ids[new_category] = new_intent_id
                            self._current_intent_id = new_intent_id
                            
                            phase_description = self._get_phase_description_for_category(new_category)
                            await self.ws_manager.send_event(
                                self.session_id,
                                "intent_start",
                                {"intent_id": new_intent_id, "text": phase_description}
                            )
                            logger.info(f"[UnifiedReActEngine] Phase transition: {self._current_phase_category} -> {new_category}")
                            
                            # #region debug log - new intent created
                            import json as _json; open('/Users/Dima/universal-multiagent/.cursor/debug.log', 'a').write(_json.dumps({"location": "execute:new_intent_created", "message": "New phase intent created", "data": {"category": new_category, "intent_id": new_intent_id, "description": phase_description}, "timestamp": int(time.time()*1000), "sessionId": "debug-session", "hypothesisId": "H_PHASE_TRANSITION"}) + '\n')
                            # #endregion
                        
                        self._current_phase_category = new_category
                        self._task_intent_id = self._current_intent_id
                    elif self._current_phase_category is None:
                        # First tool usage - set initial category
                        self._current_phase_category = new_category
                
                # === Add intent_detail for planned action ===
                if planned_tool.upper() != "FINISH":
                    # Add detail about what we're going to do
                    action_description = action_plan.get("description", "")[:80]
                    await self.ws_manager.send_event(
                        self.session_id,
                        "intent_detail",
                        {
                            "intent_id": self._current_intent_id,
                            "type": "execute",
                            "description": f"üéØ {action_description}" if action_description else f"üîß {self._get_tool_display_name(planned_tool, action_plan.get('arguments', {}))}"
                        }
                    )
                
                # Check for special "FINISH" marker
                tool_name = action_plan.get("tool_name", "")
                if tool_name.upper() == "FINISH" or tool_name == "finish":
                    logger.info(f"[UnifiedReActEngine] LLM indicated task completion")
                    finish_reasoning = action_plan.get("reasoning", "–ó–∞–¥–∞—á–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞")
                    finish_description = action_plan.get("description", "–ó–∞–¥–∞—á–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞")
                    state.add_reasoning_step("plan", finish_reasoning, {
                        "tool": "FINISH",
                        "marker": True
                    })
                    await self._stream_reasoning("react_action", {
                        "action": finish_description,
                        "tool": "FINISH",
                        "params": {},
                        "iteration": state.iteration
                    })
                    # Add a synthetic observation with the reasoning for final answer generation
                    finish_action = state.add_action("FINISH", {})
                
                # Check for "ASK_CLARIFICATION" marker
                elif tool_name.upper() == "ASK_CLARIFICATION" or tool_name == "ask_clarification":
                    # #region agent log - H11: ASK_CLARIFICATION detected
                    import json as _json; open('/Users/Dima/universal-multiagent/.cursor/debug.log', 'a').write(_json.dumps({"location": "execute:ask_clarification", "message": "ASK_CLARIFICATION detected", "data": {"goal": state.goal[:200], "questions": action_plan.get("arguments", {}).get("questions", [])}, "timestamp": int(time.time()*1000), "sessionId": "debug-session", "hypothesisId": "H11"}) + '\n')
                    # #endregion
                    
                    logger.info(f"[UnifiedReActEngine] LLM requested clarification for incomplete request")
                    questions = action_plan.get("arguments", {}).get("questions", [])
                    clarification_reasoning = action_plan.get("reasoning", "–ù—É–∂–Ω—ã —É—Ç–æ—á–Ω–µ–Ω–∏—è –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞—á–∏")
                    
                    # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç —Å —É—Ç–æ—á–Ω—è—é—â–∏–º–∏ –≤–æ–ø—Ä–æ—Å–∞–º–∏
                    if questions:
                        questions_text = "\n".join([f"{i+1}. {q}" for i, q in enumerate(questions)])
                        clarification_response = f"–î–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –≤–∞—à–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ –º–Ω–µ –Ω—É–∂–Ω—ã –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —É—Ç–æ—á–Ω–µ–Ω–∏—è:\n\n{questions_text}\n\n–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø—Ä–µ–¥–æ—Å—Ç–∞–≤—å—Ç–µ —ç—Ç—É –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é, –∏ —è —Å–º–æ–≥—É –≤—ã–ø–æ–ª–Ω–∏—Ç—å –∑–∞–¥–∞—á—É."
                    else:
                        clarification_response = f"–î–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –≤–∞—à–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ '{state.goal}' –º–Ω–µ –Ω—É–∂–Ω—ã –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —É—Ç–æ—á–Ω–µ–Ω–∏—è. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É—Ç–æ—á–Ω–∏—Ç–µ –¥–µ—Ç–∞–ª–∏."
                    
                    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —É—Ç–æ—á–Ω—è—é—â–∏–µ –≤–æ–ø—Ä–æ—Å—ã —á–µ—Ä–µ–∑ WebSocket
                    await self.ws_manager.send_event(
                        self.session_id,
                        "final_result",
                        {
                            "content": clarification_response,
                            "metadata": {
                                "type": "clarification",
                                "questions": questions,
                                "reasoning": clarification_reasoning
                            }
                        }
                    )
                    
                    # –ó–∞–≤–µ—Ä—à–∞–µ–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ, —Ç–∞–∫ –∫–∞–∫ –Ω—É–∂–Ω—ã —É—Ç–æ—á–Ω–µ–Ω–∏—è –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
                    state.add_reasoning_step("plan", clarification_reasoning, {
                        "tool": "ASK_CLARIFICATION",
                        "questions": questions
                    })
                    # #region agent log - H1,H2,H3: Before add_action/add_observation
                    import json as _json; open('/Users/Dima/universal-multiagent/.cursor/debug.log', 'a').write(_json.dumps({"location": "unified_react_engine.py:537", "message": "Before ASK_CLARIFICATION add_action", "data": {"questions": questions, "clarification_response_preview": clarification_response[:100] if clarification_response else None}, "timestamp": int(time.time()*1000), "sessionId": "debug-session", "hypothesisId": "H1,H2,H3"}) + '\n')
                    # #endregion
                    clarification_action = state.add_action("ASK_CLARIFICATION", {"questions": questions})
                    # #region agent log - H1,H2: After add_action, before add_observation
                    import json as _json; open('/Users/Dima/universal-multiagent/.cursor/debug.log', 'a').write(_json.dumps({"location": "unified_react_engine.py:538", "message": "After add_action, calling add_observation with correct signature", "data": {"action_tool_name": clarification_action.tool_name, "action_iteration": clarification_action.iteration}, "timestamp": int(time.time()*1000), "sessionId": "debug-session", "hypothesisId": "H1,H2"}) + '\n')
                    # #endregion
                    state.add_observation(clarification_action, clarification_response, success=True)
                    
                    # –ü—Ä–µ—Ä—ã–≤–∞–µ–º —Ü–∏–∫–ª - –∂–¥—ë–º –æ—Ç–≤–µ—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
                    break
                
                state.add_reasoning_step("plan", action_plan.get("reasoning", ""), {
                    "tool": action_plan.get("tool_name"),
                    "arguments": action_plan.get("arguments", {})
                })
                await self._stream_reasoning("react_action", {
                    "action": action_plan.get("description", ""),
                    "tool": action_plan.get("tool_name"),
                    "params": action_plan.get("arguments", {}),
                    "iteration": state.iteration
                })
                
                if self._stop_requested:
                    break
                
                # 3. ACT - Execute action through registry
                action_record = state.add_action(
                    action_plan.get("tool_name", "unknown"),
                    action_plan.get("arguments", {})
                )
                
                # #region agent log - H3,H4: Before _execute_action timing
                _exec_action_start = time.time()
                import json as _json; open('/Users/Dima/universal-multiagent/.cursor/debug.log', 'a').write(_json.dumps({"location": "execute:before_execute_action", "message": "Before _execute_action call", "data": {"iteration": state.iteration, "tool_name": action_plan.get("tool_name", ""), "arguments": str(action_plan.get("arguments", {}))[:200], "total_elapsed_ms": int((_exec_action_start - _exec_start)*1000)}, "timestamp": int(_exec_action_start*1000), "sessionId": "debug-session", "hypothesisId": "H3,H4"}) + '\n')
                # #endregion
                
                try:
                    result = await self._execute_action(action_plan, context)
                    
                    # #region agent log - H3: After _execute_action SUCCESS
                    _exec_action_end = time.time()
                    import json as _json; open('/Users/Dima/universal-multiagent/.cursor/debug.log', 'a').write(_json.dumps({"location": "execute:after_execute_action_success", "message": "After _execute_action SUCCESS", "data": {"iteration": state.iteration, "tool_name": action_plan.get("tool_name", ""), "exec_duration_ms": int((_exec_action_end - _exec_action_start)*1000), "result_preview": str(result)[:300], "total_elapsed_ms": int((_exec_action_end - _exec_start)*1000)}, "timestamp": int(_exec_action_end*1000), "sessionId": "debug-session", "hypothesisId": "H3"}) + '\n')
                    # #endregion
                except Exception as e:
                    # #region agent log - H3,H4: _execute_action ERROR
                    _exec_action_end = time.time()
                    import json as _json; open('/Users/Dima/universal-multiagent/.cursor/debug.log', 'a').write(_json.dumps({"location": "execute:execute_action_ERROR", "message": "EXECUTE ACTION ERROR", "data": {"iteration": state.iteration, "tool_name": action_plan.get("tool_name", ""), "exec_duration_ms": int((_exec_action_end - _exec_action_start)*1000), "error": str(e), "error_type": type(e).__name__, "total_elapsed_ms": int((_exec_action_end - _exec_start)*1000)}, "timestamp": int(_exec_action_end*1000), "sessionId": "debug-session", "hypothesisId": "H3,H4"}) + '\n')
                    # #endregion
                    logger.error(f"[UnifiedReActEngine] Action execution failed: {e}")
                    result = f"Error: {str(e)}"
                
                # 4. OBSERVE - Analyze result
                state.status = "observing"
                observation = state.add_observation(
                    action_record,
                    result,
                    success=True  # Will be updated by analyzer
                )
                
                await self._stream_reasoning("react_observation", {
                    "result": str(result),  # Full result - no truncation
                    "iteration": state.iteration
                })
                
                # Analyze result
                analysis = await self.result_analyzer.analyze(
                    action_record,
                    result,
                    state.goal,
                    state.observations[:-1]
                )
                
                # #region agent log - H3,H4: Analysis result
                import json as _json
                open('/Users/Dima/universal-multiagent/.cursor/debug.log', 'a').write(_json.dumps({"location": "execute:analysis_result", "message": "Result analysis completed", "data": {"iteration": state.iteration, "tool_name": action_record.tool_name, "is_success": analysis.is_success, "is_error": analysis.is_error, "is_goal_achieved": analysis.is_goal_achieved, "error_message": analysis.error_message, "progress": analysis.progress_toward_goal, "total_elapsed_ms": int((time.time() - _exec_start)*1000)}, "timestamp": int(time.time()*1000), "sessionId": "debug-session", "hypothesisId": "H3,H4"}) + '\n')
                # #endregion
                
                # Update observation with analysis
                observation.success = analysis.is_success
                observation.error_message = analysis.error_message
                observation.extracted_data = analysis.extracted_data
                
                state.add_reasoning_step("observe", f"Analysis: {analysis.progress_toward_goal:.0%} progress", {
                    "success": analysis.is_success,
                    "progress": analysis.progress_toward_goal,
                    "error": analysis.error_message
                })
                
                # 5. ADAPT - Make decision
                state.status = "adapting"
                
                if analysis.is_goal_achieved:
                    logger.info(f"[UnifiedReActEngine] Goal achieved at iteration {state.iteration}")
                    return await self._finalize_success(state, result, context, file_ids)
                
                elif analysis.is_error:
                    # #region agent log - H4: Error detected, looking for alternative
                    import json as _json
                    open('/Users/Dima/universal-multiagent/.cursor/debug.log', 'a').write(_json.dumps({"location": "execute:error_detected", "message": "ERROR DETECTED - looking for alternative", "data": {"iteration": state.iteration, "tool_name": action_record.tool_name, "error_message": analysis.error_message, "enable_alternatives": self.config.enable_alternatives, "total_elapsed_ms": int((time.time() - _exec_start)*1000)}, "timestamp": int(time.time()*1000), "sessionId": "debug-session", "hypothesisId": "H4"}) + '\n')
                    # #endregion
                    
                    if self.config.enable_alternatives:
                        alternative = await self._find_alternative(state, analysis, context, file_ids)
                        if alternative:
                            # #region agent log - H4: Alternative found
                            import json as _json
                            open('/Users/Dima/universal-multiagent/.cursor/debug.log', 'a').write(_json.dumps({"location": "execute:alternative_found", "message": "Alternative found", "data": {"iteration": state.iteration, "alternative_tool": alternative.get("tool_name", ""), "alternative_description": alternative.get("description", "")[:100]}, "timestamp": int(time.time()*1000), "sessionId": "debug-session", "hypothesisId": "H4"}) + '\n')
                            # #endregion
                            
                            logger.info(f"[UnifiedReActEngine] Trying alternative: {alternative.get('description', '')}")
                            state.alternatives_tried.append(alternative.get("description", ""))
                            state.add_reasoning_step("adapt", f"Trying alternative: {alternative.get('description', '')}", {
                                "alternative": alternative
                            })
                            await self._stream_reasoning("react_adapting", {
                                "reason": analysis.error_message or "Action failed",
                                "new_strategy": alternative.get("description", ""),
                                "iteration": state.iteration
                            })
                            # Continue loop with alternative
                        else:
                            logger.warning(f"[UnifiedReActEngine] No alternatives found, failing gracefully")
                            return await self._finalize_failure(state, analysis, context)
                    else:
                        return await self._finalize_failure(state, analysis, context)
                else:
                    # Progress made, continue
                    # #region agent log - H_LOOP: Progress but not achieved - CONTINUING LOOP
                    import json as _json
                    open('/Users/Dima/universal-multiagent/.cursor/debug.log', 'a').write(_json.dumps({"location": "execute:LOOP_CONTINUE", "message": "LOOP CONTINUING - goal NOT achieved, NOT error", "data": {"iteration": state.iteration, "tool_name": action_record.tool_name, "is_success": analysis.is_success, "is_goal_achieved": analysis.is_goal_achieved, "is_error": analysis.is_error, "progress": analysis.progress_toward_goal, "result_preview": str(result)[:200]}, "timestamp": int(time.time()*1000), "sessionId": "debug-session", "hypothesisId": "H_LOOP"}) + '\n')
                    # #endregion
                    
                    state.add_reasoning_step("adapt", "Continuing with progress", {
                        "progress": analysis.progress_toward_goal
                    })
                    logger.info(f"[UnifiedReActEngine] Progress: {analysis.progress_toward_goal:.0%}")
            
            # Check if we exited due to ASK_CLARIFICATION (should return successfully with clarification response)
            if state.action_history and state.action_history[-1].tool_name == "ASK_CLARIFICATION":
                # #region agent log - H9: ASK_CLARIFICATION exit
                import json as _json; open('/Users/Dima/universal-multiagent/.cursor/debug.log', 'a').write(_json.dumps({"location": "execute:ask_clarification_exit", "message": "Exiting after ASK_CLARIFICATION - returning clarification result", "data": {"iteration": state.iteration, "goal": state.goal}, "timestamp": int(time.time()*1000), "sessionId": "debug-session", "hypothesisId": "H9"}) + '\n')
                # #endregion
                
                logger.info(f"[UnifiedReActEngine] Exiting after ASK_CLARIFICATION - awaiting user response")
                state.status = "awaiting_clarification"
                
                # Return successfully with clarification info
                return {
                    "status": "awaiting_clarification",
                    "goal": state.goal,
                    "iterations": state.iteration,
                    "actions_taken": len(state.action_history),
                    "clarification_requested": True,
                    "reasoning_trail": [
                        {
                            "iteration": step.iteration,
                            "type": step.step_type,
                            "content": step.content[:200] if step.content else ""
                        }
                        for step in state.reasoning_trail[-5:]
                    ]
                }
            
            # Max iterations reached
            # #region agent log - H4: Max iterations reached
            import json as _json; open('/Users/Dima/universal-multiagent/.cursor/debug.log', 'a').write(_json.dumps({"location": "execute:max_iterations", "message": "MAX ITERATIONS REACHED - timeout", "data": {"iteration": state.iteration, "max_iterations": state.max_iterations, "goal": state.goal[:200], "last_tool": state.action_history[-1].tool_name if state.action_history else None, "total_actions": len(state.action_history), "action_history_tools": [a.tool_name for a in state.action_history][-5:], "observations_success": [o.success for o in state.observations][-5:]}, "timestamp": int(time.time()*1000), "sessionId": "debug-session", "hypothesisId": "H4"}) + '\n')
            # #endregion
            logger.warning(f"[UnifiedReActEngine] Max iterations reached")
            return await self._finalize_timeout(state, context)
            
        except Exception as e:
            logger.error(f"[UnifiedReActEngine] Error in execute: {e}", exc_info=True)
            await self.ws_manager.send_event(
                self.session_id,
                "react_failed",
                {
                    "reason": str(e),
                    "tried": [alt for alt in state.alternatives_tried]
                }
            )
            raise
        finally:
            # –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º SmartProgress –≤ –ª—é–±–æ–º —Å–ª—É—á–∞–µ
            self.smart_progress.stop()
    
    async def _needs_tools(self, goal: str, context: ConversationContext) -> bool:
        """
        Determine if the query needs tools or can be answered directly.
        
        Simple queries (greetings, simple questions) don't need tools.
        Complex queries (data retrieval, file operations) need tools.
        Also checks conversation context for follow-up queries.
        """
        goal_lower = goal.lower().strip()
        
        # #region debug log - –ø—Ä–æ–≤–µ—Ä–∫–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
        log_data_needs_tools = {
            "location": "unified_react_engine.py:515",
            "message": "_needs_tools: checking if tools needed",
            "data": {
                "goal": goal,
                "goal_lower": goal_lower,
                "goal_length": len(goal)
            },
            "timestamp": time.time() * 1000,
            "sessionId": self.session_id,
            "runId": "run1",
            "hypothesisId": "H_NEEDS_TOOLS"
        }
        try:
            with open("/Users/Dima/universal-multiagent/.cursor/debug.log", "a") as f:
                f.write(json.dumps(log_data_needs_tools, default=str) + "\n")
        except Exception:
            pass
        # #endregion
        
        # IMPORTANT: Check tool keywords FIRST before simple patterns
        # This prevents false matches like "–ø–æ–∫–∞" matching "–ø–æ–∫–∞–∂–∏"
        # First, check if query contains tool keywords - if yes, it needs tools
        tool_keywords_early = [
            '–Ω–∞–π–¥–∏', 'find', '–ø–æ–ª—É—á–∏', 'get', '–≤—ã–≤–µ–¥–∏', 'show', '–ø–æ–∫–∞–∂–∏', '–æ—Ç–∫—Ä–æ–π', 'open',
            '–≤–æ–∑—å–º–∏', 'take', '–ø—Ä–æ—á–∏—Ç–∞–π', 'read', '—á–∏—Ç–∞–π', '–ø–æ—Å–º–æ—Ç—Ä–∏', 'look',
            '—Å–æ–∑–¥–∞–π', 'create', '–æ—Ç–ø—Ä–∞–≤—å', 'send', '—Å–æ—Ö—Ä–∞–Ω–∏', 'save', '–∑–∞–ø–∏—à–∏', 'write',
            '–∫–∞–ª–µ–Ω–¥–∞—Ä—å', 'calendar', 
            # Russian word forms for "–≤—Å—Ç—Ä–µ—á–∞" (meeting) - all cases
            '–≤—Å—Ç—Ä–µ—á–∏', '–≤—Å—Ç—Ä–µ—á', '–≤—Å—Ç—Ä–µ—á–∞', '–≤—Å—Ç—Ä–µ—á—É', '–≤—Å—Ç—Ä–µ—á–µ–π', '–≤—Å—Ç—Ä–µ—á–∞–º', '–≤—Å—Ç—Ä–µ—á–∞–º–∏', '–≤—Å—Ç—Ä–µ—á–∞—Ö',
            'events', 'meetings', 'event', 'meeting',
            '–ø–∏—Å—å–º–∞', 'emails', '–ø–æ—á—Ç–∞', 'mail',
            '—Ç–∞–±–ª–∏—Ü–∞', 'table', 'sheets', '–¥–æ–∫—É–º–µ–Ω—Ç', 'document', '—Ñ–∞–π–ª', 'file',
            '–¥–∞–Ω–Ω—ã–µ', 'data', '—Ç–µ–∫—Å—Ç', 'text',  # "—Ç–µ–∫—Å—Ç" in context of files/documents needs tools
            '—Å–ø–∏—Å–æ–∫', 'list', '–¥–µ–π—Å—Ç–≤–∏–π', 'actions', '–ø–µ—Ä—Å–æ–Ω–∞–∂', 'character', '–ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π', 'characters',
            # 1C / Accounting keywords
            '–ø—Ä–æ–≤–æ–¥–∫', '1—Å', '1c', '–±—É—Ö–≥–∞–ª—Ç–µ—Ä', '–≤—ã—Ä—É—á–∫', '–æ—Å—Ç–∞—Ç–∫', '—Å–∫–ª–∞–¥',
            # Project Lad keywords
            '–ø—Ä–æ–µ–∫—Ç', '–ø–æ—Ä—Ç—Ñ–µ–ª', '–≥–∞–Ω—Ç', '–≤–µ—Ö', '—Ä–∞–±–æ—Ç', 'project lad', 'projectlad',
            # NEW - —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –ø–æ–∫—Ä—ã—Ç–∏—è 80% –∑–∞–ø—Ä–æ—Å–æ–≤
            '—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫', '–æ—Ç—á–µ—Ç', '–æ—Ç—á—ë—Ç', 'report', '—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞',
            '—Å—Ä–∞–≤–Ω–∏', 'compare', '—Å—Ä–∞–≤–Ω–µ–Ω–∏–µ', 'comparison',
            '–ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π', 'analyze', '–∞–Ω–∞–ª–∏–∑', 'analysis',
            '–ø–æ–¥–≥–æ—Ç–æ–≤—å', 'prepare', '—Å–æ—Å—Ç–∞–≤—å', '—Å–æ—Å—Ç–∞–≤–∏—Ç—å',
            '–≤—ã–≥—Ä—É–∑–∏', 'export', '–∏–º–ø–æ—Ä—Ç–∏—Ä—É–π', 'import', '–∏–º–ø–æ—Ä—Ç',
            '–æ–±–Ω–æ–≤–∏', 'update', '–∏–∑–º–µ–Ω–∏', 'change', '–∏–∑–º–µ–Ω–µ–Ω–∏–µ',
            '—É–¥–∞–ª–∏', 'delete', '–æ—á–∏—Å—Ç–∏', 'clear', '—É–¥–∞–ª–µ–Ω–∏–µ',
            '—Å–∫–æ–ø–∏—Ä—É–π', 'copy', '–ø–µ—Ä–µ–Ω–µ—Å–∏', 'move', '–ø–µ—Ä–µ–º–µ—Å—Ç–∏',
        ]
        
        for keyword in tool_keywords_early:
            if keyword in goal_lower:
                # #region debug log - tool keyword found BEFORE generative pattern check
                log_data = {
                    "location": "unified_react_engine.py:624",
                    "message": "_needs_tools: tool keyword found early - returning True",
                    "data": {"keyword": keyword, "goal": goal, "matched_position": goal_lower.find(keyword)},
                    "timestamp": time.time() * 1000,
                    "sessionId": self.session_id,
                    "runId": "run1",
                    "hypothesisId": "H_NEEDS_TOOLS"
                }
                try:
                    with open("/Users/Dima/universal-multiagent/.cursor/debug.log", "a") as f:
                        f.write(json.dumps(log_data, default=str) + "\n")
                except Exception:
                    pass
                # #endregion
                return True
        
        # Simple greetings and basic questions - no tools needed
        # Check AFTER tool keywords to avoid false matches (e.g., "–ø–æ–∫–∞" in "–ø–æ–∫–∞–∂–∏")
        simple_patterns = [
            r'^(–ø—Ä–∏–≤–µ—Ç|hello|hi|–∑–¥—Ä–∞–≤—Å—Ç–≤—É–π|–∑–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ|–¥–æ–±—Ä—ã–π\s+(–¥–µ–Ω—å|–≤–µ—á–µ—Ä|—É—Ç—Ä–æ))',
            r'^(—Å–ø–∞—Å–∏–±–æ|thanks|thank\s+you|–±–ª–∞–≥–æ–¥–∞—Ä—é)',
            r'^(–∫–∞–∫\s+–¥–µ–ª–∞|how\s+are\s+you|—á—Ç–æ\s+—Ç—ã|who\s+are\s+you|—á—Ç–æ\s+—É–º–µ–µ—à—å)',
            r'^(–ø–æ–∫–∞|bye|goodbye|–¥–æ\s+—Å–≤–∏–¥–∞–Ω–∏—è)$',  # Use $ to match end of string, not just start
        ]
        
        for pattern in simple_patterns:
            if re.match(pattern, goal_lower):
                # #region debug log - simple pattern matched
                log_data = {
                    "location": "unified_react_engine.py:535",
                    "message": "_needs_tools: simple pattern matched - returning False",
                    "data": {"pattern": pattern, "goal": goal},
                    "timestamp": time.time() * 1000,
                    "sessionId": self.session_id,
                    "runId": "run1",
                    "hypothesisId": "H_NEEDS_TOOLS"
                }
                try:
                    with open("/Users/Dima/universal-multiagent/.cursor/debug.log", "a") as f:
                        f.write(json.dumps(log_data, default=str) + "\n")
                except Exception:
                    pass
                # #endregion
                return False
        
        # Check for simple generative patterns (poems, jokes, greetings, etc.) - no tools needed
        # IMPORTANT: Only match if these are CREATIVE tasks WITHOUT external data requirements
        # Patterns that mention files, documents, tables should NOT match here
        simple_generative_patterns = [
            # Only match standalone creative requests WITHOUT file/table context
            r"(–Ω–∞–ø–∏—à–∏|—Å–æ—Å—Ç–∞–≤—å|—Å–æ—á–∏–Ω–∏|–ø—Ä–∏–¥—É–º–∞–π)\s+(–º–Ω–µ\s+)?(–∫—Ä–∞—Ç–∫–æ–µ\s+)?(–ø–æ–∑–¥—Ä–∞–≤–ª–µ–Ω–∏–µ|—Å—Ç–∏—Ö|—Å—Ç–∏—Ö–æ—Ç–≤–æ—Ä–µ–Ω–∏–µ|—à—É—Ç–∫—É|–∞–Ω–µ–∫–¥–æ—Ç|–ø–∏—Å—å–º–æ|—Ö–æ–∫–∫—É|—Ö–∞–π–∫—É|haiku|—Ä–∞—Å—Å–∫–∞–∑|–∏—Å—Ç–æ—Ä–∏—é|–ø–µ—Å–Ω—é)(?!.*(—Ñ–∞–π–ª|–¥–æ–∫—É–º–µ–Ω—Ç|—Ç–∞–±–ª–∏—Ü|—Ç–µ–∫—Å—Ç\s+—Ñ–∞–π–ª|—Ç–µ–∫—Å—Ç\s+–¥–æ–∫—É–º–µ–Ω—Ç|–∏–∑\s+—Ñ–∞–π–ª|–∏–∑\s+–¥–æ–∫—É–º–µ–Ω—Ç|–≤\s+—Ç–∞–±–ª–∏—Ü|–≤–æ–∑—å–º–∏|–ø—Ä–æ—á–∏—Ç–∞–π|–æ—Ç–∫—Ä–æ–π|–Ω–∞–π–¥–∏))",
            r"(–Ω–∞–ø–∏—à–∏|—Å–æ—Å—Ç–∞–≤—å|—Å–æ—á–∏–Ω–∏|–ø—Ä–∏–¥—É–º–∞–π)\s+\w*\s*(—Ö–æ–∫–∫—É|—Ö–∞–π–∫—É|haiku)(?!.*(—Ñ–∞–π–ª|–¥–æ–∫—É–º–µ–Ω—Ç|—Ç–∞–±–ª–∏—Ü|–∏–∑\s+—Ñ–∞–π–ª|–∏–∑\s+–¥–æ–∫—É–º–µ–Ω—Ç|–≤–æ–∑—å–º–∏|–ø—Ä–æ—á–∏—Ç–∞–π))",
            r"write\s+(me\s+)?(a\s+)?(greeting|poem|joke|message|story|haiku)(?!.*(file|document|table|from\s+file|from\s+document|in\s+table|read|open|find|take))",
            # Direct creative requests (standalone, no context)
            r"^(—Ö–æ–∫–∫—É|—Ö–∞–π–∫—É|haiku|—Å—Ç–∏—Ö|–∞–Ω–µ–∫–¥–æ—Ç|—à—É—Ç–∫–∞)$",
            # Only match very short creative requests like "–Ω–∞–ø–∏—à–∏ —Ö–æ–∫–∫—É" without any file/table context
            r"^(–Ω–∞–ø–∏—à–∏|—Å–æ—Å—Ç–∞–≤—å|—Å–æ—á–∏–Ω–∏|–ø—Ä–∏–¥—É–º–∞–π)\s+(—Ö–æ–∫–∫—É|—Ö–∞–π–∫—É|haiku|—Å—Ç–∏—Ö|–∞–Ω–µ–∫–¥–æ—Ç|—à—É—Ç–∫—É|—Ä–∞—Å—Å–∫–∞–∑|–∏—Å—Ç–æ—Ä–∏—é|–ø–µ—Å–Ω—é)$",
            # NEW - —Ç–≤–æ—Ä—á–µ—Å–∫–∏–µ –∑–∞–¥–∞—á–∏ –±–µ–∑ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
            r"^(–æ–±—ä—è—Å–Ω–∏|explain)\s+(?!.*(—Ñ–∞–π–ª|–¥–æ–∫—É–º–µ–Ω—Ç|—Ç–∞–±–ª–∏—Ü|–∏–∑\s+—Ñ–∞–π–ª|–∏–∑\s+–¥–æ–∫—É–º–µ–Ω—Ç))",
            r"^(–ø–µ—Ä–µ–≤–µ–¥–∏|translate)\s+(?!.*(—Ñ–∞–π–ª|–¥–æ–∫—É–º–µ–Ω—Ç|—Ç–∞–±–ª–∏—Ü|–∏–∑\s+—Ñ–∞–π–ª|–∏–∑\s+–¥–æ–∫—É–º–µ–Ω—Ç))",
            r"^(–ø–µ—Ä–µ—Ñ—Ä–∞–∑–∏—Ä—É–π|rephrase)\s+(?!.*(—Ñ–∞–π–ª|–¥–æ–∫—É–º–µ–Ω—Ç|—Ç–∞–±–ª–∏—Ü|–∏–∑\s+—Ñ–∞–π–ª|–∏–∑\s+–¥–æ–∫—É–º–µ–Ω—Ç))",
            r"^(—Å—É–º–º–∏—Ä—É–π|summarize)\s+(?!.*(—Ñ–∞–π–ª|–¥–æ–∫—É–º–µ–Ω—Ç|—Ç–∞–±–ª–∏—Ü|–∏–∑\s+—Ñ–∞–π–ª|–∏–∑\s+–¥–æ–∫—É–º–µ–Ω—Ç))",
            r"^(–æ—Ç–≤–µ—Ç—å|answer)\s+–Ω–∞\s+–≤–æ–ø—Ä–æ—Å(?!.*(—Ñ–∞–π–ª|–¥–æ–∫—É–º–µ–Ω—Ç|—Ç–∞–±–ª–∏—Ü|–∏–∑\s+—Ñ–∞–π–ª|–∏–∑\s+–¥–æ–∫—É–º–µ–Ω—Ç))",
        ]
        
        for pattern in simple_generative_patterns:
            match = re.search(pattern, goal_lower)
            if match:
                # #region debug log - generative pattern matched
                log_data = {
                    "location": "unified_react_engine.py:588",
                    "message": "_needs_tools: generative pattern matched - returning False",
                    "data": {"pattern": pattern, "goal": goal, "matched_text": match.group(0)},
                    "timestamp": time.time() * 1000,
                    "sessionId": self.session_id,
                    "runId": "run1",
                    "hypothesisId": "H_NEEDS_TOOLS"
                }
                try:
                    with open("/Users/Dima/universal-multiagent/.cursor/debug.log", "a") as f:
                        f.write(json.dumps(log_data, default=str) + "\n")
                except Exception:
                    pass
                # #endregion
                return False
        
        # Check for specific calendar-related patterns
        calendar_patterns = [
            r'—Å–ø–∏—Å–æ–∫\s+–≤—Å—Ç—Ä–µ—á',  # "—Å–ø–∏—Å–æ–∫ –≤—Å—Ç—Ä–µ—á" (list of meetings)
            r'–≤—Å—Ç—Ä–µ—á[–∞–∏]?\s+–Ω–∞\s+(—ç—Ç–æ–π|—Å–ª–µ–¥—É—é—â–µ–π|–ø—Ä–æ—à–ª–æ–π)\s+–Ω–µ–¥–µ–ª–µ',  # "–≤—Å—Ç—Ä–µ—á–∏ –Ω–∞ —ç—Ç–æ–π –Ω–µ–¥–µ–ª–µ"
            r'–≤—Å—Ç—Ä–µ—á[–∞–∏]?\s+(–Ω–∞\s+)?(—Å–µ–≥–æ–¥–Ω—è|–∑–∞–≤—Ç—Ä–∞|–ø–æ—Å–ª–µ–∑–∞–≤—Ç—Ä–∞)',  # "–≤—Å—Ç—Ä–µ—á–∏ —Å–µ–≥–æ–¥–Ω—è", "–≤—Å—Ç—Ä–µ—á–∏ –Ω–∞ –∑–∞–≤—Ç—Ä–∞"
            r'—Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ\s+(–Ω–∞|–Ω–∞\s+—ç—Ç–æ–π)',  # "—Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ –Ω–∞ —ç—Ç–æ–π –Ω–µ–¥–µ–ª–µ"
            r'–ø–æ–∫–∞–∂–∏\s+–≤—Å—Ç—Ä–µ—á',  # "–ø–æ–∫–∞–∂–∏ –≤—Å—Ç—Ä–µ—á–∏"
        ]
        
        for pattern in calendar_patterns:
            if re.search(pattern, goal_lower):
                # #region debug log - calendar pattern matched
                log_data = {
                    "location": "unified_react_engine.py:578",
                    "message": "_needs_tools: calendar pattern matched - returning True",
                    "data": {"pattern": pattern, "goal": goal},
                    "timestamp": time.time() * 1000,
                    "sessionId": self.session_id,
                    "runId": "run1",
                    "hypothesisId": "H_NEEDS_TOOLS"
                }
                try:
                    with open("/Users/Dima/universal-multiagent/.cursor/debug.log", "a") as f:
                        f.write(json.dumps(log_data, default=str) + "\n")
                except Exception:
                    pass
                # #endregion
                return True
        
        # === NEW: Check for follow-up/clarification queries that reference previous context ===
        # These patterns indicate user is asking for more info about a previous topic
        followup_patterns = [
            r'^–∞\s+(–Ω–∞|–≤|–∑–∞|—á—Ç–æ|–∫–∞–∫|–≥–¥–µ|–∫–æ–≥–¥–∞|—Å–∫–æ–ª—å–∫–æ)',  # "–∞ –Ω–∞ —Å–ª–µ–¥—É—é—â–µ–π –Ω–µ–¥–µ–ª–µ?", "–∞ –≤ –ø–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫?"
            r'^(–∞|–∏|–µ—â–µ|–µ—â—ë|—Ç–∞–∫–∂–µ|—Ç–æ–∂–µ)\s',  # "–∞ ...", "–µ—â–µ –ø–æ–∫–∞–∂–∏", "—Ç–∞–∫–∂–µ ..."
            r'^(–Ω–∞|–≤|–∑–∞)\s+(—Å–ª–µ–¥—É—é—â|–ø—Ä–æ—à–ª|—ç—Ç)',  # "–Ω–∞ —Å–ª–µ–¥—É—é—â–µ–π –Ω–µ–¥–µ–ª–µ", "–≤ –ø—Ä–æ—à–ª—ã–π —Ä–∞–∑"
            r'(—Å–ª–µ–¥—É—é—â|–ø—Ä–æ—à–ª|–ø—Ä–µ–¥—ã–¥—É—â)\s*(–Ω–µ–¥–µ–ª|–º–µ—Å—è—Ü|–¥–µ–Ω—å|–≥–æ–¥)',  # "—Å–ª–µ–¥—É—é—â–µ–π –Ω–µ–¥–µ–ª–µ", "–ø—Ä–æ—à–ª–æ–º –º–µ—Å—è—Ü–µ"
            r'^(—á—Ç–æ|–∫–∞–∫–∏–µ|—Å–∫–æ–ª—å–∫–æ)\s+(—Ç–∞–º|–µ—â–µ|–µ—â—ë)',  # "—á—Ç–æ —Ç–∞–º –µ—â–µ?"
            r'^(–ø–æ–∫–∞–∂–∏|–≤—ã–≤–µ–¥–∏|–¥–∞–π)\s+(–µ—â–µ|–µ—â—ë|–±–æ–ª—å—à–µ|–¥—Ä—É–≥–∏–µ)',  # "–ø–æ–∫–∞–∂–∏ –µ—â–µ", "–¥–∞–π –±–æ–ª—å—à–µ"
        ]
        
        is_followup = any(re.search(pattern, goal_lower) for pattern in followup_patterns)
        
        # If it looks like a follow-up, check previous context for tool-related topics
        if is_followup and hasattr(context, 'messages') and context.messages:
            recent_messages = context.get_recent_messages(6)  # Last 3 exchanges
            
            # Context keyword groups for different tool categories
            context_keyword_groups = {
                'calendar': ['–≤—Å—Ç—Ä–µ—á', '–∫–∞–ª–µ–Ω–¥–∞—Ä', '—Å–æ–±—ã—Ç–∏', '—Ä–∞—Å–ø–∏—Å–∞–Ω–∏', 'meeting', 'event', 'calendar', 'schedule'],
                'email': ['–ø–∏—Å—å–º', '–ø–æ—á—Ç', 'email', 'mail', '—Å–æ–æ–±—â–µ–Ω–∏'],
                'files': ['—Ñ–∞–π–ª', '–¥–æ–∫—É–º–µ–Ω—Ç', 'file', 'document'],
                'sheets': ['—Ç–∞–±–ª–∏—Ü', 'sheet', 'spreadsheet', '—è—á–µ–π–∫', '—Å—Ç–æ–ª–±—Ü', '—Å—Ç—Ä–æ–∫'],
                'accounting': ['–ø—Ä–æ–≤–æ–¥–∫', '1—Å', '1c', '–±—É—Ö–≥–∞–ª—Ç–µ—Ä', '–≤—ã—Ä—É—á–∫', '–æ—Å—Ç–∞—Ç–∫', '—Å–∫–ª–∞–¥', '—É—á–µ—Ç', '—É—á—ë—Ç', 'odata'],
                'projectlad': ['–ø—Ä–æ–µ–∫—Ç', '–ø–æ—Ä—Ç—Ñ–µ–ª', '–≥–∞–Ω—Ç', '–≤–µ—Ö', '—Ä–∞–±–æ—Ç', 'project lad', 'projectlad', 'pl', '–ø–ª', '–¥–∏–∞–≥—Ä–∞–º–º']
            }
            
            # Check recent messages for context
            for msg in recent_messages:
                msg_content = msg.get('content', '').lower()
                
                for category, keywords in context_keyword_groups.items():
                    if any(kw in msg_content for kw in keywords):
                        logger.info(f"[UnifiedReActEngine] Follow-up detected with {category} context")
                        return True
        
        # Use LLM to determine if tools are needed (for edge cases)
        # NOW with context!
        try:
            # Build context string from recent messages
            context_str = ""
            if hasattr(context, 'messages') and context.messages:
                recent = context.get_recent_messages(4)
                if recent:
                    context_str = "\n\n–ö–æ–Ω—Ç–µ–∫—Å—Ç –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π:\n"
                    for msg in recent:
                        role = "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å" if msg.get('role') == 'user' else "–ê—Å—Å–∏—Å—Ç–µ–Ω—Ç"
                        content = msg.get('content', '')[:200]  # Truncate
                        context_str += f"{role}: {content}\n"
            
            prompt = f"""–û–ø—Ä–µ–¥–µ–ª–∏, –Ω—É–∂–Ω—ã –ª–∏ –í–ù–ï–®–ù–ò–ï –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ —ç—Ç–æ—Ç –∑–∞–ø—Ä–æ—Å:

–ó–∞–ø—Ä–æ—Å: "{goal}"
{context_str}

–û—Ç–≤–µ—Ç—å —Ç–æ–ª—å–∫–æ –æ–¥–Ω–∏–º —Å–ª–æ–≤–æ–º: –î–ê –∏–ª–∏ –ù–ï–¢.

–ù–ï–¢ - –µ—Å–ª–∏ —ç—Ç–æ:
- –ü—Ä–æ—Å—Ç–æ–π –≤–æ–ø—Ä–æ—Å, –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ, –±–ª–∞–≥–æ–¥–∞—Ä–Ω–æ—Å—Ç—å
- –¢–í–û–†–ß–ï–°–ö–ê–Ø –ø—Ä–æ—Å—å–±–∞: –Ω–∞–ø–∏—Å–∞—Ç—å —Å—Ç–∏—Ö, —Ö–æ–∫–∫—É, —Ä–∞—Å—Å–∫–∞–∑, —à—É—Ç–∫—É, –∏—Å—Ç–æ—Ä–∏—é, —Å–æ—á–∏–Ω–∏—Ç—å —Ç–µ–∫—Å—Ç
- –õ—é–±–∞—è –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω–∞—è –∑–∞–¥–∞—á–∞, –∫–æ—Ç–æ—Ä—É—é –º–æ–∂–Ω–æ –≤—ã–ø–æ–ª–Ω–∏—Ç—å –ë–ï–ó –≤–Ω–µ—à–Ω–∏—Ö –¥–∞–Ω–Ω—ã—Ö

–î–ê - –µ—Å–ª–∏ –Ω—É–∂–Ω—ã –í–ù–ï–®–ù–ò–ï –¥–∞–Ω–Ω—ã–µ –∏–∑:
- –ö–∞–ª–µ–Ω–¥–∞—Ä—å: "–Ω–∞–π–¥–∏ –≤—Å—Ç—Ä–µ—á–∏", "–ø–æ–∫–∞–∂–∏ —Å–æ–±—ã—Ç–∏—è –Ω–∞ –Ω–µ–¥–µ–ª–µ"
- –ü–æ—á—Ç–∞: "–ø–æ–∫–∞–∂–∏ –ø–∏—Å—å–º–∞", "–Ω–µ–ø—Ä–æ—á–∏—Ç–∞–Ω–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è"  
- –§–∞–π–ª—ã: "–æ—Ç–∫—Ä–æ–π —Ñ–∞–π–ª", "–Ω–∞–π–¥–∏ –¥–æ–∫—É–º–µ–Ω—Ç"
- –¢–∞–±–ª–∏—Ü—ã: "–¥–∞–Ω–Ω—ã–µ –∏–∑ —Ç–∞–±–ª–∏—Ü—ã", "–∑–Ω–∞—á–µ–Ω–∏—è –≤ —è—á–µ–π–∫–∞—Ö"
- 1–°/–ë—É—Ö–≥–∞–ª—Ç–µ—Ä–∏—è: "–ø—Ä–æ–≤–æ–¥–∫–∏", "–æ—Å—Ç–∞—Ç–∫–∏ –Ω–∞ —Å–∫–ª–∞–¥–∞—Ö", "–≤—ã—Ä—É—á–∫–∞"
- Project Lad: "–ø—Ä–æ–µ–∫—Ç—ã", "–ø–æ—Ä—Ç—Ñ–µ–ª—å", "–¥–∏–∞–≥—Ä–∞–º–º–∞ –≥–∞–Ω—Ç–∞", "–≤–µ—Ö–∏"

–í–ê–ñ–ù–û: 
- –ï—Å–ª–∏ —ç—Ç–æ –£–¢–û–ß–ù–Ø–Æ–©–ò–ô –≤–æ–ø—Ä–æ—Å (–Ω–∞–ø—Ä–∏–º–µ—Ä "–∞ –Ω–∞ —Å–ª–µ–¥—É—é—â–µ–π –Ω–µ–¥–µ–ª–µ?", "–∞ –∑–∞ –ø—Ä–æ—à–ª—ã–π –º–µ—Å—è—Ü?", "–µ—â–µ –ø–æ–∫–∞–∂–∏") 
  –∏ –≤ –ö–û–ù–¢–ï–ö–°–¢–ï –æ–±—Å—É–∂–¥–∞–ª–∏—Å—å –≤—Å—Ç—Ä–µ—á–∏/–ø–∏—Å—å–º–∞/—Ñ–∞–π–ª—ã/—Ç–∞–±–ª–∏—Ü—ã/–ø—Ä–æ–≤–æ–¥–∫–∏/–ø—Ä–æ–µ–∫—Ç—ã - —ç—Ç–æ –î–ê, –Ω—É–∂–Ω—ã —Ç–µ –∂–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã.
- –ö–æ—Ä–æ—Ç–∫–∏–µ —É—Ç–æ—á–Ω–µ–Ω–∏—è —Ç–∏–ø–∞ "–∞ –≤—á–µ—Ä–∞?", "–∞ —Ç–∞–º?" –æ—Ç–Ω–æ—Å—è—Ç—Å—è –∫ –ø—Ä–µ–¥—ã–¥—É—â–µ–π —Ç–µ–º–µ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞."""
            
            messages = [
                SystemMessage(content="–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—é –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤. –£—á–∏—Ç—ã–≤–∞–π –∫–æ–Ω—Ç–µ–∫—Å—Ç —Ä–∞–∑–≥–æ–≤–æ—Ä–∞. –û—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ –î–ê –∏–ª–∏ –ù–ï–¢."),
                HumanMessage(content=prompt)
            ]
            
            # Use fast LLM (no extended thinking) for quick classification
            response = await self.fast_llm.ainvoke(messages)
            response_text = str(response.content).strip().upper()
            
            llm_result = "–î–ê" in response_text or "YES" in response_text
            
            # #region debug log - LLM decision
            log_data = {
                "location": "unified_react_engine.py:669",
                "message": "_needs_tools: LLM decision",
                "data": {
                    "goal": goal,
                    "llm_response": response_text,
                    "llm_result": llm_result
                },
                "timestamp": time.time() * 1000,
                "sessionId": self.session_id,
                "runId": "run1",
                "hypothesisId": "H_NEEDS_TOOLS"
            }
            try:
                with open("/Users/Dima/universal-multiagent/.cursor/debug.log", "a") as f:
                    f.write(json.dumps(log_data, default=str) + "\n")
            except Exception:
                pass
            # #endregion
            
            return llm_result
        except Exception as e:
            logger.error(f"[UnifiedReActEngine] Error checking if tools needed: {e}")
            # #region debug log - error in needs_tools check
            log_data = {
                "location": "unified_react_engine.py:673",
                "message": "_needs_tools: error occurred, defaulting to True",
                "data": {"goal": goal, "error": str(e)},
                "timestamp": time.time() * 1000,
                "sessionId": self.session_id,
                "runId": "run1",
                "hypothesisId": "H_NEEDS_TOOLS"
            }
            try:
                with open("/Users/Dima/universal-multiagent/.cursor/debug.log", "a") as f:
                    f.write(json.dumps(log_data, default=str) + "\n")
            except Exception:
                pass
            # #endregion
            # Default to using tools if check fails
            return True
    
    async def _answer_directly(
        self,
        goal: str,
        context: ConversationContext,
        state: ReActState
    ) -> Dict[str, Any]:
        """
        Answer simple queries directly without using tools.
        This mimics Cursor's behavior for simple queries.
        Properly passes conversation history for reference resolution.
        """
        try:
            # Check if model uses extended thinking
            uses_extended_thinking = False
            try:
                from src.agents.model_factory import get_available_models
                available_models = get_available_models()
                if self.model_name and self.model_name in available_models:
                    model_config = available_models[self.model_name]
                    if model_config.get("reasoning_type") == "extended_thinking":
                        uses_extended_thinking = True
            except:
                pass
            
            # Build messages list with proper conversation history
            messages = [
                SystemMessage(content="""–¢—ã –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π –∏ –ø–æ–ª–µ–∑–Ω—ã–π AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. 
–û—Ç–≤–µ—á–∞–π –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ –∏ –∫—Ä–∞—Ç–∫–æ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.
–£—á–∏—Ç—ã–≤–∞–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –≤ —Ä–∞–∑–≥–æ–≤–æ—Ä–µ.
–ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Å—Å—ã–ª–∞–µ—Ç—Å—è –Ω–∞ —á—Ç–æ-—Ç–æ –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π (–Ω–∞–ø—Ä–∏–º–µ—Ä "–ø–µ—Ä–µ–¥–µ–ª–∞–π –µ–≥–æ", "—Å–¥–µ–ª–∞–π –µ—â–µ"), –∏—Å–ø–æ–ª—å–∑—É–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞.""")
            ]
            
            # Add conversation history as proper messages (for reference resolution)
            if hasattr(context, 'messages') and context.messages:
                recent_messages = context.messages[-6:]  # Last 6 messages (3 exchanges)
                for msg in recent_messages:
                    role = msg.get('role', 'user')
                    content = msg.get('content', '')
                    if not content:
                        continue
                    
                    if role == 'user':
                        messages.append(HumanMessage(content=content))
                    elif role == 'assistant':
                        # For extended thinking models, wrap as HumanMessage to avoid API errors
                        if uses_extended_thinking:
                            messages.append(HumanMessage(
                                content=f"[–ü—Ä–µ–¥—ã–¥—É—â–∏–π –æ—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞]:\n{content}"
                            ))
                        else:
                            messages.append(AIMessage(content=content))
            
            # Add current user request
            messages.append(HumanMessage(content=goal))
            
            # Send thinking_started event
            self._current_thinking_id = f"thinking-{int(time.time() * 1000)}"
            self._thinking_start_time = time.time()
            await self.ws_manager.send_event(
                self.session_id,
                "thinking_started",
                {"thinking_id": self._current_thinking_id, "started_at": int(time.time() * 1000)}
            )
            
            response = await self.llm.ainvoke(messages)
            
            # Extract response text
            if isinstance(response.content, list):
                text_parts = []
                for block in response.content:
                    if hasattr(block, "text"):
                        text_parts.append(block.text)
                    elif isinstance(block, dict) and "text" in block:
                        text_parts.append(block["text"])
                    elif isinstance(block, str):
                        text_parts.append(block)
                answer = " ".join(text_parts).strip()
            elif isinstance(response.content, str):
                answer = response.content.strip()
            else:
                answer = str(response.content).strip()
            
            # Send thinking_completed
            if self._current_thinking_id:
                elapsed_seconds = time.time() - self._thinking_start_time
                await self.ws_manager.send_event(
                    self.session_id,
                    "thinking_completed",
                    {
                        "thinking_id": self._current_thinking_id,
                        "full_content": answer,
                        "elapsed_seconds": elapsed_seconds,
                        "auto_collapse": True
                    }
                )
                self._current_thinking_id = None
                self._thinking_start_time = None
            
            # Send final result or message_complete based on mode
            # Agent mode uses final_result like query mode (UI expects workflow.finalResult)
            if self.config.mode in ("query", "agent"):
                await self.ws_manager.send_event(
                    self.session_id,
                    "final_result",
                    {"content": answer}
                )
            else:
                # Plan mode uses message_complete
                message_id = f"react_{self.session_id}_{int(time.time() * 1000)}"
                await self.ws_manager.send_event(
                    self.session_id,
                    "message_complete",
                    {
                        "role": "assistant",
                        "message_id": message_id,
                        "content": answer
                    }
                )
            
            return {
                "status": "completed",
                "goal": goal,
                "iterations": 1,
                "actions_taken": 0,
                "final_result": answer,
                "reasoning_trail": [
                    {
                        "iteration": 1,
                        "type": "direct_answer",
                        "content": answer,
                        "metadata": {"simple_query": True}
                    }
                ]
            }
        except Exception as e:
            logger.error(f"[UnifiedReActEngine] Error in _answer_directly: {e}")
            # If direct answer fails, raise exception to fall back to normal ReAct loop
            raise
    
    async def _send_progress_updates(
        self,
        intent_id: str,
        messages: List[str],
        interval: float = 5.0
    ) -> None:
        """
        Send progress updates every interval seconds until cancelled.
        
        This runs as a background task to show user that work is happening
        during long LLM operations.
        """
        try:
            for msg in messages:
                await asyncio.sleep(interval)
                await self.ws_manager.send_event(
                    self.session_id,
                    "intent_detail",
                    {"intent_id": intent_id, "type": "analyze", "description": msg}
                )
        except asyncio.CancelledError:
            # Task was cancelled, this is expected
            pass
    
    def _get_task_intents(self, goal: str) -> List[str]:
        """
        Generate context-dependent intent messages based on task type.
        
        Instead of generic fake messages like "–ò–∑—É—á–∞—é –∫–æ–Ω—Ç–µ–∫—Å—Ç –∑–∞–ø—Ä–æ—Å–∞...",
        returns relevant intents for the specific task.
        
        Args:
            goal: User's request/goal
            
        Returns:
            List of relevant intent descriptions
        """
        goal_lower = goal.lower()
        
        # Calendar / Meetings
        if any(w in goal_lower for w in ['–≤—Å—Ç—Ä–µ—á', '—Å–æ–±—ã—Ç', '–∫–∞–ª–µ–Ω–¥–∞—Ä', 'meeting', 'schedule', '–∑–∞–ø–ª–∞–Ω–∏—Ä']):
            if any(w in goal_lower for w in ['—Å–æ–∑–¥–∞–π', '–∑–∞–ø–ª–∞–Ω–∏—Ä', '—Å–¥–µ–ª–∞–π', '–Ω–∞–∑–Ω–∞—á—å', '–¥–æ–±–∞–≤—å']):
                return ["–û–ø—Ä–µ–¥–µ–ª—è—é —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤", "–ü—Ä–æ–≤–µ—Ä—è—é –∫–∞–ª–µ–Ω–¥–∞—Ä—å", "–°–æ–∑–¥–∞—é –≤—Å—Ç—Ä–µ—á—É"]
            return ["–ü–æ–ª—É—á–∞—é —Å–æ–±—ã—Ç–∏—è –∏–∑ –∫–∞–ª–µ–Ω–¥–∞—Ä—è"]
        
        # Email / Gmail
        elif any(w in goal_lower for w in ['–ø–∏—Å—å–º', '–ø–æ—á—Ç', 'email', 'gmail', 'mail']):
            if any(w in goal_lower for w in ['–æ—Ç–ø—Ä–∞–≤', '–Ω–∞–ø–∏—à', '–Ω–∞–ø–∏—Å–∞—Ç—å']):
                return ["–°–æ—Å—Ç–∞–≤–ª—è—é –ø–∏—Å—å–º–æ", "–û—Ç–ø—Ä–∞–≤–ª—è—é"]
            return ["–ò—â—É –ø–∏—Å—å–º–∞"]
        
        # Sheets / Data
        elif any(w in goal_lower for w in ['—Ç–∞–±–ª–∏—Ü', 'sheet', 'excel', '–¥–∞–Ω–Ω—ã']):
            if any(w in goal_lower for w in ['–∑–∞–ø–∏—à', '–¥–æ–±–∞–≤', '–∏–∑–º–µ–Ω', '–æ–±–Ω–æ–≤']):
                return ["–ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞—é –¥–∞–Ω–Ω—ã–µ", "–ó–∞–ø–∏—Å—ã–≤–∞—é –≤ —Ç–∞–±–ª–∏—Ü—É"]
            return ["–ó–∞–ø—Ä–∞—à–∏–≤–∞—é –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ç–∞–±–ª–∏—Ü—ã"]
        
        # Files / Documents
        elif any(w in goal_lower for w in ['—Ñ–∞–π–ª', '–¥–æ–∫—É–º–µ–Ω—Ç', '–æ—Ç–∫—Ä–æ–π', '–Ω–∞–π–¥–∏ —Ñ–∞–π–ª']):
            return ["–ò—â—É —Ñ–∞–π–ª—ã"]
        
        # 1C / Accounting
        elif any(w in goal_lower for w in ['1—Å', '1c', '–ø—Ä–æ–≤–æ–¥–∫', '–æ—Å—Ç–∞—Ç–∫', '–±—É—Ö–≥–∞–ª—Ç–µ—Ä', '—Å–∫–ª–∞–¥']):
            return ["–ó–∞–ø—Ä–∞—à–∏–≤–∞—é –¥–∞–Ω–Ω—ã–µ –∏–∑ 1–°"]
        
        # Project management
        elif any(w in goal_lower for w in ['–ø—Ä–æ–µ–∫—Ç', '–∑–∞–¥–∞—á', 'project', 'task']):
            return ["–ü–æ–ª—É—á–∞—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—Ä–æ–µ–∫—Ç–µ"]
        
        # Default - simple intent without fake progress
        return ["–û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å"]
    
    def _generate_task_description(self, goal: str) -> str:
        """
        Generate a high-level task description for the task-level intent.
        
        This is shown as the main intent header (Cursor-style).
        Unlike per-iteration intents, this describes the entire task goal.
        
        Args:
            goal: User's request/goal
            
        Returns:
            Human-readable task description
        """
        goal_lower = goal.lower()
        
        # Calendar / Meetings - use goal directly if it's specific
        if any(w in goal_lower for w in ['–≤—Å—Ç—Ä–µ—á', '—Å–æ–±—ã—Ç', '–∫–∞–ª–µ–Ω–¥–∞—Ä', 'meeting']):
            if any(w in goal_lower for w in ['—Å–æ–∑–¥–∞–π', '–∑–∞–ø–ª–∞–Ω–∏—Ä', '–Ω–∞–∑–Ω–∞—á—å']):
                # Extract email if present
                import re
                email_match = re.search(r'[\w\.-]+@[\w\.-]+', goal)
                if email_match:
                    return f"–°–æ–∑–¥–∞–Ω–∏–µ –≤—Å—Ç—Ä–µ—á–∏ —Å {email_match.group()}"
                return "–°–æ–∑–¥–∞–Ω–∏–µ –≤—Å—Ç—Ä–µ—á–∏"
            return "–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–æ–±—ã—Ç–∏–π –∫–∞–ª–µ–Ω–¥–∞—Ä—è"
        
        # Email
        elif any(w in goal_lower for w in ['–ø–∏—Å—å–º', '–ø–æ—á—Ç', 'email', 'gmail']):
            if any(w in goal_lower for w in ['–æ—Ç–ø—Ä–∞–≤', '–Ω–∞–ø–∏—à']):
                return "–û—Ç–ø—Ä–∞–≤–∫–∞ –ø–∏—Å—å–º–∞"
            return "–ü–æ–∏—Å–∫ –ø–∏—Å–µ–º"
        
        # Data / Sheets
        elif any(w in goal_lower for w in ['—Ç–∞–±–ª–∏—Ü', 'sheet', '–¥–∞–Ω–Ω—ã']):
            return "–†–∞–±–æ—Ç–∞ —Å —Ç–∞–±–ª–∏—Ü–µ–π"
        
        # Files
        elif any(w in goal_lower for w in ['—Ñ–∞–π–ª', '–¥–æ–∫—É–º–µ–Ω—Ç']):
            return "–ü–æ–∏—Å–∫ —Ñ–∞–π–ª–æ–≤"
        
        # 1C
        elif any(w in goal_lower for w in ['1—Å', '1c']):
            return "–ó–∞–ø—Ä–æ—Å –∫ 1–°"
        
        # Default - truncate goal if too long
        if len(goal) > 60:
            return goal[:57] + "..."
        return goal
    
    def _analyze_task_phases(self, goal: str) -> List[Dict[str, Any]]:
        """
        Analyze goal to identify multiple logical phases.
        
        Returns list of phases if task is multi-step, or empty list for single-step.
        Each phase has: {name, description, keywords, category}
        
        Args:
            goal: User's request/goal
            
        Returns:
            List of phases or empty list if single-step task
        """
        # #region agent log - H1,H2: Analyze task phases entry
        import json as _json; open('/Users/Dima/universal-multiagent/.cursor/debug.log', 'a').write(_json.dumps({"location": "_analyze_task_phases:entry", "message": "Analyzing task phases", "data": {"goal": goal[:200], "goal_length": len(goal)}, "timestamp": int(time.time()*1000), "sessionId": "debug-session", "hypothesisId": "H1,H2"}) + '\n')
        # #endregion
        
        goal_lower = goal.lower()
        phases = []
        
        # Define phase categories with their detection keywords
        # IMPORTANT: Order matters - more specific patterns should come first
        phase_definitions = [
            {
                'name': 'data_1c',
                # REMOVED '–∑–∞—Ä–ø–ª–∞—Ç' and '—Å–æ—Ç—Ä—É–¥–Ω–∏–∫' - too ambiguous, can appear in table names
                # Only detect 1C when explicitly mentioned or with accounting context
                'keywords': ['1—Å', '1c', '–±—É—Ö–≥–∞–ª—Ç–µ—Ä', 'odata'],
                'description': 'üìä –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ 1–°',
                'category': 'accounting',
                'context_exclude': ['–∑–∞–ø–∏—à', '–∑–∞–ø–∏—à–∏', '—Å–æ–∑–¥–∞–π', '—Ç–∞–±–ª–∏—Ü', '–≤ —Ç–∞–±–ª–∏—Ü']  # If these words present, NOT 1C read
            },
            {
                'name': 'email_read',
                'keywords': ['–ø–∏—Å—å–º', '–ø–æ—á—Ç', 'email', 'gmail', 'inbox', '–Ω–∞–π–¥–∏ –ø–∏—Å—å–º'],
                'description': 'üìß –ü–æ–∏—Å–∫ –∏ —á—Ç–µ–Ω–∏–µ –ø–∏—Å–µ–º',
                'category': 'email_read'
            },
            {
                'name': 'email_send',
                'keywords': ['–æ—Ç–ø—Ä–∞–≤', '–Ω–∞–ø–∏—à', 'send', '–ø–æ–¥—Ç–≤–µ—Ä–∂–¥'],
                'description': 'üìß –û—Ç–ø—Ä–∞–≤–∫–∞ –ø–∏—Å—å–º–∞',
                'category': 'email_send'
            },
            {
                'name': 'calendar_read',
                'keywords': ['–ø–æ–∫–∞–∂–∏ –≤—Å—Ç—Ä–µ—á', '—Å–æ–±—ã—Ç', '—Å–≤–æ–±–æ–¥–Ω', '–∑–∞–Ω—è—Ç', 'calendar'],
                'description': 'üìÖ –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞–ª–µ–Ω–¥–∞—Ä—è',
                'category': 'calendar_read'
            },
            {
                'name': 'calendar_create',
                'keywords': ['—Å–æ–∑–¥–∞–π –≤—Å—Ç—Ä–µ—á', '–∑–∞–ø–ª–∞–Ω–∏—Ä', '–Ω–∞–∑–Ω–∞—á—å', '–∑–∞–±—Ä–æ–Ω–∏—Ä', '—Å–æ–∑–¥–∞–π –∑–∞–¥–∞—á'],
                'description': 'üìÖ –°–æ–∑–¥–∞–Ω–∏–µ —Å–æ–±—ã—Ç–∏—è',
                'category': 'calendar_create'
            },
            {
                'name': 'sheets_write',
                'keywords': ['–∑–∞–ø–∏—à', '–∑–∞–ø–∏—à–∏', '–∑–∞–ø–∏—Å–∞—Ç—å', '–∑–∞–ø–∏—à', '–∑–∞–ø–∏—Å—å –≤', '–≤ —Ç–∞–±–ª–∏—Ü', '–∑–∞–ø–∏—Å–∞—Ç—å –≤ —Ç–∞–±–ª–∏—Ü'],
                'description': 'üìã –ó–∞–ø–∏—Å—å –≤ —Ç–∞–±–ª–∏—Ü—É',
                'category': 'sheets_write'
            },
            {
                'name': 'sheets_create',
                'keywords': ['—Å–æ–∑–¥–∞–π —Ç–∞–±–ª–∏—Ü', '–Ω–æ–≤—É—é —Ç–∞–±–ª–∏—Ü', 'create sheet'],
                'description': 'üìã –°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã',
                'category': 'sheets_create'
            },
            {
                'name': 'sheets_read',
                'keywords': ['—Ç–∞–±–ª–∏—Ü', 'sheet', '–ø–æ–ª—É—á–∏ –¥–∞–Ω–Ω—ã', '—á–∏—Ç–∞–π —Ç–∞–±–ª–∏—Ü', '—á–∏—Ç–∞–π sheet'],
                'description': 'üìã –ß—Ç–µ–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã',
                'category': 'sheets_read'
            },
            {
                'name': 'code_execute',
                'keywords': ['–∫–æ–¥', 'python', '–ø–∏—Ç–æ–Ω', 'script', '—Ä–∞—Å—á–µ—Ç', '–≤—ã—á–∏—Å–ª', '—Å–∫—Ä–∏–ø—Ç'],
                'description': 'üêç –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∫–æ–¥–∞',
                'category': 'code'
            },
            {
                'name': 'chart_create',
                'keywords': ['–¥–∏–∞–≥—Ä–∞–º–º', '–≥—Ä–∞—Ñ–∏–∫', 'chart', 'graph', '–≤–∏–∑—É–∞–ª–∏–∑', '–ø–æ—Å—Ç—Ä–æ'],
                'description': 'üìà –°–æ–∑–¥–∞–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–∞',
                'category': 'visualization'
            },
            {
                'name': 'file_search',
                'keywords': ['—Ñ–∞–π–ª', '–¥–æ–∫—É–º–µ–Ω—Ç', '–Ω–∞–π–¥–∏', '–æ—Ç–∫—Ä–æ–π', '—Ç–µ–∫—Å—Ç', '—Å–∫–∞–∑–∫', '–≤–æ–∑—å–º–∏ —Ç–µ–∫—Å—Ç', '—á–∏—Ç–∞–π –¥–æ–∫—É–º–µ–Ω—Ç', 'read_document'],
                'description': 'üìÅ –ü–æ–∏—Å–∫ –∏ —á—Ç–µ–Ω–∏–µ —Ñ–∞–π–ª–æ–≤',
                'category': 'files'
            },
        ]
        
        # Detect which phases are present in the goal
        matched_keywords = {}
        for phase_def in phase_definitions:
            matched_kw = [kw for kw in phase_def['keywords'] if kw in goal_lower]
            if matched_kw:
                # Context exclusion check: if phase has context_exclude and any of those words present, skip
                if 'context_exclude' in phase_def:
                    if any(exclude_kw in goal_lower for exclude_kw in phase_def['context_exclude']):
                        # Skip this phase - context indicates it's not applicable
                        continue
                
                phases.append({
                    'name': phase_def['name'],
                    'description': phase_def['description'],
                    'category': phase_def['category'],
                    'keywords': phase_def['keywords']
                })
                matched_keywords[phase_def['name']] = matched_kw
        
        # #region agent log - H1,H2: Phase detection results
        import json as _json; open('/Users/Dima/universal-multiagent/.cursor/debug.log', 'a').write(_json.dumps({"location": "_analyze_task_phases:matched", "message": "Phase detection results", "data": {"phases_count": len(phases), "phases": [{"name": p['name'], "category": p['category'], "description": p['description']} for p in phases], "matched_keywords": matched_keywords}, "timestamp": int(time.time()*1000), "sessionId": "debug-session", "hypothesisId": "H1,H2"}) + '\n')
        # #endregion
        
        # Check for explicit multi-step patterns
        explicit_multi_step = any(pattern in goal_lower for pattern in [
            '–ø–æ –æ—á–µ—Ä–µ–¥–∏', '–ø–æ—Ç–æ–º', '–∑–∞—Ç–µ–º', '–¥–∞–ª–µ–µ', '–ø–æ—Å–ª–µ —ç—Ç–æ–≥–æ',
            '—à–∞–≥ 1', '—à–∞–≥ 2', '1.', '2.', '1)', '2)',
            '—Å–Ω–∞—á–∞–ª–∞', '–≤ –ø–µ—Ä–≤—É—é –æ—á–µ—Ä–µ–¥—å', '–≤–æ-–ø–µ—Ä–≤—ã—Ö',
        ])
        
        # Only return phases if:
        # 1. Multiple different categories detected, OR
        # 2. Explicit multi-step pattern found
        unique_categories = set(p['category'] for p in phases)
        if len(unique_categories) >= 2 or (explicit_multi_step and len(phases) >= 1):
            # Remove duplicates within same category, keep first
            seen_categories = set()
            unique_phases = []
            for phase in phases:
                if phase['category'] not in seen_categories:
                    seen_categories.add(phase['category'])
                    unique_phases.append(phase)
            
            # Sort phases by order of appearance in goal (earliest keyword first)
            def get_first_keyword_position(phase):
                positions = []
                for kw in phase['keywords']:
                    pos = goal_lower.find(kw)
                    if pos >= 0:
                        positions.append(pos)
                return min(positions) if positions else 9999
            
            unique_phases.sort(key=get_first_keyword_position)
            
            return unique_phases
        
        return []  # Single-step task
    
    def _get_tool_category(self, tool_name: str) -> str:
        """
        Get category of a tool for phase tracking.
        
        Args:
            tool_name: Internal tool name
            
        Returns:
            Category string (e.g., 'email', 'calendar', 'sheets', 'accounting', 'code')
        """
        tool_categories = {
            # 1C / Accounting
            'onec_get_data': 'accounting',
            'onec_execute_query': 'accounting',
            'onec_list_catalogs': 'accounting',
            
            # Email
            'gmail_search': 'email_read',
            'gmail_get_message': 'email_read',
            'gmail_list_messages': 'email_read',
            'gmail_send_email': 'email_send',
            
            # Calendar
            'calendar_list_events': 'calendar_read',
            'calendar_get_event': 'calendar_read',
            'calendar_create_event': 'calendar_create',
            'calendar_update_event': 'calendar_create',
            'calendar_delete_event': 'calendar_create',
            
            # Sheets - MCP tool names
            'sheets_create': 'sheets_create',
            'sheets_read_range': 'sheets_read',
            'sheets_write_range': 'sheets_write',
            'sheets_batch_update': 'sheets_write',
            # Sheets - LangChain tool names (actual names used by LLM)
            'get_sheet_data': 'sheets_read',
            'add_rows': 'sheets_write',
            'update_cells': 'sheets_write',
            'create_spreadsheet': 'sheets_create',
            'get_spreadsheet_info': 'sheets_read',
            'format_cells': 'sheets_write',
            'auto_resize_columns': 'sheets_write',
            'merge_cells': 'sheets_write',
            
            # Code execution
            'code_execute': 'code',
            'python_execute': 'code',
            'execute_python': 'code',
            
            # Files / Documents
            'workspace_search_files': 'files',
            'drive_search': 'files',
            'drive_get_file': 'files',
            'find_and_open_file': 'files',
            'file_search': 'files',
            'read_document': 'files',  # Google Docs reading
            'docs_read': 'files',
            
            # Charts / Visualization
            'create_chart': 'visualization',
            'slides_create': 'visualization',
        }
        
        # Normalize tool name and check
        tool_lower = tool_name.lower()
        
        # Direct match
        if tool_lower in tool_categories:
            return tool_categories[tool_lower]
        
        # Prefix match
        for key, category in tool_categories.items():
            if tool_lower.startswith(key.split('_')[0]):
                return category
        
        return 'general'
    
    def _get_phase_description_for_category(self, category: str) -> str:
        """Get human-readable phase description for a tool category."""
        category_descriptions = {
            'accounting': 'üìä –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ 1–°',
            'email_read': 'üìß –ü–æ–∏—Å–∫ –∏ —á—Ç–µ–Ω–∏–µ –ø–∏—Å–µ–º',
            'email_send': 'üìß –û—Ç–ø—Ä–∞–≤–∫–∞ –ø–∏—Å—å–º–∞',
            'calendar_read': 'üìÖ –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞–ª–µ–Ω–¥–∞—Ä—è',
            'calendar_create': 'üìÖ –°–æ–∑–¥–∞–Ω–∏–µ —Å–æ–±—ã—Ç–∏—è',
            'sheets_create': 'üìã –°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã',
            'sheets_read': 'üìã –ß—Ç–µ–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã',
            'sheets_write': 'üìã –ó–∞–ø–∏—Å—å –≤ —Ç–∞–±–ª–∏—Ü—É',
            'files': 'üìÅ –ü–æ–∏—Å–∫ –∏ —á—Ç–µ–Ω–∏–µ —Ñ–∞–π–ª–æ–≤',
            'code': 'üêç –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∫–æ–¥–∞',
            'visualization': 'üìà –°–æ–∑–¥–∞–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–∞',
            'files': 'üìÅ –ü–æ–∏—Å–∫ —Ñ–∞–π–ª–æ–≤',
        }
        return category_descriptions.get(category, '‚öôÔ∏è –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –¥–µ–π—Å—Ç–≤–∏—è')
    
    def _get_tool_display_name(self, tool_name: str, args: Dict[str, Any]) -> str:
        """
        Get human-readable display name for tool execution.
        
        Converts internal tool names to user-friendly descriptions.
        
        Args:
            tool_name: Internal tool name (e.g., "calendar_list_events")
            args: Tool arguments
            
        Returns:
            Human-readable description (e.g., "üìÖ –ü–æ–ª—É—á–∞—é —Å–æ–±—ã—Ç–∏—è –∏–∑ –∫–∞–ª–µ–Ω–¥–∞—Ä—è")
        """
        tool_map = {
            # Calendar
            'calendar_list_events': 'üìÖ –ü–æ–ª—É—á–∞—é —Å–æ–±—ã—Ç–∏—è –∏–∑ –∫–∞–ª–µ–Ω–¥–∞—Ä—è',
            'calendar_create_event': 'üìÖ –°–æ–∑–¥–∞—é –≤—Å—Ç—Ä–µ—á—É',
            'calendar_update_event': 'üìÖ –û–±–Ω–æ–≤–ª—è—é —Å–æ–±—ã—Ç–∏–µ',
            'calendar_delete_event': 'üìÖ –£–¥–∞–ª—è—é —Å–æ–±—ã—Ç–∏–µ',
            'calendar_get_event': 'üìÖ –ü–æ–ª—É—á–∞—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–æ–±—ã—Ç–∏–∏',
            
            # Gmail
            'gmail_search': 'üìß –ò—â—É –ø–∏—Å—å–º–∞',
            'gmail_send_email': 'üìß –û—Ç–ø—Ä–∞–≤–ª—è—é –ø–∏—Å—å–º–æ',
            'gmail_get_message': 'üìß –ß–∏—Ç–∞—é –ø–∏—Å—å–º–æ',
            'gmail_list_messages': 'üìß –ü–æ–ª—É—á–∞—é —Å–ø–∏—Å–æ–∫ –ø–∏—Å–µ–º',
            
            # Sheets
            'sheets_read_range': 'üìä –ß–∏—Ç–∞—é –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ç–∞–±–ª–∏—Ü—ã',
            'sheets_write_range': 'üìä –ó–∞–ø–∏—Å—ã–≤–∞—é –¥–∞–Ω–Ω—ã–µ –≤ —Ç–∞–±–ª–∏—Ü—É',
            'sheets_append_rows': 'üìä –î–æ–±–∞–≤–ª—è—é —Å—Ç—Ä–æ–∫–∏ –≤ —Ç–∞–±–ª–∏—Ü—É',
            'sheets_get_spreadsheet': 'üìä –ü–æ–ª—É—á–∞—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–∞–±–ª–∏—Ü–µ',
            
            # Docs
            'docs_read': 'üìÑ –ß–∏—Ç–∞—é –¥–æ–∫—É–º–µ–Ω—Ç',
            'docs_create': 'üìÑ –°–æ–∑–¥–∞—é –¥–æ–∫—É–º–µ–Ω—Ç',
            'docs_update': 'üìÑ –û–±–Ω–æ–≤–ª—è—é –¥–æ–∫—É–º–µ–Ω—Ç',
            
            # Files / Workspace
            'workspace_search_files': 'üìÅ –ò—â—É —Ñ–∞–π–ª—ã',
            'workspace_find_and_open_file': 'üìÅ –û—Ç–∫—Ä—ã–≤–∞—é —Ñ–∞–π–ª',
            'workspace_get_file_info': 'üìÅ –ü–æ–ª—É—á–∞—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ñ–∞–π–ª–µ',
            
            # Slides
            'slides_create': 'üé® –°–æ–∑–¥–∞—é –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏—é',
            'slides_create_slide': 'üé® –î–æ–±–∞–≤–ª—è—é —Å–ª–∞–π–¥',
            
            # 1C
            'onec_get_data': 'üè¢ –ó–∞–ø—Ä–∞—à–∏–≤–∞—é –¥–∞–Ω–Ω—ã–µ –∏–∑ 1–°',
            'onec_query': 'üè¢ –í—ã–ø–æ–ª–Ω—è—é –∑–∞–ø—Ä–æ—Å –∫ 1–°',
        }
        
        # Get base action name
        base_name = tool_map.get(tool_name)
        
        if not base_name:
            # Fallback: convert snake_case to readable format
            readable = tool_name.replace('_', ' ').title()
            base_name = f"üîß {readable}"
        
        # Add context from arguments if available
        if 'query' in args:
            query = str(args['query'])
            if len(query) < 40:
                return f"{base_name} ¬´{query}¬ª"
        elif 'summary' in args:
            summary = str(args['summary'])
            if len(summary) < 40:
                return f"{base_name} ¬´{summary}¬ª"
        elif 'title' in args:
            title = str(args['title'])
            if len(title) < 40:
                return f"{base_name} ¬´{title}¬ª"
        elif 'attendees' in args:
            attendees = args['attendees']
            if isinstance(attendees, list) and attendees:
                first_attendee = str(attendees[0])
                if '@' in first_attendee:
                    return f"{base_name} —Å {first_attendee}"
        
        return base_name
    
    def _get_result_summary(self, tool_name: str, result: Any) -> Optional[str]:
        """
        Generate human-readable summary of tool execution result.
        
        Args:
            tool_name: Name of the executed tool
            result: Result from tool execution
            
        Returns:
            Summary string or None if no meaningful summary
        """
        if result is None:
            return None
            
        result_str = str(result)
        
        # Check for error indicators
        if any(err in result_str.lower() for err in ['error', '–æ—à–∏–±–∫–∞', '–Ω–µ —É–¥–∞–ª–æ—Å—å', 'failed', '–Ω–µ –Ω–∞–π–¥–µ–Ω']):
            # Extract first line of error
            first_line = result_str.split('\n')[0][:80]
            return f"‚ùå {first_line}"
        
        # Check for success indicators
        if any(ok in result_str.lower() for ok in ['—Å–æ–∑–¥–∞–Ω', 'created', '—É—Å–ø–µ—à–Ω–æ', 'success', '–Ω–∞–π–¥–µ–Ω', 'found']):
            first_line = result_str.split('\n')[0][:80]
            return f"‚úÖ {first_line}"
        
        # Tool-specific summaries
        if 'calendar' in tool_name:
            if 'events' in result_str.lower() or '—Å–æ–±—ã—Ç–∏–π' in result_str.lower():
                return f"‚úÖ –ü–æ–ª—É—á–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ –∫–∞–ª–µ–Ω–¥–∞—Ä—è"
            if 'slot' in result_str.lower() or '—Å–ª–æ—Ç' in result_str.lower():
                return f"‚úÖ –ù–∞–π–¥–µ–Ω —Å–≤–æ–±–æ–¥–Ω—ã–π —Å–ª–æ—Ç"
        
        if 'gmail' in tool_name or 'email' in tool_name:
            if '–æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ' in result_str.lower() or 'sent' in result_str.lower():
                return f"‚úÖ –ü–∏—Å—å–º–æ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ"
            return f"‚úÖ –ü–æ–ª—É—á–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ –ø–æ—á—Ç—ã"
        
        if 'sheets' in tool_name:
            return f"‚úÖ –î–∞–Ω–Ω—ã–µ —Ç–∞–±–ª–∏—Ü—ã –ø–æ–ª—É—á–µ–Ω—ã"
        
        # Generic success for non-empty result
        if len(result_str) > 10:
            return f"‚úÖ –í—ã–ø–æ–ª–Ω–µ–Ω–æ"
        
        return None
    
    class StreamingThoughtParser:
        """–ü–∞—Ä—Å–∏—Ç thought –∏–∑ —Å—Ç—Ä–∏–º–∞ –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –ø–æ WebSocket."""
        
        def __init__(self, ws_manager: WebSocketManager, session_id: str):
            self.ws_manager = ws_manager
            self.session_id = session_id
            self.buffer = ""
            self.thought_started = False
            self.thought_complete = False
            self.thought_content = ""
            self.thinking_id = f"thinking_{session_id}_{int(time.time() * 1000)}"
        
        async def process_chunk(self, chunk: str) -> None:
            """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç chunk, –∏–∑–≤–ª–µ–∫–∞–µ—Ç thought –∏ —Å—Ç—Ä–∏–º–∏—Ç."""
            self.buffer += chunk
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞—á–∞–ª–æ thought
            if "<thought>" in self.buffer and not self.thought_started:
                self.thought_started = True
                await self.ws_manager.send_event(
                    self.session_id,
                    "thinking_started",
                    {"thinking_id": self.thinking_id}
                )
                # –£–¥–∞–ª—è–µ–º –æ—Ç–∫—Ä—ã–≤–∞—é—â–∏–π —Ç–µ–≥ –∏–∑ –±—É—Ñ–µ—Ä–∞
                self.buffer = self.buffer.replace("<thought>", "", 1)
            
            # –ï—Å–ª–∏ thought –Ω–∞—á–∞–ª—Å—è, –∏–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç
            if self.thought_started and not self.thought_complete:
                # –ò—â–µ–º –∑–∞–∫—Ä—ã–≤–∞—é—â–∏–π —Ç–µ–≥
                if "</thought>" in self.buffer:
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç –¥–æ –∑–∞–∫—Ä—ã–≤–∞—é—â–µ–≥–æ —Ç–µ–≥–∞
                    parts = self.buffer.split("</thought>", 1)
                    thought_chunk = parts[0]
                    self.thought_content += thought_chunk
                    
                    # –°—Ç—Ä–∏–º–∏–º –ø–æ—Å–ª–µ–¥–Ω–∏–π chunk
                    if thought_chunk.strip():
                        await self.ws_manager.send_event(
                            self.session_id,
                            "thinking_chunk",
                            {
                                "thinking_id": self.thinking_id,
                                "chunk": thought_chunk
                            }
                        )
                    
                    self.thought_complete = True
                    await self.ws_manager.send_event(
                        self.session_id,
                        "thinking_completed",
                        {"thinking_id": self.thinking_id}
                    )
                    
                    # –û—Å—Ç–∞–≤–ª—è–µ–º –æ—Å—Ç–∞—Ç–æ–∫ –±—É—Ñ–µ—Ä–∞ (action —á–∞—Å—Ç—å)
                    self.buffer = parts[1] if len(parts) > 1 else ""
                else:
                    # –ï—â—ë –Ω–µ—Ç –∑–∞–∫—Ä—ã–≤–∞—é—â–µ–≥–æ —Ç–µ–≥–∞, —Å—Ç—Ä–∏–º–∏–º –≤–µ—Å—å –±—É—Ñ–µ—Ä
                    # –ù–æ –Ω—É–∂–Ω–æ —Å—Ç—Ä–∏–º–∏—Ç—å —Ç–æ–ª—å–∫–æ –Ω–æ–≤—ã–µ —á–∞—Å—Ç–∏
                    if len(self.buffer) > len(self.thought_content):
                        new_chunk = self.buffer[len(self.thought_content):]
                        self.thought_content = self.buffer
                        if new_chunk.strip():
                            await self.ws_manager.send_event(
                                self.session_id,
                                "thinking_chunk",
                                {
                                    "thinking_id": self.thinking_id,
                                    "chunk": new_chunk
                                }
                            )
        
        def get_thought(self) -> str:
            """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–∑–≤–ª–µ—á—ë–Ω–Ω—ã–π thought."""
            return self.thought_content.strip()
        
        def get_remaining_buffer(self) -> str:
            """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ—Å—Ç–∞–≤—à–∏–π—Å—è –±—É—Ñ–µ—Ä (action —á–∞—Å—Ç—å)."""
            return self.buffer
    
    async def _think(
        self,
        state: ReActState,
        context: ConversationContext,
        file_ids: List[str]
    ) -> str:
        """Generate thought about current situation."""
        context_str = f"–¶–µ–ª—å: {state.goal}\n\n"
        
        # Add conversation history for reference resolution (NEW)
        if hasattr(context, 'messages') and context.messages:
            recent_messages = context.messages[-4:]  # Last 2 exchanges
            if recent_messages:
                context_str += "üìù –ö–æ–Ω—Ç–µ–∫—Å—Ç —Ä–∞–∑–≥–æ–≤–æ—Ä–∞ (–¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–æ–≤):\n"
                for msg in recent_messages:
                    role = "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å" if msg.get('role') == 'user' else "–ê—Å—Å–∏—Å—Ç–µ–Ω—Ç"
                    content = msg.get('content', '')[:300]  # Truncate
                    context_str += f"  {role}: {content}\n"
                context_str += "\n"
        
        # Add file context (uploaded files have PRIORITY #1)
        if file_ids:
            uploaded_files_found = []
            for file_id in file_ids:
                file_data = context.get_file(file_id)
                if file_data:
                    uploaded_files_found.append(file_data)
            if uploaded_files_found:
                context_str += "üìé –ü—Ä–∏–∫—Ä–µ–ø–ª–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã:\n"
                for file_data in uploaded_files_found:
                    filename = file_data.get('filename', 'unknown')
                    file_type = file_data.get('type', '')
                    if file_type == 'application/pdf' and 'text' in file_data:
                        pdf_text = file_data.get('text', '')
                        max_len = 8000  # Increased for better analysis
                        if len(pdf_text) > max_len:
                            pdf_text = pdf_text[:max_len] + "\n... (–æ–±—Ä–µ–∑–∞–Ω–æ, –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç " + str(len(file_data.get('text', ''))) + " —Å–∏–º–≤–æ–ª–æ–≤)"
                        context_str += f"- PDF: {filename}\n{pdf_text}\n"
                    elif file_type in ("application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                                      "application/msword") and 'text' in file_data:
                        docx_text = file_data.get('text', '')
                        max_len = 8000  # Increased for better analysis
                        if len(docx_text) > max_len:
                            docx_text = docx_text[:max_len] + "\n... (–æ–±—Ä–µ–∑–∞–Ω–æ, –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç " + str(len(file_data.get('text', ''))) + " —Å–∏–º–≤–æ–ª–æ–≤)"
                        context_str += f"- Word –¥–æ–∫—É–º–µ–Ω—Ç: {filename}\n{docx_text}\n"
                    else:
                        context_str += f"- {filename}\n"
        
        # Add open files context (PRIORITY #2)
        # #region debug log - hypothesis H2, H4: –ø—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –æ—Ç–∫—Ä—ã—Ç—ã—Ö —Ñ–∞–π–ª–æ–≤ –≤ _think
        import json
        import time
        open_files = context.get_open_files() if hasattr(context, 'get_open_files') else []
        log_data_think = {
            "location": "unified_react_engine.py:1350",
            "message": "H2,H4: _think - open_files from context",
            "data": {
                "has_get_open_files": hasattr(context, 'get_open_files'),
                "open_files_count": len(open_files),
                "open_files": open_files,
                "open_files_details": [
                    {
                        "type": f.get('type'),
                        "title": f.get('title'),
                        "document_id": f.get('document_id'),
                        "spreadsheet_id": f.get('spreadsheet_id'),
                        "url": f.get('url')
                    }
                    for f in open_files
                ]
            },
            "timestamp": time.time() * 1000,
            "sessionId": self.session_id,
            "runId": "run1",
            "hypothesisId": "H2,H4"
        }
        try:
            with open("/Users/Dima/universal-multiagent/.cursor/debug.log", "a") as f:
                f.write(json.dumps(log_data_think, default=str) + "\n")
        except Exception:
            pass
        # #endregion
        
        if open_files:
            context_str += "\nüìÇ –û–¢–ö–†–´–¢–´–ï –§–ê–ô–õ–´ –í –†–ê–ë–û–ß–ï–ô –û–ë–õ–ê–°–¢–ò:\n"
            for file in open_files:
                file_type = file.get('type')
                title = file.get('title', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')
                
                if file_type == 'sheets':
                    spreadsheet_id = file.get('spreadsheet_id') or file.get('spreadsheetId')
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º ID –∏–∑ URL, –µ—Å–ª–∏ –Ω–µ—Ç –≤ –¥–∞–Ω–Ω—ã—Ö
                    if not spreadsheet_id and file.get('url'):
                        url_match = re.search(r'/spreadsheets/d/([a-zA-Z0-9-_]+)', file.get('url', ''))
                        if url_match:
                            spreadsheet_id = url_match.group(1)
                    
                    if spreadsheet_id:
                        context_str += f"- üìä –¢–∞–±–ª–∏—Ü–∞: {title} (ID: {spreadsheet_id})\n"
                        context_str += f"  –ò—Å–ø–æ–ª—å–∑—É–π: sheets_read_range —Å spreadsheetId={spreadsheet_id}\n"
                elif file_type == 'docs':
                    document_id = file.get('document_id') or file.get('documentId')
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º ID –∏–∑ URL, –µ—Å–ª–∏ –Ω–µ—Ç –≤ –¥–∞–Ω–Ω—ã—Ö
                    if not document_id and file.get('url'):
                        url_match = re.search(r'/document/d/([a-zA-Z0-9-_]+)', file.get('url', ''))
                        if url_match:
                            document_id = url_match.group(1)
                    
                    if document_id:
                        context_str += f"- üìÑ –î–æ–∫—É–º–µ–Ω—Ç: {title} (ID: {document_id})\n"
                        context_str += f"  –ò—Å–ø–æ–ª—å–∑—É–π: read_document —Å documentId={document_id}\n"
            
            context_str += "\n‚ö†Ô∏è –í–ê–ñ–ù–û: –§–∞–π–ª—ã –£–ñ–ï –æ—Ç–∫—Ä—ã—Ç—ã, –∏—Å–ø–æ–ª—å–∑—É–π –∏—Ö ID –Ω–∞–ø—Ä—è–º—É—é, –ù–ï –∏—â–∏ —á–µ—Ä–µ–∑ search!\n"
        
        # #region debug log - hypothesis H2: –ø—Ä–æ–≤–µ—Ä–∫–∞ —á—Ç–æ –¥–æ–±–∞–≤–ª—è–µ—Ç—Å—è –≤ –ø—Ä–æ–º–ø—Ç _think
        open_files_context_added_think = "üìÇ –û—Ç–∫—Ä—ã—Ç—ã–µ —Ñ–∞–π–ª—ã" in context_str if open_files else False
        log_data_think_prompt = {
            "location": "unified_react_engine.py:1380",
            "message": "H2: _think - context added to prompt",
            "data": {
                "open_files_in_context": open_files_context_added_think,
                "context_str_length": len(context_str),
                "context_str_snippet": context_str[-500:] if len(context_str) > 500 else context_str,
                "open_files_count_in_prompt": context_str.count("üìÇ –û—Ç–∫—Ä—ã—Ç—ã–µ —Ñ–∞–π–ª—ã") if open_files else 0
            },
            "timestamp": time.time() * 1000,
            "sessionId": self.session_id,
            "runId": "run1",
            "hypothesisId": "H2"
        }
        try:
            with open("/Users/Dima/universal-multiagent/.cursor/debug.log", "a") as f:
                f.write(json.dumps(log_data_think_prompt, default=str) + "\n")
        except Exception:
            pass
        # #endregion
        
        if state.action_history:
            context_str += "\n–í—ã–ø–æ–ª–Ω–µ–Ω–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è:\n"
            for i, action in enumerate(state.action_history[-5:], 1):
                obs = next((o for o in state.observations if o.action == action), None)
                status = "‚úì" if obs and obs.success else "‚úó"
                context_str += f"{i}. {status} {action.tool_name}\n"
        
        if state.observations:
            context_str += "\n–ü–æ—Å–ª–µ–¥–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã:\n"
            for obs in state.observations[-3:]:
                result_preview = str(obs.raw_result)[:200]
                context_str += f"- {obs.action.tool_name}: {result_preview}...\n"
        
        prompt = f"""–¢—ã –≤—ã–ø–æ–ª–Ω—è–µ—à—å –∑–∞–¥–∞—á—É –ø–æ—à–∞–≥–æ–≤–æ, –∏—Å–ø–æ–ª—å–∑—É—è –¥–æ—Å—Ç—É–ø–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã.

{context_str}

–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ç–µ–∫—É—â—É—é —Å–∏—Ç—É–∞—Ü–∏—é:
1. –ß—Ç–æ —É–∂–µ —Å–¥–µ–ª–∞–Ω–æ?
2. –ß—Ç–æ –æ—Å—Ç–∞–ª–æ—Å—å —Å–¥–µ–ª–∞—Ç—å –¥–ª—è –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è —Ü–µ–ª–∏?
3. –ö–∞–∫–æ–µ —Å–ª–µ–¥—É—é—â–µ–µ –¥–µ–π—Å—Ç–≤–∏–µ –±—É–¥–µ—Ç –Ω–∞–∏–±–æ–ª–µ–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–º?

–î–∞–π –∫—Ä–∞—Ç–∫–∏–π –∞–Ω–∞–ª–∏–∑ (2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è) –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ."""

        try:
            messages = [
                SystemMessage(content="–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É –∑–∞–¥–∞—á –∏ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—é –¥–µ–π—Å—Ç–≤–∏–π. –û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ."),
                HumanMessage(content=prompt)
            ]
            
            # Stream thinking process
            thought = ""
            thinking_id = f"thinking_{self.session_id}_{int(time.time() * 1000)}"
            
            # Send thinking start
            await self.ws_manager.send_event(
                self.session_id,
                "thinking_started",
                {"thinking_id": thinking_id}
            )
            
            async for chunk in self.llm.astream(messages):
                chunk_text = ""
                if hasattr(chunk, 'content') and chunk.content:
                    if isinstance(chunk.content, list):
                        for block in chunk.content:
                            if hasattr(block, "text"):
                                chunk_text += block.text
                            elif isinstance(block, dict) and "text" in block:
                                chunk_text += block["text"]
                            elif isinstance(block, str):
                                chunk_text += block
                    elif isinstance(chunk.content, str):
                        chunk_text = chunk.content
                elif isinstance(chunk, str):
                    chunk_text = chunk
                
                if chunk_text:
                    thought += chunk_text
                    await self.ws_manager.send_event(
                        self.session_id,
                        "thinking_chunk",
                        {
                            "thinking_id": thinking_id,
                            "chunk": chunk_text  # Frontend expects "chunk" not "content"
                        }
                    )
            
            # Complete thinking
            await self.ws_manager.send_event(
                self.session_id,
                "thinking_completed",
                {"thinking_id": thinking_id}
            )
            
            return thought.strip()
        except Exception as e:
            logger.error(f"[UnifiedReActEngine] Error in _think: {e}")
            return f"–ê–Ω–∞–ª–∏–∑–∏—Ä—É—é —Å–∏—Ç—É–∞—Ü–∏—é... (–∏—Ç–µ—Ä–∞—Ü–∏—è {state.iteration})"
    
    async def _plan_action(
        self,
        state: ReActState,
        thought: str,
        context: ConversationContext,
        file_ids: List[str]
    ) -> Dict[str, Any]:
        """Plan next action based on thought."""
        # Get capability descriptions (filtered by allowed categories)
        capability_descriptions = []
        for cap in self.capabilities[:50]:  # Limit to first 50
            capability_descriptions.append(f"- {cap.name}: {cap.description}")
        
        tools_str = "\n".join(capability_descriptions)
        
        # Build context
        context_str = f"–¶–µ–ª—å: {state.goal}\n\n"
        context_str += f"–¢–µ–∫—É—â–∏–π –∞–Ω–∞–ª–∏–∑: {thought}\n\n"
        
        # Add conversation history for reference resolution (NEW)
        if hasattr(context, 'messages') and context.messages:
            recent_messages = context.messages[-4:]  # Last 2 exchanges
            if recent_messages:
                context_str += "üìù –ö–æ–Ω—Ç–µ–∫—Å—Ç —Ä–∞–∑–≥–æ–≤–æ—Ä–∞ (–¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–æ–≤ —Ç–∏–ø–∞ '–µ–≥–æ', '—ç—Ç–æ', '–µ—â–µ'):\n"
                for msg in recent_messages:
                    role = "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å" if msg.get('role') == 'user' else "–ê—Å—Å–∏—Å—Ç–µ–Ω—Ç"
                    content = msg.get('content', '')[:300]  # Truncate
                    context_str += f"  {role}: {content}\n"
                context_str += "\n"
        
        if state.action_history:
            context_str += "–£–∂–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ:\n"
            for action in state.action_history[-3:]:
                context_str += f"- {action.tool_name}\n"
        
        # Add uploaded files context (PRIORITY #1) - must come FIRST
        if file_ids:
            uploaded_files_found = []
            for file_id in file_ids:
                file_data = context.get_file(file_id)
                if file_data:
                    uploaded_files_found.append(file_data)
            
            if uploaded_files_found:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–¥–¥–µ—Ä–∂–∫—É vision —É –º–æ–¥–µ–ª–∏
                model_supports_vision = supports_vision(self.model_name) if self.model_name else False
                
                context_str += "\nüìé –ü–†–ò–ö–†–ï–ü–õ–ï–ù–ù–´–ï –§–ê–ô–õ–´ (–ü–†–ò–û–†–ò–¢–ï–¢ #1 - –∏—Å–ø–æ–ª—å–∑—É–π –∏—Ö –ü–ï–†–í–´–ú!):\n"
                has_images = False
                for file_data in uploaded_files_found:
                    filename = file_data.get('filename', 'unknown')
                    file_type = file_data.get('type', '')
                    if file_type.startswith('image/'):
                        has_images = True
                        if model_supports_vision:
                            context_str += f"- –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {filename} (–£–ñ–ï –ü–ï–†–ï–î–ê–ù–û –í –≠–¢–û–ú –°–û–û–ë–©–ï–ù–ò–ò —á–µ—Ä–µ–∑ Vision API - –≤–∏–¥–∏—à—å –µ–≥–æ –ø—Ä—è–º–æ —Å–µ–π—á–∞—Å!)\n"
                        else:
                            context_str += f"- –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {filename} (–º–æ–¥–µ–ª—å –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç vision, –ø—Ä–æ–ø—É—â–µ–Ω–æ)\n"
                            logger.warning(f"Model {self.model_name} doesn't support vision, skipping image {filename}")
                    elif file_type == 'application/pdf' and 'text' in file_data:
                        pdf_text = file_data.get('text', '')
                        # Truncate if too long - increased limit for better analysis
                        max_len = 10000
                        if len(pdf_text) > max_len:
                            pdf_text = pdf_text[:max_len] + "\n... (—Ç–µ–∫—Å—Ç –æ–±—Ä–µ–∑–∞–Ω, –ø–æ–ª–Ω—ã–π —Ä–∞–∑–º–µ—Ä " + str(len(file_data.get('text', ''))) + " —Å–∏–º–≤–æ–ª–æ–≤)"
                        context_str += f"- PDF: {filename}\n--- –°–û–î–ï–†–ñ–ò–ú–û–ï PDF ---\n{pdf_text}\n--- –ö–û–ù–ï–¶ PDF ---\n"
                    elif file_type in ("application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                                      "application/msword") and 'text' in file_data:
                        docx_text = file_data.get('text', '')
                        # Truncate if too long - increased limit for better analysis
                        max_len = 10000
                        if len(docx_text) > max_len:
                            docx_text = docx_text[:max_len] + "\n... (—Ç–µ–∫—Å—Ç –æ–±—Ä–µ–∑–∞–Ω, –ø–æ–ª–Ω—ã–π —Ä–∞–∑–º–µ—Ä " + str(len(file_data.get('text', ''))) + " —Å–∏–º–≤–æ–ª–æ–≤)"
                        context_str += f"- Word –¥–æ–∫—É–º–µ–Ω—Ç: {filename}\n--- –°–û–î–ï–†–ñ–ò–ú–û–ï DOCX ---\n{docx_text}\n--- –ö–û–ù–ï–¶ DOCX ---\n"
                    else:
                        context_str += f"- {filename} ({file_type})\n"
                
                if has_images and model_supports_vision:
                    context_str += "\n‚ö†Ô∏è –ö–†–ò–¢–ò–ß–ù–û: –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –£–ñ–ï –ü–ï–†–ï–î–ê–ù–´ –≤ —ç—Ç–æ–º —Å–æ–æ–±—â–µ–Ω–∏–∏ —á–µ—Ä–µ–∑ Vision API! –¢—ã –≤–∏–¥–∏—à—å –∏—Ö –ø—Ä—è–º–æ —Å–µ–π—á–∞—Å! –ù–ï –∏—Å–ø–æ–ª—å–∑—É–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –¥–ª—è –∏—Ö –∞–Ω–∞–ª–∏–∑–∞ - –ø—Ä–æ—Å—Ç–æ –æ–ø–∏—à–∏ —á—Ç–æ –≤–∏–¥–∏—à—å –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö!\n"
                else:
                    context_str += "‚ö†Ô∏è –ù–ï –∏—â–∏ —ç—Ç–∏ —Ñ–∞–π–ª—ã –≤ Google Drive - –∏—Ö —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –£–ñ–ï –í–´–®–ï!\n"
        
        # Add open files context (PRIORITY #2)
        # #region debug log - hypothesis H1, H2, H4: –ø—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –æ—Ç–∫—Ä—ã—Ç—ã—Ö —Ñ–∞–π–ª–æ–≤ –≤ _plan_action
        import json
        import time
        open_files = context.get_open_files() if hasattr(context, 'get_open_files') else []
        log_data_plan = {
            "location": "unified_react_engine.py:1520",
            "message": "H1,H2,H4: _plan_action - open_files from context",
            "data": {
                "has_get_open_files": hasattr(context, 'get_open_files'),
                "open_files_count": len(open_files),
                "open_files": open_files,
                "open_files_details": [
                    {
                        "type": f.get('type'),
                        "title": f.get('title'),
                        "document_id": f.get('document_id'),
                        "spreadsheet_id": f.get('spreadsheet_id'),
                        "url": f.get('url')
                    }
                    for f in open_files
                ]
            },
            "timestamp": time.time() * 1000,
            "sessionId": self.session_id,
            "runId": "run1",
            "hypothesisId": "H1,H2,H4"
        }
        try:
            with open("/Users/Dima/universal-multiagent/.cursor/debug.log", "a") as f:
                f.write(json.dumps(log_data_plan, default=str) + "\n")
        except Exception:
            pass
        # #endregion
        
        if open_files:
            context_str += "\nüìÇ –û–¢–ö–†–´–¢–´–ï –§–ê–ô–õ–´ –í –†–ê–ë–û–ß–ï–ô –û–ë–õ–ê–°–¢–ò (–ü–†–ò–û–†–ò–¢–ï–¢ #2):\n"
            for file in open_files:
                file_type = file.get('type')
                title = file.get('title', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')
                
                if file_type == 'sheets':
                    spreadsheet_id = file.get('spreadsheet_id') or file.get('spreadsheetId')
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º ID –∏–∑ URL, –µ—Å–ª–∏ –Ω–µ—Ç –≤ –¥–∞–Ω–Ω—ã—Ö
                    if not spreadsheet_id and file.get('url'):
                        url_match = re.search(r'/spreadsheets/d/([a-zA-Z0-9-_]+)', file.get('url', ''))
                        if url_match:
                            spreadsheet_id = url_match.group(1)
                    
                    if spreadsheet_id:
                        context_str += f"- üìä –¢–∞–±–ª–∏—Ü–∞: {title}\n"
                        context_str += f"  ID: {spreadsheet_id}\n"
                        context_str += f"  URL: {file.get('url', 'N/A')}\n"
                        context_str += f"  ‚ö†Ô∏è –ò–°–ü–û–õ–¨–ó–£–ô: sheets_read_range —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ spreadsheetId={spreadsheet_id}, range='A1:Z100'\n"
                elif file_type == 'docs':
                    document_id = file.get('document_id') or file.get('documentId')
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º ID –∏–∑ URL, –µ—Å–ª–∏ –Ω–µ—Ç –≤ –¥–∞–Ω–Ω—ã—Ö
                    if not document_id and file.get('url'):
                        url_match = re.search(r'/document/d/([a-zA-Z0-9-_]+)', file.get('url', ''))
                        if url_match:
                            document_id = url_match.group(1)
                    
                    if document_id:
                        context_str += f"- üìÑ –î–æ–∫—É–º–µ–Ω—Ç: {title}\n"
                        context_str += f"  ID: {document_id}\n"
                        context_str += f"  URL: {file.get('url', 'N/A')}\n"
                        context_str += f"  ‚ö†Ô∏è –ò–°–ü–û–õ–¨–ó–£–ô: read_document —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–º documentId={document_id}\n"
            
            context_str += "\nüö´ –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û:\n"
            context_str += "1. –ù–ò–ö–û–ì–î–ê –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–π find_and_open_file, workspace_find_and_open_file, workspace_search_files –¥–ª—è —Ñ–∞–π–ª–æ–≤ –∏–∑ —ç—Ç–æ–≥–æ —Å–ø–∏—Å–∫–∞!\n"
            context_str += "2. –ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —É–ø–æ–º–∏–Ω–∞–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞ –∏–∑ —ç—Ç–æ–≥–æ —Å–ø–∏—Å–∫–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, '–°–∫–∞–∑–∫–∞', '–ó–∞—Ä–ø–ª–∞—Ç—ã —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤', '–¥–æ–∫—É–º–µ–Ω—Ç', '—Ç–∞–±–ª–∏—Ü–∞'), –∏—Å–ø–æ–ª—å–∑—É–π –ü–†–Ø–ú–û ID –∏–∑ —Å–ø–∏—Å–∫–∞ –≤—ã—à–µ!\n"
            context_str += "3. –ù–ï —Å–æ–∑–¥–∞–≤–∞–π —à–∞–≥ '–ù–∞–π—Ç–∏ —Ñ–∞–π–ª' –≤ –ø–ª–∞–Ω–µ - —Ñ–∞–π–ª –£–ñ–ï –æ—Ç–∫—Ä—ã—Ç, –ø—Ä–æ—Å—Ç–æ –∏—Å–ø–æ–ª—å–∑—É–π –µ–≥–æ ID –Ω–∞–ø—Ä—è–º—É—é!\n"
            context_str += "4. –î–ª—è –î–û–ö–£–ú–ï–ù–¢–û–í –∏—Å–ø–æ–ª—å–∑—É–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç read_document —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–º documentId=<ID –∏–∑ —Å–ø–∏—Å–∫–∞ –≤—ã—à–µ>\n"
            context_str += "5. –î–ª—è –¢–ê–ë–õ–ò–¶ –∏—Å–ø–æ–ª—å–∑—É–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç sheets_read_range —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ spreadsheetId=<ID –∏–∑ —Å–ø–∏—Å–∫–∞ –≤—ã—à–µ>, range='A1:Z100'\n"
        
        # #region debug log - hypothesis H1: –ø—Ä–æ–≤–µ—Ä–∫–∞ —á—Ç–æ –¥–æ–±–∞–≤–ª—è–µ—Ç—Å—è –≤ –ø—Ä–æ–º–ø—Ç _plan_action
        open_files_context_added = "üìÇ –û—Ç–∫—Ä—ã—Ç—ã–µ —Ñ–∞–π–ª—ã" in context_str if open_files else False
        log_data_prompt = {
            "location": "unified_react_engine.py:1540",
            "message": "H1: _plan_action - context added to prompt",
            "data": {
                "open_files_in_context": open_files_context_added,
                "context_str_length": len(context_str),
                "context_str_snippet": context_str[-500:] if len(context_str) > 500 else context_str,
                "open_files_count_in_prompt": context_str.count("üìÇ –û—Ç–∫—Ä—ã—Ç—ã–µ —Ñ–∞–π–ª—ã") if open_files else 0
            },
            "timestamp": time.time() * 1000,
            "sessionId": self.session_id,
            "runId": "run1",
            "hypothesisId": "H1"
        }
        try:
            with open("/Users/Dima/universal-multiagent/.cursor/debug.log", "a") as f:
                f.write(json.dumps(log_data_prompt, default=str) + "\n")
        except Exception:
            pass
        # #endregion
        
        prompt = f"""–¢—ã –ø–ª–∞–Ω–∏—Ä—É–µ—à—å —Å–ª–µ–¥—É—é—â–µ–µ –¥–µ–π—Å—Ç–≤–∏–µ –¥–ª—è –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è —Ü–µ–ª–∏.

{context_str}

–î–æ—Å—Ç—É–ø–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã:
{tools_str}

–í–ê–ñ–ù–û:
- –ï—Å–ª–∏ –ø–æ–ª—É—á–µ–Ω —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º —Å–æ–±—ã—Ç–∏–π/–¥–∞–Ω–Ω—ã—Ö, –Ω–æ –ë–ï–ó –¥–µ—Ç–∞–ª–µ–π (–Ω–∞–ø—Ä–∏–º–µ—Ä, "Found 10 events" –±–µ–∑ —Å–ø–∏—Å–∫–∞), 
  —ç—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ –Ω—É–∂–Ω–æ –ø–æ–ª—É—á–∏—Ç—å –î–ï–¢–ê–õ–ò —ç—Ç–∏—Ö –¥–∞–Ω–Ω—ã—Ö
- –ù–ï –∑–∞–≤–µ—Ä—à–∞–π –∑–∞–¥–∞—á—É, –ø–æ–∫–∞ –Ω–µ –ø–æ–ª—É—á–µ–Ω—ã –≤—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–µ—Ç–∞–ª–∏ –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
- –î–ª—è –∫–∞–ª–µ–Ω–¥–∞—Ä—è: –µ—Å–ª–∏ –ø–æ–ª—É—á–µ–Ω–æ —Ç–æ–ª—å–∫–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–±—ã—Ç–∏–π, –Ω—É–∂–Ω–æ –ø–æ–ª—É—á–∏—Ç—å –¥–µ—Ç–∞–ª–∏ –∫–∞–∂–¥–æ–≥–æ —Å–æ–±—ã—Ç–∏—è
- –î–ª—è —Ñ–∞–π–ª–æ–≤: –µ—Å–ª–∏ –ø–æ–ª—É—á–µ–Ω —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤, –Ω–æ –Ω—É–∂–Ω–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ - –ø–æ–ª—É—á–∏ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ
- –î–ª—è –ø–∏—Å–µ–º: –µ—Å–ª–∏ –ø–æ–ª—É—á–µ–Ω —Å–ø–∏—Å–æ–∫ –ø–∏—Å–µ–º, –Ω–æ –Ω—É–∂–Ω–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ - –ø–æ–ª—É—á–∏ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ

–ö–†–ò–¢–ò–ß–ù–û –î–õ–Ø –ü–†–ò–ö–†–ï–ü–õ–ï–ù–ù–´–• –§–ê–ô–õ–û–í:
- –ï—Å–ª–∏ –≤ –ø—Ä–∏–∫—Ä–µ–ø–ª–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–∞—Ö –µ—Å—Ç—å –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–Ø - –æ–Ω–∏ –£–ñ–ï –ü–ï–†–ï–î–ê–ù–´ –≤ —ç—Ç–æ–º —Å–æ–æ–±—â–µ–Ω–∏–∏ —á–µ—Ä–µ–∑ Vision API! 
  –¢—ã –≤–∏–¥–∏—à—å –∏—Ö –ø—Ä—è–º–æ —Å–µ–π—á–∞—Å! –ù–ï –∏—Å–ø–æ–ª—å–∑—É–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã —Ç–∏–ø–∞ "vision-api" –∏–ª–∏ "analyze_image" - –ø—Ä–æ—Å—Ç–æ –æ–ø–∏—à–∏ —á—Ç–æ –≤–∏–¥–∏—à—å!
- –ï—Å–ª–∏ –≤ –ø—Ä–∏–∫—Ä–µ–ø–ª–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–∞—Ö –µ—Å—Ç—å PDF –∏–ª–∏ DOCX - –∏—Ö –¢–ï–ö–°–¢ –£–ñ–ï –ü–†–ï–î–°–¢–ê–í–õ–ï–ù –í–´–®–ï –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ!
- –ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Å–ø—Ä–∞—à–∏–≤–∞–µ—Ç "—á—Ç–æ –≤ —Ñ–∞–π–ª–µ" –∏–ª–∏ "—á—Ç–æ –≤ —Ñ–∞–π–ª–∞—Ö" –∏ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–æ–≤ –£–ñ–ï –í–ò–î–ù–û (—Ç–µ–∫—Å—Ç PDF/DOCX –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –≤—ã—à–µ, –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —á–µ—Ä–µ–∑ Vision API), 
  —Ç–æ –∑–∞–¥–∞—á–∞ –£–ñ–ï –í–´–ü–û–õ–ù–ï–ù–ê - –∏—Å–ø–æ–ª—å–∑—É–π FINISH –∏ –æ–ø–∏—à–∏ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–æ–≤ –≤ –æ—Ç–≤–µ—Ç–µ!
- –ù–ï –∏—â–∏ —Ñ–∞–π–ª—ã –≤ Google Drive –∏–ª–∏ —Ä–∞–±–æ—á–µ–π –æ–±–ª–∞—Å—Ç–∏, –µ—Å–ª–∏ –æ–Ω–∏ —É–∂–µ –ø—Ä–∏–∫—Ä–µ–ø–ª–µ–Ω—ã –∏ –∏—Ö —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —É–∂–µ –≤–∏–¥–Ω–æ!

–í—ã–±–µ—Ä–∏ –û–î–ò–ù –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –∏ —É–∫–∞–∂–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –µ–≥–æ –≤—ã–∑–æ–≤–∞. –û—Ç–≤–µ—Ç—å –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON:
{{
    "tool_name": "–∏–º—è_–∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞",
    "arguments": {{"param1": "value1", "param2": "value2"}},
    "description": "–∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –¥–µ–π—Å—Ç–≤–∏—è",
    "reasoning": "–ø–æ—á–µ–º—É –≤—ã–±—Ä–∞–Ω–æ —ç—Ç–æ –¥–µ–π—Å—Ç–≤–∏–µ"
}}

–ï—Å–ª–∏ —Ü–µ–ª—å –ø–æ–ª–Ω–æ—Å—Ç—å—é –¥–æ—Å—Ç–∏–≥–Ω—É—Ç–∞ –∏ –ø–æ–ª—É—á–µ–Ω—ã –í–°–ï –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–µ—Ç–∞–ª–∏ –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é, –∏—Å–ø–æ–ª—å–∑—É–π —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π –º–∞—Ä–∫–µ—Ä:
{{
    "tool_name": "FINISH",
    "arguments": {{}},
    "description": "–∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–Ω–æ–π –∑–∞–¥–∞—á–∏",
    "reasoning": "–ø–æ—á–µ–º—É –∑–∞–¥–∞—á–∞ —Å—á–∏—Ç–∞–µ—Ç—Å—è –≤—ã–ø–æ–ª–Ω–µ–Ω–Ω–æ–π (—É–∫–∞–∂–∏, –∫–∞–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –ø–æ–ª—É—á–µ–Ω—ã)"
}}

–û–°–û–ë–ï–ù–ù–û: –ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Å–ø—Ä–∞—à–∏–≤–∞–µ—Ç –æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º –ø—Ä–∏–∫—Ä–µ–ø–ª–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤, –∏ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –£–ñ–ï –í–ò–î–ù–û (—Ç–µ–∫—Å—Ç PDF/DOCX –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –≤—ã—à–µ, –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —á–µ—Ä–µ–∑ Vision API), 
–∏—Å–ø–æ–ª—å–∑—É–π FINISH –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ - –Ω–µ –∏—â–∏ —Ñ–∞–π–ª—ã –≤ –¥—Ä—É–≥–∏—Ö –º–µ—Å—Ç–∞—Ö!

–û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –≤–∞–ª–∏–¥–Ω—ã–º JSON, –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞."""

        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–¥–¥–µ—Ä–∂–∫—É vision –∏ —Å–æ–±–∏—Ä–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            model_supports_vision = supports_vision(self.model_name) if self.model_name else False
            image_contents = []
            
            if file_ids and model_supports_vision:
                for file_id in file_ids:
                    file_data = context.get_file(file_id)
                    if file_data:
                        file_type = file_data.get('type', '')
                        if file_type.startswith('image/'):
                            media_type = file_data.get('media_type', file_type)
                            base64_data = file_data.get('data', '')
                            if base64_data:
                                image_contents.append({
                                    "type": "image_url",
                                    "image_url": {
                                        "url": f"data:{media_type};base64,{base64_data}"
                                    }
                                })
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ
            if image_contents:
                # Multimodal —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏
                message_content = [{"type": "text", "text": prompt}] + image_contents
                messages = [
                    SystemMessage(content="–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—é –¥–µ–π—Å—Ç–≤–∏–π. –û—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ –≤–∞–ª–∏–¥–Ω—ã–º JSON."),
                    HumanMessage(content=message_content)
                ]
            else:
                # –û–±—ã—á–Ω–æ–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
                messages = [
                    SystemMessage(content="–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—é –¥–µ–π—Å—Ç–≤–∏–π. –û—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ –≤–∞–ª–∏–¥–Ω—ã–º JSON."),
                    HumanMessage(content=prompt)
                ]
            
            response = await self.llm.ainvoke(messages)
            
            # Handle different response formats
            if isinstance(response.content, list):
                text_parts = []
                for block in response.content:
                    if hasattr(block, "text"):
                        text_parts.append(block.text)
                    elif isinstance(block, dict) and "text" in block:
                        text_parts.append(block["text"])
                    elif isinstance(block, str):
                        text_parts.append(block)
                response_text = " ".join(text_parts).strip()
            elif isinstance(response.content, str):
                response_text = response.content.strip()
            else:
                response_text = str(response.content).strip()
            
            # Extract JSON
            json_match = re.search(r'\{[\s\S]*\}', response_text)
            if json_match:
                json_str = json_match.group(0)
                action_plan = json.loads(json_str)
            else:
                action_plan = json.loads(response_text)
            
            # Validate
            if "tool_name" not in action_plan:
                raise ValueError("tool_name missing in action plan")
            
            return action_plan
            
        except Exception as e:
            logger.error(f"[UnifiedReActEngine] Error in _plan_action: {e}")
            # Fallback
            if self.capabilities:
                fallback_cap = self.capabilities[0]
                return {
                    "tool_name": fallback_cap.name,
                    "arguments": {},
                    "description": f"Fallback: –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ {fallback_cap.name}",
                    "reasoning": f"–û—à–∏–±–∫–∞ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è: {str(e)}. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è fallback –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç."
                }
            else:
                return {
                    "tool_name": "error",
                    "arguments": {},
                    "description": "–û—à–∏–±–∫–∞ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è: –Ω–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤",
                    "reasoning": str(e)
                }
    
    async def _think_and_plan(
        self,
        state: ReActState,
        context: ConversationContext,
        file_ids: List[str]
    ) -> tuple[str, Dict[str, Any]]:
        """
        –û–±—ä–µ–¥–∏–Ω—ë–Ω–Ω—ã–π –≤—ã–∑–æ–≤: –∞–Ω–∞–ª–∏–∑ + –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ –æ–¥–Ω–æ–º LLM –∑–∞–ø—Ä–æ—Å–µ.
        –°—Ç—Ä–∏–º–∏—Ç thought –ø–æ –º–µ—Ä–µ –ø–æ—Å—Ç—É–ø–ª–µ–Ω–∏—è, –∑–∞—Ç–µ–º –ø–∞—Ä—Å–∏—Ç action plan.
        
        Returns:
            Tuple[thought: str, action_plan: Dict[str, Any]]
        """
        # –°—Ç—Ä–æ–∏–º –∫–æ–Ω—Ç–µ–∫—Å—Ç (–æ–±—ä–µ–¥–∏–Ω—è–µ–º –ª–æ–≥–∏–∫—É –∏–∑ _think –∏ _plan_action)
        from datetime import datetime, timedelta
        import pytz
        from src.utils.config_loader import get_config
        tz = pytz.timezone(get_config().timezone)
        now = datetime.now(tz)
        current_date_str = now.strftime("%Y-%m-%d %H:%M")
        tomorrow = now + timedelta(days=1)
        tomorrow_str = tomorrow.strftime("%Y-%m-%d")
        
        context_str = f"üìÖ –¢–ï–ö–£–©–ê–Ø –î–ê–¢–ê –ò –í–†–ï–ú–Ø: {current_date_str} (–∑–∞–≤—Ç—Ä–∞ = {tomorrow_str})\n\n"
        context_str += f"–¶–µ–ª—å: {state.goal}\n\n"
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏—Å—Ç–æ—Ä–∏—é —Ä–∞–∑–≥–æ–≤–æ—Ä–∞
        if hasattr(context, 'messages') and context.messages:
            recent_messages = context.messages[-4:]
            if recent_messages:
                context_str += "üìù –ö–æ–Ω—Ç–µ–∫—Å—Ç —Ä–∞–∑–≥–æ–≤–æ—Ä–∞:\n"
                for msg in recent_messages:
                    role = "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å" if msg.get('role') == 'user' else "–ê—Å—Å–∏—Å—Ç–µ–Ω—Ç"
                    content = msg.get('content', '')[:300]
                    context_str += f"  {role}: {content}\n"
                context_str += "\n"
        
        # –î–æ–±–∞–≤–ª—è–µ–º –æ—Ç–∫—Ä—ã—Ç—ã–µ —Ñ–∞–π–ª—ã
        open_files = context.get_open_files() if hasattr(context, 'get_open_files') else []
        if open_files:
            context_str += "\nüìÇ –û–¢–ö–†–´–¢–´–ï –§–ê–ô–õ–´ –í –†–ê–ë–û–ß–ï–ô –û–ë–õ–ê–°–¢–ò:\n"
            for file in open_files:
                file_type = file.get('type')
                title = file.get('title', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')
                
                if file_type == 'sheets':
                    spreadsheet_id = file.get('spreadsheet_id') or file.get('spreadsheetId')
                    if not spreadsheet_id and file.get('url'):
                        url_match = re.search(r'/spreadsheets/d/([a-zA-Z0-9-_]+)', file.get('url', ''))
                        if url_match:
                            spreadsheet_id = url_match.group(1)
                    if spreadsheet_id:
                        context_str += f"- üìä –¢–∞–±–ª–∏—Ü–∞: {title} (ID: {spreadsheet_id})\n"
                        context_str += f"  –ò—Å–ø–æ–ª—å–∑—É–π: sheets_read_range —Å spreadsheetId={spreadsheet_id}\n"
                elif file_type == 'docs':
                    document_id = file.get('document_id') or file.get('documentId')
                    if not document_id and file.get('url'):
                        url_match = re.search(r'/document/d/([a-zA-Z0-9-_]+)', file.get('url', ''))
                        if url_match:
                            document_id = url_match.group(1)
                    if document_id:
                        context_str += f"- üìÑ –î–æ–∫—É–º–µ–Ω—Ç: {title} (ID: {document_id})\n"
                        context_str += f"  –ò—Å–ø–æ–ª—å–∑—É–π: read_document —Å documentId={document_id}\n"
            context_str += "\n"
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏—Å—Ç–æ—Ä–∏—é –¥–µ–π—Å—Ç–≤–∏–π
        if state.action_history:
            context_str += "–£–∂–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ:\n"
            for action in state.action_history[-3:]:
                context_str += f"- {action.tool_name}\n"
        
        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
        capability_descriptions = []
        for cap in self.capabilities[:50]:
            capability_descriptions.append(f"- {cap.name}: {cap.description}")
        tools_str = "\n".join(capability_descriptions)
        
        # #region agent log - H11: Before building prompt
        import json as _json; import time as _time; open('/Users/Dima/universal-multiagent/.cursor/debug.log', 'a').write(_json.dumps({"location": "_think_and_plan:before_prompt", "message": "Building prompt for LLM", "data": {"goal": state.goal[:200], "goal_length": len(state.goal), "iteration": state.iteration, "capabilities_count": len(self.capabilities)}, "timestamp": int(_time.time()*1000), "sessionId": "debug-session", "hypothesisId": "H11"}) + '\n')
        # #endregion
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –æ–±—ä–µ–¥–∏–Ω—ë–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç
        prompt = f"""–¢—ã –≤—ã–ø–æ–ª–Ω—è–µ—à—å –∑–∞–¥–∞—á—É –ø–æ—à–∞–≥–æ–≤–æ, –∏—Å–ø–æ–ª—å–∑—É—è –¥–æ—Å—Ç—É–ø–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã.

{context_str}

–î–æ—Å—Ç—É–ø–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã:
{tools_str}

–ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û: –ï—Å–ª–∏ –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –Ω–µ–ø–æ–ª–Ω—ã–π –∏–ª–∏ –Ω–µ—è—Å–Ω—ã–π (–Ω–∞–ø—Ä–∏–º–µ—Ä, "—Å–æ–∑–¥–∞–π –≤—Å—Ç—Ä–µ—á—É" –±–µ–∑ —É–∫–∞–∑–∞–Ω–∏—è –≤—Ä–µ–º–µ–Ω–∏, —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤, –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏), 
"–Ω–∞–∑–Ω–∞—á—å –≤—Å—Ç—Ä–µ—á—É?" (–≤–æ–ø—Ä–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –∑–Ω–∞–∫ —É–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞ –Ω–µ–ø–æ–ª–Ω–æ—Ç—É), "–æ—Ç–ø—Ä–∞–≤—å –ø–∏—Å—å–º–æ" –±–µ–∑ —É–∫–∞–∑–∞–Ω–∏—è –ø–æ–ª—É—á–∞—Ç–µ–ª—è –∏ —Ç–µ–º—ã,
–ù–ï –ø—ã—Ç–∞–π—Å—è –≤—ã–ø–æ–ª–Ω–∏—Ç—å –¥–µ–π—Å—Ç–≤–∏–µ —Å –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏ –∏–ª–∏ —É–≥–∞–¥—ã–≤–∞—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã. 
–í–°–ï–ì–î–ê –∏—Å–ø–æ–ª—å–∑—É–π tool_name "ASK_CLARIFICATION" –∏ –≤ arguments —É–∫–∞–∂–∏ —Å–ø–∏—Å–æ–∫ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤ –¥–ª—è —É—Ç–æ—á–Ω–µ–Ω–∏—è.

–í–ê–ñ–ù–û: –°–ª–µ–¥—É—é—â–∏–µ –∑–∞–ø—Ä–æ—Å—ã –ù–ï —Ç—Ä–µ–±—É—é—Ç —É—Ç–æ—á–Ω–µ–Ω–∏—è (–∏—Å–ø–æ–ª—å–∑—É–π —Ç–µ–∫—É—â—É—é –¥–∞—Ç—É/–≤—Ä–µ–º—è –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞):
- "–ø–æ–∫–∞–∂–∏ –≤—Å—Ç—Ä–µ—á–∏ –Ω–∞ –Ω–µ–¥–µ–ª–µ" ‚Üí –æ–∑–Ω–∞—á–∞–µ—Ç —Ç–µ–∫—É—â—É—é –Ω–µ–¥–µ–ª—é (–ø–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫-–≤–æ—Å–∫—Ä–µ—Å–µ–Ω—å–µ)
- "–ø–æ–∫–∞–∂–∏ –≤—Å—Ç—Ä–µ—á–∏ —Å–µ–≥–æ–¥–Ω—è" ‚Üí –æ–∑–Ω–∞—á–∞–µ—Ç —Å–µ–≥–æ–¥–Ω—è—à–Ω–∏–π –¥–µ–Ω—å
- "–ø–æ–∫–∞–∂–∏ –≤—Å—Ç—Ä–µ—á–∏ –∑–∞–≤—Ç—Ä–∞" ‚Üí –æ–∑–Ω–∞—á–∞–µ—Ç –∑–∞–≤—Ç—Ä–∞—à–Ω–∏–π –¥–µ–Ω—å
- "–ø–æ–∫–∞–∂–∏ –≤—Å—Ç—Ä–µ—á–∏" –±–µ–∑ —É–∫–∞–∑–∞–Ω–∏—è –ø–µ—Ä–∏–æ–¥–∞ ‚Üí –æ–∑–Ω–∞—á–∞–µ—Ç —Å–µ–≥–æ–¥–Ω—è

–û–°–û–ë–ï–ù–ù–û –í–ê–ñ–ù–û –î–õ–Ø –ö–ê–õ–ï–ù–î–ê–†–Ø:
1. **–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤**: –ï—Å–ª–∏ –≤ –∑–∞–ø—Ä–æ—Å–µ —É–∫–∞–∑–∞–Ω—ã —É—á–∞—Å—Ç–Ω–∏–∫–∏ –≤—Å—Ç—Ä–µ—á–∏ –∏ –≤—Ä–µ–º—è, –¢–´ –î–û–õ–ñ–ï–ù –°–ê–ú –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –∏—Ö –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å —á–µ—Ä–µ–∑ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç `get_calendar_events` –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —É—á–∞—Å—Ç–Ω–∏–∫–∞ –Ω–∞ —É–∫–∞–∑–∞–Ω–Ω–æ–µ –≤—Ä–µ–º—è. –ù–ï —Å–ø—Ä–∞—à–∏–≤–∞–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –æ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ - –ø—Ä–æ–≤–µ—Ä—å —Å–∞–º!

2. **–ï—Å–ª–∏ —É—á–∞—Å—Ç–Ω–∏–∫ –∑–∞–Ω—è—Ç**: –ï—Å–ª–∏ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ –∫–∞–ª–µ–Ω–¥–∞—Ä—è —É—á–∞—Å—Ç–Ω–∏–∫–∞ –≤—ã—è—Å–Ω–∏–ª–æ—Å—å, —á—Ç–æ –æ–Ω –∑–∞–Ω—è—Ç –≤ —É–∫–∞–∑–∞–Ω–Ω–æ–µ –≤—Ä–µ–º—è:
   - –ü–æ–ª—É—á–∏ —Å–ø–∏—Å–æ–∫ –µ–≥–æ –≤—Å—Ç—Ä–µ—á –Ω–∞ —ç—Ç–æ—Ç –¥–µ–Ω—å —á–µ—Ä–µ–∑ `get_calendar_events`
   - –ò—Å–ø–æ–ª—å–∑—É–π `ASK_CLARIFICATION` —Å –≤–æ–ø—Ä–æ—Å–æ–º: "–£—á–∞—Å—Ç–Ω–∏–∫ [email] –∑–∞–Ω—è—Ç –≤ —É–∫–∞–∑–∞–Ω–Ω–æ–µ –≤—Ä–µ–º—è. –í–æ—Ç –µ–≥–æ –≤—Å—Ç—Ä–µ—á–∏ –Ω–∞ [–¥–∞—Ç–∞]: [—Å–ø–∏—Å–æ–∫ –≤—Å—Ç—Ä–µ—á]. –ö–∞–∫ –ª—É—á—à–µ –ø–æ—Å—Ç—É–ø–∏—Ç—å? (–ø–µ—Ä–µ–Ω–µ—Å—Ç–∏ –≤—Å—Ç—Ä–µ—á—É, –≤—ã–±—Ä–∞—Ç—å –¥—Ä—É–≥–æ–µ –≤—Ä–µ–º—è, —Å–æ–∑–¥–∞—Ç—å –≤—Å—Ç—Ä–µ—á—É –Ω–µ—Å–º–æ—Ç—Ä—è –Ω–∞ –∫–æ–Ω—Ñ–ª–∏–∫—Ç)"

3. **–ï—Å–ª–∏ –≤ –∑–∞–ø—Ä–æ—Å–µ "–ø–æ–¥–±–µ—Ä–∏ –≤—Ä–µ–º—è" –∏–ª–∏ "–Ω–∞–π–¥–∏ —Å–≤–æ–±–æ–¥–Ω–æ–µ –≤—Ä–µ–º—è"**: 
   - –ò—Å–ø–æ–ª—å–∑—É–π `schedule_group_meeting` –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞ —Å–≤–æ–±–æ–¥–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ –¥–ª—è –≤—Å–µ—Ö —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤
   - –ò–õ–ò –ø—Ä–æ–≤–µ—Ä—å –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å —á–µ—Ä–µ–∑ `get_calendar_events` –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —É—á–∞—Å—Ç–Ω–∏–∫–∞ –∏ –Ω–∞–π–¥–∏ –æ–±—â–µ–µ —Å–≤–æ–±–æ–¥–Ω–æ–µ –æ–∫–Ω–æ
   - –ù–ï —Å–ø—Ä–∞—à–∏–≤–∞–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è - –Ω–∞–π–¥–∏ –≤—Ä–µ–º—è —Å–∞–º!

4. **–ü–æ—Ä—è–¥–æ–∫ –¥–µ–π—Å—Ç–≤–∏–π –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –≤—Å—Ç—Ä–µ—á–∏ —Å —É—á–∞—Å—Ç–Ω–∏–∫–∞–º–∏**:
   - –®–∞–≥ 1: –ï—Å–ª–∏ –≤—Ä–µ–º—è —É–∫–∞–∑–∞–Ω–æ - –ø—Ä–æ–≤–µ—Ä—å –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ —á–µ—Ä–µ–∑ `get_calendar_events`
   - –®–∞–≥ 2: –ï—Å–ª–∏ –≤—Å–µ —Å–≤–æ–±–æ–¥–Ω—ã - —Å–æ–∑–¥–∞–π –≤—Å—Ç—Ä–µ—á—É —á–µ—Ä–µ–∑ `create_event` –∏–ª–∏ `schedule_group_meeting`
   - –®–∞–≥ 3: –ï—Å–ª–∏ –∫—Ç–æ-—Ç–æ –∑–∞–Ω—è—Ç - –ø–æ–∫–∞–∂–∏ –µ–≥–æ –≤—Å—Ç—Ä–µ—á–∏ –∏ —Å–ø—Ä–æ—Å–∏, –∫–∞–∫ –ø–æ—Å—Ç—É–ø–∏—Ç—å (—á–µ—Ä–µ–∑ `ASK_CLARIFICATION`)

‚ö†Ô∏è **–ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û - –ù–ï –ó–ê–¶–ò–ö–õ–ò–í–ê–ô–°–Ø:**
- –ù–ò–ö–û–ì–î–ê –Ω–µ –≤—ã–∑—ã–≤–∞–π `get_calendar_events` –±–æ–ª–µ–µ –û–î–ù–û–ì–û —Ä–∞–∑–∞ –¥–ª—è –æ–¥–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –¥–∏–∞–ø–∞–∑–æ–Ω–∞!
- –ü–æ—Å–ª–µ –ü–ï–†–í–û–ô –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –°–†–ê–ó–£ –ø–µ—Ä–µ—Ö–æ–¥–∏ –∫ —Å–ª–µ–¥—É—é—â–µ–º—É —à–∞–≥—É:
  * –ï—Å–ª–∏ –≤—Ä–µ–º—è —Å–≤–æ–±–æ–¥–Ω–æ ‚Üí –≤—ã–∑–æ–≤–∏ `create_event`
  * –ï—Å–ª–∏ –≤—Ä–µ–º—è –∑–∞–Ω—è—Ç–æ ‚Üí –≤—ã–∑–æ–≤–∏ `ASK_CLARIFICATION` –∏ —Å–æ–æ–±—â–∏ –æ –∫–æ–Ω—Ñ–ª–∏–∫—Ç–µ
- –ï—Å–ª–∏ —Ç—ã —É–∂–µ –ø–æ–ª—É—á–∏–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç –æ—Ç `get_calendar_events`, –ù–ï –≤—ã–∑—ã–≤–∞–π –µ–≥–æ —Å–Ω–æ–≤–∞!

–ü—Ä–∏–º–µ—Ä—ã –Ω–µ–ø–æ–ª–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤, —Ç—Ä–µ–±—É—é—â–∏—Ö —É—Ç–æ—á–Ω–µ–Ω–∏—è:
- "—Å–æ–∑–¥–∞–π –≤—Å—Ç—Ä–µ—á—É" ‚Üí –Ω—É–∂–Ω—ã: –≤—Ä–µ–º—è, —É—á–∞—Å—Ç–Ω–∏–∫–∏, –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å, —Ç–µ–º–∞
- "–Ω–∞–∑–Ω–∞—á—å –≤—Å—Ç—Ä–µ—á—É?" ‚Üí –Ω—É–∂–Ω—ã: –≤—Å–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≤—Å—Ç—Ä–µ—á–∏
- "–æ—Ç–ø—Ä–∞–≤—å –ø–∏—Å—å–º–æ" ‚Üí –Ω—É–∂–Ω—ã: –ø–æ–ª—É—á–∞—Ç–µ–ª—å, —Ç–µ–º–∞, —Ç–µ–∫—Å—Ç

–û—Ç–≤–µ—Ç—å –≤ —Ñ–æ—Ä–º–∞—Ç–µ:
<thought>
–ö—Ä–∞—Ç–∫–∏–π –∞–Ω–∞–ª–∏–∑ —Å–∏—Ç—É–∞—Ü–∏–∏ (2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –Ω–∞ —Ä—É—Å—Å–∫–æ–º):
1. –ß—Ç–æ —É–∂–µ —Å–¥–µ–ª–∞–Ω–æ?
2. –ß—Ç–æ –æ—Å—Ç–∞–ª–æ—Å—å —Å–¥–µ–ª–∞—Ç—å?
3. –ö–∞–∫–æ–µ —Å–ª–µ–¥—É—é—â–µ–µ –¥–µ–π—Å—Ç–≤–∏–µ –±—É–¥–µ—Ç –Ω–∞–∏–±–æ–ª–µ–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–º?
–ï—Å–ª–∏ –∑–∞–ø—Ä–æ—Å –Ω–µ–ø–æ–ª–Ω—ã–π - —É–∫–∞–∂–∏, –∫–∞–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç.
</thought>
<action>
{{
    "tool_name": "–∏–º—è_–∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞",
    "arguments": {{"param1": "value1", "param2": "value2"}},
    "description": "–∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –¥–µ–π—Å—Ç–≤–∏—è",
    "reasoning": "–ø–æ—á–µ–º—É –≤—ã–±—Ä–∞–Ω–æ —ç—Ç–æ –¥–µ–π—Å—Ç–≤–∏–µ"
}}
</action>

–ï—Å–ª–∏ —Ü–µ–ª—å –ø–æ–ª–Ω–æ—Å—Ç—å—é –¥–æ—Å—Ç–∏–≥–Ω—É—Ç–∞, –∏—Å–ø–æ–ª—å–∑—É–π:
{{
    "tool_name": "FINISH",
    "arguments": {{}},
    "description": "–∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–Ω–æ–π –∑–∞–¥–∞—á–∏",
    "reasoning": "–ø–æ—á–µ–º—É –∑–∞–¥–∞—á–∞ —Å—á–∏—Ç–∞–µ—Ç—Å—è –≤—ã–ø–æ–ª–Ω–µ–Ω–Ω–æ–π"
}}

–ï—Å–ª–∏ –∑–∞–ø—Ä–æ—Å –Ω–µ–ø–æ–ª–Ω—ã–π –∏ –Ω—É–∂–Ω—ã —É—Ç–æ—á–Ω–µ–Ω–∏—è, –∏—Å–ø–æ–ª—å–∑—É–π:
{{
    "tool_name": "ASK_CLARIFICATION",
    "arguments": {{
        "questions": ["–í–æ–ø—Ä–æ—Å 1", "–í–æ–ø—Ä–æ—Å 2", "–í–æ–ø—Ä–æ—Å 3"]
    }},
    "description": "–ó–∞–ø—Ä–æ—Å —É—Ç–æ—á–Ω–µ–Ω–∏–π —É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è",
    "reasoning": "–ø–æ—á–µ–º—É –Ω—É–∂–Ω—ã —É—Ç–æ—á–Ω–µ–Ω–∏—è"
}}

–û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –≤ —É–∫–∞–∑–∞–Ω–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ, –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞."""
        
        try:
            messages = [
                SystemMessage(content="–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É –∑–∞–¥–∞—á –∏ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—é –¥–µ–π—Å—Ç–≤–∏–π. –û—Ç–≤–µ—á–∞–π –≤ —É–∫–∞–∑–∞–Ω–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ."),
                HumanMessage(content=prompt)
            ]
            
            # –°–æ–∑–¥–∞—ë–º –ø–∞—Ä—Å–µ—Ä –¥–ª—è —Å—Ç—Ä–∏–º–∏–Ω–≥–∞ thought
            parser = self.StreamingThoughtParser(self.ws_manager, self.session_id)
            
            # –°—Ç—Ä–∏–º–∏–º –æ—Ç–≤–µ—Ç
            full_response = ""
            async for chunk in self.llm.astream(messages):
                chunk_text = ""
                if hasattr(chunk, 'content') and chunk.content:
                    if isinstance(chunk.content, list):
                        for block in chunk.content:
                            if hasattr(block, "text"):
                                chunk_text += block.text
                            elif isinstance(block, dict) and "text" in block:
                                chunk_text += block["text"]
                            elif isinstance(block, str):
                                chunk_text += block
                    elif isinstance(chunk.content, str):
                        chunk_text = chunk.content
                elif isinstance(chunk, str):
                    chunk_text = chunk
                
                if chunk_text:
                    full_response += chunk_text
                    await parser.process_chunk(chunk_text)
            
            # –ü–æ–ª—É—á–∞–µ–º thought –∏–∑ –ø–∞—Ä—Å–µ—Ä–∞
            thought = parser.get_thought()
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º action –∏–∑ –æ—Å—Ç–∞–≤—à–µ–≥–æ—Å—è –±—É—Ñ–µ—Ä–∞ –∏–ª–∏ –ø–æ–ª–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞
            remaining_buffer = parser.get_remaining_buffer()
            response_text = remaining_buffer if remaining_buffer else full_response
            
            # –ò—â–µ–º action –±–ª–æ–∫
            action_match = re.search(r'<action>([\s\S]*?)</action>', response_text, re.DOTALL)
            if not action_match:
                # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ JSON –±–µ–∑ —Ç–µ–≥–æ–≤
                action_match = re.search(r'\{[\s\S]*"tool_name"[\s\S]*\}', response_text)
            
            if action_match:
                action_text = action_match.group(1) if action_match.lastindex else action_match.group(0)
                # –û—á–∏—â–∞–µ–º –æ—Ç —Ç–µ–≥–æ–≤ –µ—Å–ª–∏ –µ—Å—Ç—å
                action_text = re.sub(r'</?action>', '', action_text).strip()
                
                # –ü–∞—Ä—Å–∏–º JSON
                json_match = re.search(r'\{[\s\S]*\}', action_text)
                if json_match:
                    json_str = json_match.group(0)
                    try:
                        action_plan = json.loads(json_str)
                    except json.JSONDecodeError:
                        # Fallback –Ω–∞ –ø–∞—Ä—Å–∏–Ω–≥ –≤—Å–µ–≥–æ —Ç–µ–∫—Å—Ç–∞
                        action_plan = json.loads(action_text)
                else:
                    action_plan = json.loads(action_text)
            else:
                # Fallback: –ø—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ JSON –≤ –æ—Ç–≤–µ—Ç–µ
                json_match = re.search(r'\{[\s\S]*"tool_name"[\s\S]*\}', full_response)
                if json_match:
                    action_plan = json.loads(json_match.group(0))
                else:
                    raise ValueError("Could not find action plan in response")
            
            # –í–∞–ª–∏–¥–∞—Ü–∏—è
            if "tool_name" not in action_plan:
                raise ValueError("tool_name missing in action plan")
            
            # #region agent log - H11,H17: After parsing action plan
            tool_name = action_plan.get("tool_name", "")
            is_clarification = tool_name == "ASK_CLARIFICATION"
            goal_lower = state.goal.lower() if state.goal else ""
            has_meeting_keywords = any(kw in goal_lower for kw in ["–≤—Å—Ç—Ä–µ—á", "meeting", "–Ω–∞–∑–Ω–∞—á—å", "—Å–æ–∑–¥–∞–π –≤—Å—Ç—Ä–µ—á—É", "–∑–∞–ø–ª–∞–Ω–∏—Ä"])
            has_attendees = any("@" in arg for arg in str(action_plan.get("arguments", {})).split() if isinstance(arg, str))
            has_time = any(kw in goal_lower for kw in ["–≤ ", "–≤ ", "–≤—Ä–µ–º—è", "time", "14:00", "15:00"])
            should_check_availability = has_meeting_keywords and has_attendees and has_time and not is_clarification
            import json as _json; import time as _time; open('/Users/Dima/universal-multiagent/.cursor/debug.log', 'a').write(_json.dumps({"location": "_think_and_plan:after_parsing", "message": "Action plan parsed", "data": {"tool_name": tool_name, "is_clarification": is_clarification, "goal": state.goal[:200], "thought_length": len(thought) if thought else 0, "arguments_keys": list(action_plan.get("arguments", {}).keys()), "has_meeting_keywords": has_meeting_keywords, "has_attendees": has_attendees, "has_time": has_time, "should_check_availability": should_check_availability}, "timestamp": int(_time.time()*1000), "sessionId": "debug-session", "hypothesisId": "H11,H17"}) + '\n')
            # #endregion
            
            # –ï—Å–ª–∏ thought –ø—É—Å—Ç–æ–π, –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback
            if not thought:
                thought = f"–ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –∑–∞–¥–∞—á—É: {state.goal[:100]}..."
            
            return thought, action_plan
            
        except Exception as e:
            logger.error(f"[UnifiedReActEngine] Error in _think_and_plan: {e}")
            # Fallback
            fallback_thought = f"–ê–Ω–∞–ª–∏–∑–∏—Ä—É—é —Å–∏—Ç—É–∞—Ü–∏—é... (–∏—Ç–µ—Ä–∞—Ü–∏—è {state.iteration})"
            
            if self.capabilities:
                fallback_cap = self.capabilities[0]
                fallback_plan = {
                    "tool_name": fallback_cap.name,
                    "arguments": {},
                    "description": f"Fallback: –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ {fallback_cap.name}",
                    "reasoning": f"–û—à–∏–±–∫–∞ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è: {str(e)}. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è fallback –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç."
                }
            else:
                fallback_plan = {
                    "tool_name": "error",
                    "arguments": {},
                    "description": "–û—à–∏–±–∫–∞ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è: –Ω–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤",
                    "reasoning": str(e)
                }
            
            return fallback_thought, fallback_plan
    
    async def _execute_action(
        self,
        action_plan: Dict[str, Any],
        context: ConversationContext
    ) -> Any:
        """Execute action through CapabilityRegistry (provider-agnostic)."""
        capability_name = action_plan.get("tool_name")
        arguments = action_plan.get("arguments", {})
        
        # #region agent log - H3: _execute_action entry
        _action_entry_time = time.time()
        import json as _json; open('/Users/Dima/universal-multiagent/.cursor/debug.log', 'a').write(_json.dumps({"location": "_execute_action:ENTRY", "message": "Entering _execute_action", "data": {"capability_name": capability_name, "arguments": str(arguments)[:200]}, "timestamp": int(_action_entry_time*1000), "sessionId": "debug-session", "hypothesisId": "H3"}) + '\n')
        # #endregion
        
        # Send real progress event BEFORE tool execution
        if self.ws_manager and self.session_id:
            display_name = self._get_tool_display_name(capability_name, arguments)
            
            # Get current intent_id if available
            intent_id = getattr(self, '_current_intent_id', None)
            if intent_id:
                await self.ws_manager.send_event(
                    self.session_id,
                    "intent_detail",
                    {
                        "intent_id": intent_id,
                        "type": "execute",
                        "description": f"{display_name}..."
                    }
                )
        
        # #region agent log - H3: Before registry.execute
        _registry_start = time.time()
        import json as _json; open('/Users/Dima/universal-multiagent/.cursor/debug.log', 'a').write(_json.dumps({"location": "_execute_action:before_registry", "message": "Before registry.execute", "data": {"capability_name": capability_name, "time_in_execute_action_ms": int((_registry_start - _action_entry_time)*1000)}, "timestamp": int(_registry_start*1000), "sessionId": "debug-session", "hypothesisId": "H3"}) + '\n')
        # #endregion
        
        # Registry routes to appropriate provider (MCP or A2A)
        result = await self.registry.execute(capability_name, arguments)
        
        # #region agent log - H3: After registry.execute
        _registry_end = time.time()
        import json as _json; open('/Users/Dima/universal-multiagent/.cursor/debug.log', 'a').write(_json.dumps({"location": "_execute_action:after_registry", "message": "After registry.execute", "data": {"capability_name": capability_name, "registry_duration_ms": int((_registry_end - _registry_start)*1000), "result_type": type(result).__name__, "result_preview": str(result)[:200]}, "timestamp": int(_registry_end*1000), "sessionId": "debug-session", "hypothesisId": "H3"}) + '\n')
        # #endregion
        
        # Send intent_detail AFTER tool execution with result summary
        if self.ws_manager and self.session_id:
            intent_id = getattr(self, '_current_intent_id', None)
            if intent_id:
                # Generate result summary
                result_summary = self._get_result_summary(capability_name, result)
                if result_summary:
                    await self.ws_manager.send_event(
                        self.session_id,
                        "intent_detail",
                        {
                            "intent_id": intent_id,
                            "type": "analyze",
                            "description": result_summary
                        }
                    )
        
        return result
    
    async def _find_alternative(
        self,
        state: ReActState,
        analysis: Analysis,
        context: ConversationContext,
        file_ids: List[str]
    ) -> Optional[Dict[str, Any]]:
        """Find alternative action when current one failed."""
        context_str = f"–¶–µ–ª—å: {state.goal}\n\n"
        context_str += f"–û—à–∏–±–∫–∞: {analysis.error_message}\n\n"
        context_str += "–ù–µ—É–¥–∞—á–Ω—ã–µ –ø–æ–ø—ã—Ç–∫–∏:\n"
        for action in state.action_history[-3:]:
            context_str += f"- {action.tool_name}\n"
        
        context_str += f"\n–ò—Å–ø—Ä–æ–±–æ–≤–∞–Ω–Ω—ã–µ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã: {', '.join(state.alternatives_tried) if state.alternatives_tried else '–Ω–µ—Ç'}\n"
        
        # Get capability descriptions
        capability_descriptions = []
        for cap in self.capabilities[:50]:
            capability_descriptions.append(f"- {cap.name}: {cap.description}")
        
        tools_str = "\n".join(capability_descriptions)
        
        prompt = f"""–ü—Ä–µ–¥—ã–¥—É—â–µ–µ –¥–µ–π—Å—Ç–≤–∏–µ –Ω–µ —É–¥–∞–ª–æ—Å—å. –ù–∞–π–¥–∏ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π —Å–ø–æ—Å–æ–± –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è —Ü–µ–ª–∏.

{context_str}

–î–æ—Å—Ç—É–ø–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã:
{tools_str}

–ü—Ä–µ–¥–ª–æ–∂–∏ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON:
{{
    "tool_name": "–∏–º—è_–∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞",
    "arguments": {{"param1": "value1"}},
    "description": "–æ–ø–∏—Å–∞–Ω–∏–µ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–æ–≥–æ –¥–µ–π—Å—Ç–≤–∏—è",
    "reasoning": "–ø–æ—á–µ–º—É —ç—Ç–æ –¥–æ–ª–∂–Ω–æ —Å—Ä–∞–±–æ—Ç–∞—Ç—å"
}}

–ï—Å–ª–∏ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã –Ω–µ—Ç, –≤–µ—Ä–Ω–∏ {{"alternative": false}}.

–û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –≤–∞–ª–∏–¥–Ω—ã–º JSON."""

        try:
            messages = [
                SystemMessage(content="–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –ø–æ–∏—Å–∫—É –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã—Ö —Ä–µ—à–µ–Ω–∏–π. –û—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ –≤–∞–ª–∏–¥–Ω—ã–º JSON."),
                HumanMessage(content=prompt)
            ]
            
            response = await self.llm.ainvoke(messages)
            
            # Handle different response formats
            if isinstance(response.content, list):
                text_parts = []
                for block in response.content:
                    if hasattr(block, "text"):
                        text_parts.append(block.text)
                    elif isinstance(block, dict) and "text" in block:
                        text_parts.append(block["text"])
                    elif isinstance(block, str):
                        text_parts.append(block)
                response_text = " ".join(text_parts).strip()
            elif isinstance(response.content, str):
                response_text = response.content.strip()
            else:
                response_text = str(response.content).strip()
            
            # Extract JSON
            json_match = re.search(r'\{[\s\S]*\}', response_text)
            if json_match:
                json_str = json_match.group(0)
                alternative = json.loads(json_str)
            else:
                alternative = json.loads(response_text)
            
            # Check if alternative exists
            if alternative.get("alternative") is False:
                return None
            
            if "tool_name" not in alternative:
                return None
            
            return alternative
            
        except Exception as e:
            logger.error(f"[UnifiedReActEngine] Error in _find_alternative: {e}")
            return None
    
    async def _generate_final_answer(self, state: ReActState, context: Optional[ConversationContext] = None, file_ids: Optional[List[str]] = None) -> str:
        """Generate a human-friendly final answer based on all collected results with streaming."""
        try:
            # Collect all observations/results
            observations_text = ""
            for obs in state.observations:
                if obs.raw_result:
                    observations_text += f"- {obs.action.tool_name}: {str(obs.raw_result)[:1500]}\n"
            
            # If no observations but we have FINISH reasoning, use it
            if not observations_text:
                # Check for FINISH marker in reasoning trail
                for step in reversed(state.reasoning_trail):
                    if step.metadata and step.metadata.get("tool") == "FINISH":
                        # Use the reasoning from FINISH step
                        observations_text = step.content
                        break
            
            if not observations_text:
                observations_text = "–ù–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ—Ç –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤."
            
            # Build file contents for FINISH cases
            file_contents_text = ""
            if file_ids and context:
                for file_id in file_ids:
                    file_data = context.get_file(file_id)
                    if file_data:
                        filename = file_data.get('filename', 'unknown')
                        file_type = file_data.get('type', '')
                        full_text = file_data.get('text', '')
                        # Use larger limit for final answer - user wants detailed description
                        max_len = 15000
                        if file_type == 'application/pdf' and 'text' in file_data:
                            pdf_text = full_text[:max_len] if len(full_text) > max_len else full_text
                            truncation_note = f"\n... (–ø–æ–∫–∞–∑–∞–Ω–æ {max_len} –∏–∑ {len(full_text)} —Å–∏–º–≤–æ–ª–æ–≤)" if len(full_text) > max_len else ""
                            file_contents_text += f"\nüìÑ PDF '{filename}':\n{pdf_text}{truncation_note}\n"
                        elif file_type in ("application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                                          "application/msword") and 'text' in file_data:
                            docx_text = full_text[:max_len] if len(full_text) > max_len else full_text
                            truncation_note = f"\n... (–ø–æ–∫–∞–∑–∞–Ω–æ {max_len} –∏–∑ {len(full_text)} —Å–∏–º–≤–æ–ª–æ–≤)" if len(full_text) > max_len else ""
                            file_contents_text += f"\nüìÑ Word '{filename}':\n{docx_text}{truncation_note}\n"
                        elif file_type.startswith('image/'):
                            file_contents_text += f"\nüñºÔ∏è –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ '{filename}': (–ø–µ—Ä–µ–¥–∞–Ω–æ —á–µ—Ä–µ–∑ Vision API - –æ–ø–∏—à–∏ —á—Ç–æ –≤–∏–¥–∏—à—å)\n"
            
            # Check if user asked for a table
            goal_lower = state.goal.lower()
            wants_table = any(word in goal_lower for word in ['—Ç–∞–±–ª–∏—á–∫', '—Ç–∞–±–ª–∏—Ü', 'table'])
            
            if wants_table:
                table_instruction = """
–§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê:
–í—ã–≤–µ–¥–∏ –¥–∞–Ω–Ω—ã–µ –≤ –≤–∏–¥–µ MARKDOWN –¢–ê–ë–õ–ò–¶–´. –ü—Ä–∏–º–µ—Ä:
| –ù–∞–∑–≤–∞–Ω–∏–µ | –î–∞—Ç–∞ | –í—Ä–µ–º—è |
|----------|------|-------|
| –í—Å—Ç—Ä–µ—á–∞ 1 | 2025-12-25 | 10:00 |

–ü–æ—Å–ª–µ —Ç–∞–±–ª–∏—Ü—ã –¥–æ–±–∞–≤—å –ø—Ä–∏–º–µ—á–∞–Ω–∏–µ:
"üí° –ï—Å–ª–∏ –Ω—É–∂–Ω–æ —Å–æ–∑–¥–∞—Ç—å Google —Ç–∞–±–ª–∏—Ü—É —Å —ç—Ç–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏, –ø–µ—Ä–µ–∫–ª—é—á–∏—Ç–µ—Å—å –≤ —Ä–µ–∂–∏–º **–ê–≥–µ–Ω—Ç**."
"""
            else:
                table_instruction = ""
            
            # Check if this is a FINISH case (reasoning contains file analysis)
            is_finish_case = any(
                step.metadata and step.metadata.get("tool") == "FINISH"
                for step in state.reasoning_trail
            )
            
            if is_finish_case and file_contents_text:
                # For FINISH with file content, include actual file contents in prompt
                prompt = f"""–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Å–ø—Ä–æ—Å–∏–ª: "{state.goal}"

–í–æ—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –ø—Ä–∏–∫—Ä–µ–ø–ª–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤:
{file_contents_text}

{table_instruction}
–í–ê–ñ–ù–û: –û–ø–∏—à–∏ –ö–û–ù–ö–†–ï–¢–ù–û —á—Ç–æ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ —Ñ–∞–π–ª–∞—Ö. –ù–∞–ø—Ä–∏–º–µ—Ä:
- –î–ª—è PDF: "–í —Ñ–∞–π–ª–µ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è —á–µ–∫ –Ω–∞ –æ–ø–ª–∞—Ç—É –Ω–∞–ª–æ–≥–æ–≤ –Ω–∞ —Å—É–º–º—É X —Ä—É–±. –æ—Ç –¥–∞—Ç—ã Y..."
- –î–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: "–ù–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ –ø–æ–∫–∞–∑–∞–Ω —á–µ–ª–æ–≤–µ–∫, –∏–≥—Ä–∞—é—â–∏–π –≤ —Ç–µ–Ω–Ω–∏—Å..."
–ù–ï –≥–æ–≤–æ—Ä–∏ –∞–±—Å—Ç—Ä–∞–∫—Ç–Ω–æ "—Ñ–∞–π–ª —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–µ–∫—Å—Ç–æ–≤—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é". –ë—É–¥—å –ö–û–ù–ö–†–ï–¢–ù–´–ú!

–û—Ç–≤–µ—Ç:"""
            elif is_finish_case:
                # FINISH case without file contents - use reasoning
                prompt = f"""–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Å–ø—Ä–æ—Å–∏–ª: "{state.goal}"

–ê–Ω–∞–ª–∏–∑:
{observations_text}

{table_instruction}
–°—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π –ø–æ–Ω—è—Ç–Ω—ã–π –æ—Ç–≤–µ—Ç –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ, –æ–ø–∏—Å—ã–≤–∞—è —á—Ç–æ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ —Ñ–∞–π–ª–µ/—Ñ–∞–π–ª–∞—Ö. –ë—É–¥—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º –∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–º.

–û—Ç–≤–µ—Ç:"""
            else:
                prompt = f"""–í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: "{state.goal}"

–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞:
{observations_text}

–í–ê–ñ–ù–û: –í–Ω–∏–º–∞—Ç–µ–ª—å–Ω–æ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤—ã—à–µ. –ï—Å–ª–∏ —Ç–∞–º –µ—Å—Ç—å –¥–∞–Ω–Ω—ã–µ (events, messages, files –∏ —Ç.–¥.) - –∑–Ω–∞—á–∏—Ç –æ–Ω–∏ –ù–ê–ô–î–ï–ù–´.
{table_instruction}
–°—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π –æ—Ç–≤–µ—Ç –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ:
- –ï—Å–ª–∏ –Ω–∞–π–¥–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ - –ø–µ—Ä–µ—á–∏—Å–ª–∏ –∏—Ö –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ–Ω—è—Ç–Ω–æ
- –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ –ø—É—Å—Ç—ã–µ (–ø—É—Å—Ç–æ–π –º–∞—Å—Å–∏–≤ [], "Found 0") - —Å–∫–∞–∂–∏ —á—Ç–æ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ
- –ù–ï –≥–æ–≤–æ—Ä–∏ —á—Ç–æ –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç, –µ—Å–ª–∏ –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö –µ—Å—Ç—å –∑–∞–ø–∏—Å–∏!

–û—Ç–≤–µ—Ç:"""

            # Build multimodal message with images if available
            image_contents = []
            model_supports_vision = supports_vision(self.model_name) if self.model_name else False
            
            if file_ids and context and model_supports_vision:
                for file_id in file_ids:
                    file_data = context.get_file(file_id)
                    if file_data:
                        file_type = file_data.get('type', '')
                        if file_type.startswith('image/'):
                            media_type = file_data.get('media_type', file_type)
                            base64_data = file_data.get('data', '')
                            if base64_data:
                                image_contents.append({
                                    "type": "image_url",
                                    "image_url": {
                                        "url": f"data:{media_type};base64,{base64_data}"
                                    }
                                })
            
            # Create message (multimodal if images present)
            if image_contents:
                message_content = [{"type": "text", "text": prompt}] + image_contents
                messages = [HumanMessage(content=message_content)]
            else:
                messages = [HumanMessage(content=prompt)]

            # Stream the response
            full_answer = ""
            
            # Send intent event to show user what's happening
            intent_message = "–ê–Ω–∞–ª–∏–∑–∏—Ä—É—é —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–æ–≤" if file_contents_text else "–§–æ—Ä–º–∏—Ä—É—é –æ—Ç–≤–µ—Ç"
            if len(image_contents) > 0:
                intent_message += f" (–≤–∫–ª—é—á–∞—è {len(image_contents)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ(—è))..."
            else:
                intent_message += "..."
            
            intent_id = f"intent-final-{int(time.time() * 1000)}"
            await self.ws_manager.send_event(
                self.session_id,
                "intent_start",
                {"intent_id": intent_id, "text": intent_message}  # Fixed: use 'text' not 'intent'
            )
            
            # Send details about each file being analyzed
            if file_ids and context:
                for i, file_id in enumerate(file_ids):
                    file_data = context.get_file(file_id)
                    if file_data:
                        filename = file_data.get('filename', 'unknown')
                        file_type = file_data.get('type', '')
                        detail_type = 'read'
                        if file_type.startswith('image/'):
                            detail_desc = f"–ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {filename}"
                        elif 'pdf' in file_type:
                            detail_desc = f"–ß–∏—Ç–∞—é PDF: {filename}"
                        elif 'word' in file_type or 'document' in file_type:
                            detail_desc = f"–ß–∏—Ç–∞—é –¥–æ–∫—É–º–µ–Ω—Ç: {filename}"
                        else:
                            detail_desc = f"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é —Ñ–∞–π–ª: {filename}"
                        
                        await self.ws_manager.send_event(
                            self.session_id,
                            "intent_detail",
                            {
                                "intent_id": intent_id,
                                "type": detail_type,
                                "description": detail_desc
                            }
                        )
            
            # Send start event
            await self.ws_manager.send_event(
                self.session_id,
                "final_result_start",
                {}
            )
            
            # #region agent log - H7: final_result streaming start
            import json as _json; open('/Users/Dima/universal-multiagent/.cursor/debug.log', 'a').write(_json.dumps({"location": "generate_final_answer:stream_start", "message": "Starting LLM streaming for final answer", "data": {"session_id": self.session_id, "goal": state.goal[:100] if state.goal else None}, "timestamp": int(time.time()*1000), "sessionId": "debug-session", "hypothesisId": "H7"}) + '\n')
            _stream_chunk_count = 0
            # #endregion
            
            # Stream chunks
            async for chunk in self.llm.astream(messages):
                chunk_text = ""
                if hasattr(chunk, 'content') and chunk.content:
                    content = chunk.content
                    # Handle multimodal response where content is a list
                    if isinstance(content, list):
                        for block in content:
                            if hasattr(block, 'text'):
                                chunk_text += block.text
                            elif isinstance(block, dict) and 'text' in block:
                                chunk_text += block['text']
                            elif isinstance(block, str):
                                chunk_text += block
                    elif isinstance(content, str):
                        chunk_text = content
                elif isinstance(chunk, str):
                    chunk_text = chunk
                
                if chunk_text:
                    full_answer += chunk_text
                    _stream_chunk_count += 1
                    await self.ws_manager.send_event(
                        self.session_id,
                        "final_result_chunk",
                        {"content": full_answer}  # Send accumulated content
                    )
            
            # #region agent log - H7: final_result streaming complete
            import json as _json; open('/Users/Dima/universal-multiagent/.cursor/debug.log', 'a').write(_json.dumps({"location": "generate_final_answer:stream_complete", "message": "LLM streaming completed", "data": {"total_chunks": _stream_chunk_count, "full_answer_length": len(full_answer), "full_answer_preview": full_answer[:500] if full_answer else None, "full_answer_end": full_answer[-200:] if len(full_answer) > 200 else full_answer}, "timestamp": int(time.time()*1000), "sessionId": "debug-session", "hypothesisId": "H7"}) + '\n')
            # #endregion
            
            # Send intent completion
            await self.ws_manager.send_event(
                self.session_id,
                "intent_complete",
                {"intent_id": intent_id, "summary": "–ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à—ë–Ω"}
            )
            
            # Send completion event
            await self.ws_manager.send_event(
                self.session_id,
                "final_result_complete",
                {"content": full_answer.strip()}
            )
            
            return full_answer.strip()
        except Exception as e:
            logger.error(f"[UnifiedReActEngine] Error generating final answer: {e}")
            # Fallback to last result
            if state.observations:
                last_result = str(state.observations[-1].raw_result)
                return self._format_result_summary(last_result, state.observations[-1].action.tool_name)
            return "–ó–∞–¥–∞—á–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞."

    async def _finalize_success(
        self,
        state: ReActState,
        final_result: Any,
        context: ConversationContext,
        file_ids: Optional[List[str]] = None
    ) -> Dict[str, Any]:
        """Finalize successful execution."""
        state.status = "done"
        
        # === NEW ARCHITECTURE: Complete the task-level intent ===
        task_intent_id = getattr(self, '_task_intent_id', None)
        if task_intent_id and self.ws_manager and self.session_id:
            await self.ws_manager.send_event(
                self.session_id,
                "intent_complete",
                {
                    "intent_id": task_intent_id,
                    "summary": f"‚úÖ –ó–∞–¥–∞—á–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞ –∑–∞ {state.iteration} —à–∞–≥(–æ–≤)",
                    "auto_collapse": False  # Keep expanded to show result
                }
            )
        
        # Generate human-friendly final answer instead of raw result
        human_answer = await self._generate_final_answer(state, context, file_ids)
        
        result_summary = {
            "status": "completed",
            "goal": state.goal,
            "iterations": state.iteration,
            "actions_taken": len(state.action_history),
            "final_result": human_answer,
            "reasoning_trail": [
                {
                    "iteration": step.iteration,
                    "type": step.step_type,
                    "content": step.content,
                    "metadata": step.metadata
                }
                for step in state.reasoning_trail
            ]
        }
        
        # Send thinking_completed event FIRST (before final_result to stop animations)
        if self._current_thinking_id and self._thinking_start_time:
            elapsed_seconds = time.time() - self._thinking_start_time
            # –°–æ–±–∏—Ä–∞–µ–º –≤–µ—Å—å –∫–æ–Ω—Ç–µ–Ω—Ç –∏–∑ reasoning trail
            full_content = "\n".join([step.content for step in state.reasoning_trail])
            await self.ws_manager.send_event(
                self.session_id,
                "thinking_completed",
                {
                    "thinking_id": self._current_thinking_id,
                    "full_content": full_content,
                    "elapsed_seconds": elapsed_seconds,
                    "auto_collapse": True
                }
            )
            self._current_thinking_id = None
            self._thinking_start_time = None
        
        # Send react_complete event
        await self.ws_manager.send_event(
            self.session_id,
            "react_complete",
            {
                "result": human_answer[:1000],
                "trail": result_summary["reasoning_trail"][-10:]
            }
        )
        
        # Send final_result or message_complete event based on mode
        # NOTE: final_result_start, final_result_chunk, final_result_complete are already sent by _generate_final_answer
        # So we only send final_result here as a final confirmation (or skip if already sent)
        if self.config.mode == "query":
            # For query mode, send workflow_stopped to indicate completion (stops animations)
            await self.ws_manager.send_event(
                self.session_id,
                "workflow_stopped",
                {
                    "reason": "–ó–∞–¥–∞—á–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞"
                }
            )
        else:
            # For agent and plan modes, send message_complete to ensure response is displayed
            message_id = f"react_{self.session_id}_{int(time.time() * 1000)}"
            await self.ws_manager.send_event(
                self.session_id,
                "message_complete",
                {
                    "role": "assistant",
                    "message_id": message_id,
                    "content": human_answer
                }
            )
        
        if hasattr(context, 'add_message'):
            context.add_message("assistant", f"–ó–∞–¥–∞—á–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞: {state.goal}")
        
        logger.info(f"[UnifiedReActEngine] Successfully completed in {state.iteration} iterations")
        return result_summary
    
    async def _finalize_failure(
        self,
        state: ReActState,
        analysis: Analysis,
        context: ConversationContext
    ) -> Dict[str, Any]:
        """Finalize failed execution with report."""
        state.status = "failed"
        
        # === NEW ARCHITECTURE: Complete the task-level intent with failure status ===
        task_intent_id = getattr(self, '_task_intent_id', None)
        if task_intent_id and self.ws_manager and self.session_id:
            error_msg = analysis.error_message or "–ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å"
            await self.ws_manager.send_event(
                self.session_id,
                "intent_complete",
                {
                    "intent_id": task_intent_id,
                    "summary": f"‚ùå {error_msg[:50]}",
                    "auto_collapse": False
                }
            )
        
        failure_report = {
            "status": "failed",
            "goal": state.goal,
            "iterations": state.iteration,
            "actions_taken": len(state.action_history),
            "error": analysis.error_message or "–ù–µ —É–¥–∞–ª–æ—Å—å –¥–æ—Å—Ç–∏—á—å —Ü–µ–ª–∏",
            "alternatives_tried": state.alternatives_tried,
            "reasoning_trail": [
                {
                    "iteration": step.iteration,
                    "type": step.step_type,
                    "content": step.content,
                    "metadata": step.metadata
                }
                for step in state.reasoning_trail
            ]
        }
        
        await self.ws_manager.send_event(
            self.session_id,
            "react_failed",
            {
                "reason": failure_report["error"],
                "tried": state.alternatives_tried
            }
        )
        
        # Send message_complete with error message for agent/plan modes
        if self.config.mode != "query":
            error_message = f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å –∑–∞–¥–∞—á—É: {failure_report['error']}"
            message_id = f"react_{self.session_id}_{int(time.time() * 1000)}"
            await self.ws_manager.send_event(
                self.session_id,
                "message_complete",
                {
                    "role": "assistant",
                    "message_id": message_id,
                    "content": error_message
                }
            )
        
        # Send thinking_completed event (with error, –Ω–µ —Å–≤–æ—Ä–∞—á–∏–≤–∞–µ–º)
        if self._current_thinking_id and self._thinking_start_time:
            elapsed_seconds = time.time() - self._thinking_start_time
            full_content = "\n".join([step.content for step in state.reasoning_trail])
            await self.ws_manager.send_event(
                self.session_id,
                "thinking_completed",
                {
                    "thinking_id": self._current_thinking_id,
                    "full_content": full_content,
                    "elapsed_seconds": elapsed_seconds,
                    "auto_collapse": False  # –ù–µ —Å–≤–æ—Ä–∞—á–∏–≤–∞–µ–º –ø—Ä–∏ –æ—à–∏–±–∫–µ
                }
            )
            self._current_thinking_id = None
            self._thinking_start_time = None
        
        logger.warning(f"[UnifiedReActEngine] Failed after {state.iteration} iterations: {failure_report['error']}")
        return failure_report
    
    async def _finalize_timeout(
        self,
        state: ReActState,
        context: ConversationContext
    ) -> Dict[str, Any]:
        """Finalize execution that reached max iterations."""
        state.status = "failed"
        
        # === NEW ARCHITECTURE: Complete the task-level intent with timeout status ===
        task_intent_id = getattr(self, '_task_intent_id', None)
        if task_intent_id and self.ws_manager and self.session_id:
            await self.ws_manager.send_event(
                self.session_id,
                "intent_complete",
                {
                    "intent_id": task_intent_id,
                    "summary": f"‚è±Ô∏è –î–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç ({state.iteration} –∏—Ç–µ—Ä–∞—Ü–∏–π)",
                    "auto_collapse": False
                }
            )
        
        timeout_report = {
            "status": "timeout",
            "goal": state.goal,
            "iterations": state.iteration,
            "actions_taken": len(state.action_history),
            "message": f"–î–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç –∏—Ç–µ—Ä–∞—Ü–∏–π ({state.max_iterations})",
            "reasoning_trail": [
                {
                    "iteration": step.iteration,
                    "type": step.step_type,
                    "content": step.content,
                    "metadata": step.metadata
                }
                for step in state.reasoning_trail
            ]
        }
        
        await self.ws_manager.send_event(
            self.session_id,
            "react_failed",
            {
                "reason": timeout_report["message"],
                "tried": state.alternatives_tried
            }
        )
        
        # Send timeout message based on mode
        timeout_message = f"‚è±Ô∏è {timeout_report['message']}. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —É—Ç–æ—á–Ω–∏—Ç—å –∑–∞–ø—Ä–æ—Å –∏–ª–∏ —Ä–∞–∑–±–∏—Ç—å –∑–∞–¥–∞—á—É –Ω–∞ –±–æ–ª–µ–µ –º–µ–ª–∫–∏–µ —à–∞–≥–∏."
        
        if self.config.mode == "query":
            # For Query mode, send final_result event
            await self.ws_manager.send_event(
                self.session_id,
                "final_result",
                {
                    "content": timeout_message
                }
            )
        else:
            # For agent and plan modes, send message_complete
            message_id = f"react_{self.session_id}_{int(time.time() * 1000)}"
            await self.ws_manager.send_event(
                self.session_id,
                "message_complete",
                {
                    "role": "assistant",
                    "message_id": message_id,
                    "content": timeout_message
                }
            )
        
        # Send thinking_completed event (timeout)
        if self._current_thinking_id and self._thinking_start_time:
            elapsed_seconds = time.time() - self._thinking_start_time
            full_content = "\n".join([step.content for step in state.reasoning_trail])
            await self.ws_manager.send_event(
                self.session_id,
                "thinking_completed",
                {
                    "thinking_id": self._current_thinking_id,
                    "full_content": full_content,
                    "elapsed_seconds": elapsed_seconds,
                    "auto_collapse": False
                }
            )
            self._current_thinking_id = None
            self._thinking_start_time = None
        
        logger.warning(f"[UnifiedReActEngine] Timeout after {state.iteration} iterations")
        return timeout_report
    
    def _transform_to_human_readable(self, action: str, tool_name: str) -> str:
        """Transform technical messages to human-readable format."""
        action_lower = action.lower()
        tool_lower = tool_name.lower()
        
        # –ï—Å–ª–∏ —É–∂–µ human-readable, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å
        if not action_lower.startswith(('fallback:', 'error:', '–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ')):
            return action
        
        # –ú–∞–ø–ø–∏–Ω–≥ tool names –Ω–∞ human-readable –æ–ø–∏—Å–∞–Ω–∏—è
        if 'calendar' in tool_lower or 'event' in tool_lower:
            return "üìÖ –ü–æ–ª—É—á–∞—é —Å–æ–±—ã—Ç–∏—è –∫–∞–ª–µ–Ω–¥–∞—Ä—è..."
        elif 'email' in tool_lower or 'gmail' in tool_lower or 'mail' in tool_lower:
            return "üìß –ò—â—É –≤ –ø–æ—á—Ç–µ..."
        elif 'file' in tool_lower or 'workspace' in tool_lower or 'drive' in tool_lower:
            return "üìÅ –ò—â—É —Ñ–∞–π–ª—ã..."
        elif 'search' in tool_lower:
            return "üîç –ò—â—É –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é..."
        elif 'create' in tool_lower or 'write' in tool_lower:
            return "‚úèÔ∏è –°–æ–∑–¥–∞—é –¥–æ–∫—É–º–µ–Ω—Ç..."
        elif 'read' in tool_lower or 'get' in tool_lower:
            return "üìñ –ß–∏—Ç–∞—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é..."
        else:
            return "üîß –í—ã–ø–æ–ª–Ω—è—é –¥–µ–π—Å—Ç–≤–∏–µ..."
    
    def _get_detail_type(self, tool_name: str) -> str:
        """Map tool name to intent detail type."""
        tool_lower = tool_name.lower()
        if 'search' in tool_lower or 'find' in tool_lower:
            return 'search'
        elif 'read' in tool_lower or 'get' in tool_lower or 'list' in tool_lower or 'fetch' in tool_lower:
            return 'read'
        elif 'create' in tool_lower or 'write' in tool_lower or 'send' in tool_lower or 'update' in tool_lower:
            return 'write'
        else:
            return 'execute'
    
    def _extract_result_details(self, result: str) -> List[str]:
        """Extract meaningful details from result for display in intent block."""
        details = []
        try:
            import json
            import re
            logger.debug(f"[_extract_result_details] Parsing result: {result[:200]}...")
            
            # Try to parse as JSON
            data = None
            if result.strip().startswith('{') or result.strip().startswith('['):
                try:
                    data = json.loads(result)
                except json.JSONDecodeError:
                    pass
            
            if isinstance(data, list):
                # List of items (events, messages, files)
                logger.debug(f"[_extract_result_details] Found list with {len(data)} items")
                for item in data[:10]:  # Max 10 items
                    if isinstance(item, dict):
                        name = item.get('summary') or item.get('title') or item.get('subject') or item.get('name') or item.get('filename')
                        start = item.get('start', {})
                        time_str = ""
                        if isinstance(start, dict):
                            time_str = start.get('dateTime', start.get('date', ''))[:16].replace('T', ' ')
                        elif isinstance(start, str):
                            time_str = start[:16].replace('T', ' ')
                        if name:
                            if time_str:
                                details.append(f"üìÖ {name} - {time_str}")
                            else:
                                details.append(f"‚Ä¢ {name}")
            elif isinstance(data, dict):
                logger.debug(f"[_extract_result_details] Found dict with keys: {list(data.keys())[:10]}")
                if 'events' in data:
                    for event in data['events'][:10]:
                        name = event.get('summary') or event.get('title')
                        start = event.get('start', {})
                        time_str = ""
                        if isinstance(start, dict):
                            time_str = start.get('dateTime', start.get('date', ''))[:16].replace('T', ' ')
                        if name:
                            details.append(f"üìÖ {name} - {time_str}" if time_str else f"üìÖ {name}")
                elif 'messages' in data:
                    for msg in data['messages'][:10]:
                        subject = msg.get('subject') or msg.get('snippet', '')[:50]
                        if subject:
                            details.append(f"üìß {subject}")
                elif 'files' in data:
                    for f in data['files'][:10]:
                        name = f.get('name') or f.get('title')
                        if name:
                            details.append(f"üìÑ {name}")
                else:
                    name = data.get('summary') or data.get('title') or data.get('subject')
                    if name:
                        details.append(f"‚Ä¢ {name}")
            
            # If no structured data found, check for "Found N event(s)" pattern - parse calendar format
            if not details and 'Found' in result and 'event' in result.lower():
                lines = result.split('\n')
                current_event_name = None
                current_event_time = None
                
                for line in lines:
                    line = line.strip()
                    # Match event number and name: "1. –ø—Ä–æ–≤–µ—Ä–∫–∞ 1"
                    event_match = re.match(r'^(\d+)\.\s*(.+)$', line)
                    if event_match:
                        # Save previous event if exists
                        if current_event_name:
                            if current_event_time:
                                details.append(f"üìÖ {current_event_name} - {current_event_time}")
                            else:
                                details.append(f"üìÖ {current_event_name}")
                        current_event_name = event_match.group(2).strip()
                        current_event_time = None
                    # Match time line: "–í—Ä–µ–º—è: 2025-12-25 05:00 - 2025-12-25 06:00"
                    elif line.startswith('–í—Ä–µ–º—è:') or line.startswith('Time:'):
                        time_part = line.split(':', 1)[1].strip()
                        # Extract just date and start time
                        time_match = re.match(r'(\d{4}-\d{2}-\d{2})\s*(\d{2}:\d{2})?', time_part)
                        if time_match:
                            current_event_time = f"{time_match.group(1)} {time_match.group(2) or ''}".strip()
                    
                    if len(details) >= 10:
                        break
                
                # Don't forget the last event
                if current_event_name and len(details) < 10:
                    if current_event_time:
                        details.append(f"üìÖ {current_event_name} - {current_event_time}")
                    else:
                        details.append(f"üìÖ {current_event_name}")
                        
        except Exception as e:
            logger.error(f"[_extract_result_details] Error: {e}")
            lines = result.split('\n')
            for line in lines[:5]:
                line = line.strip()
                if line and len(line) > 3 and not line.startswith('{'):
                    details.append(f"‚Ä¢ {line[:100]}")
        
        logger.debug(f"[_extract_result_details] Extracted {len(details)} details: {details}")
        return details

    def _format_result_summary(self, result: str, tool: str) -> str:
        """Format raw tool result into human-readable Russian summary."""
        import re
        result_lower = result.lower()
        tool_lower = tool.lower() if tool else ""
        
        # Extract count from common patterns like "Found 5 events", "Found 0 messages"
        count_match = re.search(r'found\s+(\d+)\s+(\w+)', result_lower)
        if count_match:
            count = int(count_match.group(1))
            item_type = count_match.group(2)
            
            # Map item types to Russian with proper pluralization
            def pluralize_ru(n: int, one: str, few: str, many: str) -> str:
                mod10 = n % 10
                mod100 = n % 100
                if mod100 >= 11 and mod100 <= 14:
                    return many
                if mod10 == 1:
                    return one
                if mod10 >= 2 and mod10 <= 4:
                    return few
                return many
            
            if 'event' in item_type or 'calendar' in item_type or '–≤—Å—Ç—Ä–µ—á' in tool_lower:
                word = pluralize_ru(count, '–≤—Å—Ç—Ä–µ—á–∞', '–≤—Å—Ç—Ä–µ—á–∏', '–≤—Å—Ç—Ä–µ—á')
                return f"–ù–∞–π–¥–µ–Ω–æ {count} {word}" if count > 0 else "–í—Å—Ç—Ä–µ—á –Ω–µ –Ω–∞–π–¥–µ–Ω–æ"
            elif 'message' in item_type or 'mail' in item_type or 'email' in item_type or '–ø–∏—Å—å–º' in tool_lower:
                word = pluralize_ru(count, '–ø–∏—Å—å–º–æ', '–ø–∏—Å—å–º–∞', '–ø–∏—Å–µ–º')
                return f"–ù–∞–π–¥–µ–Ω–æ {count} {word}" if count > 0 else "–ü–∏—Å–µ–º –Ω–µ –Ω–∞–π–¥–µ–Ω–æ"
            elif 'file' in item_type or 'document' in item_type or 'doc' in item_type or '—Ñ–∞–π–ª' in tool_lower:
                word = pluralize_ru(count, '—Ñ–∞–π–ª', '—Ñ–∞–π–ª–∞', '—Ñ–∞–π–ª–æ–≤')
                return f"–ù–∞–π–¥–µ–Ω–æ {count} {word}" if count > 0 else "–§–∞–π–ª–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ"
            elif 'contact' in item_type or '–∫–æ–Ω—Ç–∞–∫—Ç' in tool_lower:
                word = pluralize_ru(count, '–∫–æ–Ω—Ç–∞–∫—Ç', '–∫–æ–Ω—Ç–∞–∫—Ç–∞', '–∫–æ–Ω—Ç–∞–∫—Ç–æ–≤')
                return f"–ù–∞–π–¥–µ–Ω–æ {count} {word}" if count > 0 else "–ö–æ–Ω—Ç–∞–∫—Ç–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ"
            elif 'task' in item_type or '–∑–∞–¥–∞—á' in tool_lower:
                word = pluralize_ru(count, '–∑–∞–¥–∞—á–∞', '–∑–∞–¥–∞—á–∏', '–∑–∞–¥–∞—á')
                return f"–ù–∞–π–¥–µ–Ω–æ {count} {word}" if count > 0 else "–ó–∞–¥–∞—á –Ω–µ –Ω–∞–π–¥–µ–Ω–æ"
            else:
                word = pluralize_ru(count, '—Ä–µ–∑—É–ª—å—Ç–∞—Ç', '—Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞', '—Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤')
                return f"–ù–∞–π–¥–µ–Ω–æ {count} {word}" if count > 0 else "–ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ"
        
        # Handle success/error patterns
        if 'success' in result_lower or 'successfully' in result_lower:
            return "‚úì –í—ã–ø–æ–ª–Ω–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ"
        if 'error' in result_lower or 'failed' in result_lower:
            return "‚úó –û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è"
        if 'created' in result_lower:
            return "‚úì –°–æ–∑–¥–∞–Ω–æ"
        if 'sent' in result_lower:
            return "‚úì –û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ"
        if 'updated' in result_lower:
            return "‚úì –û–±–Ω–æ–≤–ª–µ–Ω–æ"
        if 'deleted' in result_lower:
            return "‚úì –£–¥–∞–ª–µ–Ω–æ"
        
        # Default: truncate result
        if len(result) > 50:
            return result[:47] + "..."
        return result if result else "–í—ã–ø–æ–ª–Ω–µ–Ω–æ"

    async def _stream_reasoning(self, event_type: str, data: Dict[str, Any]):
        """Stream reasoning event to WebSocket - Cursor-style intent blocks only."""
        try:
            connection_count = self.ws_manager.get_connection_count(self.session_id)
            if connection_count > 0:
                # Only send intent events (Cursor-style) - no legacy events
                if event_type == "react_thinking":
                    # Don't start intent on thinking - wait for action
                    pass
                
                elif event_type == "react_action":
                    # === NEW ARCHITECTURE: Don't create new intent, just track tool ===
                    tool = data.get("tool", "unknown")
                    action = data.get("action", "")
                    
                    # Save tool for later use in observation
                    self._last_tool = tool
                    
                    # Don't create new intent - details are added in main loop
                    # Keep using task-level intent
                    pass
                
                elif event_type == "react_observation":
                    # === NEW ARCHITECTURE: Add result as intent_detail, don't complete yet ===
                    task_intent_id = getattr(self, '_task_intent_id', None)
                    if task_intent_id:
                        result = str(data.get("result", ""))
                        tool = getattr(self, '_last_tool', 'unknown')
                        
                        # Format result into human-readable Russian summary
                        summary = self._format_result_summary(result, tool)
                        
                        # Send summary as intent_detail
                        if summary:
                            await self.ws_manager.send_event(
                                self.session_id,
                                "intent_detail",
                                {
                                    "intent_id": task_intent_id,
                                    "type": "analyze",
                                    "description": summary
                                }
                            )
                        
                        # Extract and send result details (e.g., meeting names, file names)
                        details = self._extract_result_details(result)
                        for detail in details[:5]:  # Limit to 5 details per observation
                            await self.ws_manager.send_event(
                                self.session_id,
                                "intent_detail",
                                {
                                    "intent_id": task_intent_id,
                                    "type": "analyze",
                                    "description": detail
                                }
                            )
                        
                        # Don't complete intent here - only in _finalize_success
                
            else:
                logger.debug(f"[UnifiedReActEngine] Skipping event {event_type} - no WebSocket connection")
        except Exception as e:
            logger.debug(f"[UnifiedReActEngine] Failed to send event {event_type}: {e}")

